# PyTorch-only requirements for distilled monitoring system
# Enhanced with Ollama Llama 3.2 fallback support

# Core PyTorch ecosystem (CPU + CUDA support)
torch>=1.9.0,<2.0
torchvision>=0.10.0
torchaudio>=0.9.0

# Transformers with PyTorch backend only
transformers[torch]>=4.20.0,<5.0
tokenizers>=0.13.0

# Datasets and ML utilities
datasets>=2.0.0
accelerate>=0.12.0

# Core dependencies
numpy>=1.21.0,<1.25
requests>=2.25.0
scikit-learn>=1.0.0
pandas>=1.3.0

# Visualization
matplotlib>=3.5.0
seaborn>=0.11.0

# Jupyter environment
jupyter>=1.0.0
ipywidgets>=7.6.0
notebook>=6.4.0

# Protobuf compatibility (downgraded version to avoid conflicts)
protobuf>=3.19.0,<3.21.0

# System monitoring and utilities
psutil>=5.8.0

# Progress bars and CLI utilities
tqdm>=4.62.0

# HTTP client for Ollama integration
httpx>=0.24.0

# JSON handling for configuration
jsonschema>=4.0.0

# Development and debugging tools
ipdb>=0.13.0

# Optional: Enhanced tokenization support
sentencepiece>=0.1.96

# Optional: Better JSON handling
ujson>=5.0.0

# Optional: Memory profiling
memory-profiler>=0.60.0

# Optional: GPU memory monitoring
py3nvml>=0.2.6

# Exclude TensorFlow completely to avoid conflicts
# Do NOT install:
# tensorflow*
# tf-*
# tensorboard
# tensorflow-gpu

# Optional Spark support (uncomment if needed)
# pyspark>=3.2.0

# Optional: For advanced logging
# structlog>=22.0.0

# Optional: For configuration file validation
# pydantic>=1.9.0

# Optional: For better CLI experience
# click>=8.0.0
# rich>=12.0.0