#!/usr/bin/env python3
"""
TFT Monitoring Dashboard - Production Web Interface
Built with Streamlit for easy deployment and professional UI

Usage:
    streamlit run tft_dashboard_web.py

Requirements:
    pip install streamlit plotly requests pandas
"""

import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import time
from typing import Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# PAGE CONFIGURATION
# =============================================================================

st.set_page_config(
    page_title="TFT Monitoring Dashboard",
    page_icon="üîÆ",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'About': "TFT Monitoring Dashboard - Temporal Fusion Transformer for Server Monitoring"
    }
)

# =============================================================================
# SESSION STATE INITIALIZATION
# =============================================================================

if 'daemon_url' not in st.session_state:
    st.session_state.daemon_url = "http://localhost:8000"

if 'refresh_interval' not in st.session_state:
    st.session_state.refresh_interval = 30

if 'history' not in st.session_state:
    st.session_state.history = []

if 'last_update' not in st.session_state:
    st.session_state.last_update = None

if 'daemon_connected' not in st.session_state:
    st.session_state.daemon_connected = False

if 'demo_mode' not in st.session_state:
    st.session_state.demo_mode = False

if 'demo_running' not in st.session_state:
    st.session_state.demo_running = False

if 'demo_data' not in st.session_state:
    st.session_state.demo_data = None

if 'demo_index' not in st.session_state:
    st.session_state.demo_index = 0

if 'demo_scenario' not in st.session_state:
    st.session_state.demo_scenario = None

if 'demo_start_time' not in st.session_state:
    st.session_state.demo_start_time = None

if 'demo_generator' not in st.session_state:
    st.session_state.demo_generator = None

if 'last_demo_tick' not in st.session_state:
    st.session_state.last_demo_tick = None

# =============================================================================
# DAEMON API CLIENT
# =============================================================================

class DaemonClient:
    """Client for TFT Inference Daemon API."""

    def __init__(self, base_url: str):
        self.base_url = base_url.rstrip('/')

    def check_health(self) -> Dict:
        """Check daemon health status."""
        try:
            response = requests.get(f"{self.base_url}/health", timeout=2)
            if response.ok:
                return {'connected': True, 'data': response.json()}
            return {'connected': False, 'error': f"HTTP {response.status_code}"}
        except requests.exceptions.ConnectionError:
            return {'connected': False, 'error': 'Connection refused'}
        except Exception as e:
            return {'connected': False, 'error': str(e)}

    def get_predictions(self) -> Optional[Dict]:
        """Get current predictions from daemon."""
        try:
            response = requests.get(f"{self.base_url}/predictions/current", timeout=5)
            if response.ok:
                return response.json()
            return None
        except Exception as e:
            st.error(f"Error fetching predictions: {e}")
            return None

    def get_alerts(self) -> Optional[Dict]:
        """Get active alerts from daemon."""
        try:
            response = requests.get(f"{self.base_url}/alerts/active", timeout=5)
            if response.ok:
                return response.json()
            return None
        except Exception as e:
            return None

    def feed_data(self, records: List[Dict]) -> bool:
        """Feed data to daemon for demo mode."""
        try:
            response = requests.post(
                f"{self.base_url}/feed/data",
                json={"records": records},
                timeout=5
            )
            if not response.ok:
                st.error(f"Daemon returned {response.status_code}: {response.text[:200]}")
            return response.ok
        except Exception as e:
            st.error(f"Error feeding data: {e}")
            return False

# =============================================================================
# DEMO MODE FUNCTIONS
# =============================================================================

def initialize_demo_generator(scenario: str, fleet_size: int = 90):
    """
    Initialize streaming demo data generator.

    Args:
        scenario: 'stable', 'degrading', or 'critical'
        fleet_size: Number of servers to simulate (max 90 - full fleet)
    """
    from demo_stream_generator import DemoStreamGenerator

    # Create new generator - max 90 servers (full training fleet)
    generator = DemoStreamGenerator(num_servers=min(fleet_size, 90), seed=None)
    generator.set_scenario(scenario)

    st.session_state.demo_generator = generator
    st.session_state.demo_scenario = scenario
    st.session_state.demo_running = True
    st.session_state.demo_start_time = datetime.now()

def stop_demo():
    """Stop the demo mode."""
    st.session_state.demo_running = False
    st.session_state.demo_generator = None
    st.session_state.demo_scenario = None

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def get_health_status(predictions: Dict) -> tuple:
    """
    Determine overall environment health status.

    Returns: (status_text, status_color, status_emoji)
    """
    if not predictions or 'environment' not in predictions:
        return "Unknown", "gray", "‚ùì"

    env = predictions['environment']
    prob_30m = env.get('prob_30m', 0)
    prob_8h = env.get('prob_8h', 0)

    if prob_30m > 0.7 or prob_8h > 0.8:
        return "Critical", "red", "üî¥"
    elif prob_30m > 0.4 or prob_8h > 0.5:
        return "Warning", "orange", "üü†"
    elif prob_30m > 0.2 or prob_8h > 0.3:
        return "Caution", "yellow", "üü°"
    else:
        return "Healthy", "green", "üü¢"

def calculate_server_risk_score(server_pred: Dict) -> float:
    """Calculate aggregated risk score for a server (0-100)."""
    risk = 0.0

    # CPU risk
    if 'cpu_percent' in server_pred:
        cpu = server_pred['cpu_percent']
        p90 = cpu.get('p90', [])
        if p90:
            max_cpu = max(p90[:6]) if len(p90) >= 6 else max(p90)
            if max_cpu > 95:
                risk += 40
            elif max_cpu > 85:
                risk += 25
            elif max_cpu > 70:
                risk += 10

    # Memory risk
    if 'memory_percent' in server_pred:
        mem = server_pred['memory_percent']
        p90 = mem.get('p90', [])
        if p90:
            max_mem = max(p90[:6]) if len(p90) >= 6 else max(p90)
            if max_mem > 95:
                risk += 30
            elif max_mem > 85:
                risk += 20
            elif max_mem > 70:
                risk += 10

    # Latency risk
    if 'load_average' in server_pred:
        lat = server_pred['load_average']
        p90 = lat.get('p90', [])
        if p90:
            max_lat = max(p90[:6]) if len(p90) >= 6 else max(p90)
            if max_lat > 100:
                risk += 20
            elif max_lat > 50:
                risk += 10

    # Disk risk
    if 'disk_percent' in server_pred:
        disk = server_pred['disk_percent']
        p90 = disk.get('p90', [])
        if p90:
            max_disk = max(p90[:6]) if len(p90) >= 6 else max(p90)
            if max_disk > 90:
                risk += 10

    return min(risk, 100)

def get_risk_color(risk_score: float) -> str:
    """Get color for risk score."""
    if risk_score >= 70:
        return "#ff4444"  # Red
    elif risk_score >= 40:
        return "#ff9900"  # Orange
    elif risk_score >= 20:
        return "#ffcc00"  # Yellow
    else:
        return "#44ff44"  # Green

# =============================================================================
# SIDEBAR
# =============================================================================

with st.sidebar:
    st.title("‚öôÔ∏è Dashboard Settings")

    # Daemon connection
    st.subheader("Daemon Connection")
    daemon_url = st.text_input(
        "Daemon URL",
        value=st.session_state.daemon_url,
        help="URL of the TFT inference daemon"
    )
    st.session_state.daemon_url = daemon_url

    # Test connection
    client = DaemonClient(daemon_url)
    health = client.check_health()

    if health['connected']:
        st.success("‚úÖ Connected to daemon")
        st.session_state.daemon_connected = True
        health_data = health.get('data', {})
        st.caption(f"Status: {health_data.get('status', 'Unknown')}")

        # Show warmup status if available
        try:
            status_response = requests.get(f"{daemon_url}/status", timeout=2)
            if status_response.ok:
                status_data = status_response.json()
                warmup = status_data.get('warmup', {})
                if not warmup.get('is_warmed_up', True):
                    progress = warmup.get('progress_percent', 0)
                    st.warning(f"‚è≥ {warmup.get('message', 'Model warming up')} ({progress:.0f}%)")
                    st.progress(progress / 100)
                else:
                    st.caption(f"‚úÖ {warmup.get('message', 'Model ready')}")
        except:
            pass
    else:
        st.error(f"‚ùå Not connected: {health.get('error', 'Unknown error')}")
        st.session_state.daemon_connected = False
        st.info("Start daemon with:\n```\npython tft_inference.py --daemon\n```")

    st.divider()

    # Refresh settings
    st.subheader("Refresh Settings")
    refresh_interval = st.slider(
        "Auto-refresh interval (seconds)",
        min_value=5,
        max_value=120,
        value=st.session_state.refresh_interval,
        step=5,
        help="How often to fetch new predictions"
    )
    st.session_state.refresh_interval = refresh_interval

    auto_refresh = st.checkbox("Enable auto-refresh", value=True)

    if st.button("üîÑ Refresh Now", width='stretch'):
        st.rerun()

    st.divider()

    # Interactive Demo Control (Scenario Switcher)
    st.subheader("üé¨ Interactive Demo Control")

    if st.session_state.daemon_connected:
        st.markdown("**Scenario Control:** (Changes metrics generator behavior)")

        col1, col2, col3 = st.columns(3)

        # Metrics generator URL (port 8001)
        generator_url = "http://localhost:8001"

        with col1:
            if st.button("üü¢ Healthy", width='stretch', key="scenario_healthy"):
                try:
                    response = requests.post(
                        f"{generator_url}/scenario/set",
                        json={"scenario": "healthy"},
                        timeout=2
                    )
                    if response.ok:
                        st.success("‚úÖ Scenario: Healthy - All servers recovering")
                    else:
                        st.error(f"Failed to change scenario: {response.status_code}")
                except Exception as e:
                    st.error(f"Cannot connect to metrics generator at {generator_url}")

        with col2:
            if st.button("üü° Degrading", width='stretch', key="scenario_degrading"):
                try:
                    response = requests.post(
                        f"{generator_url}/scenario/set",
                        json={"scenario": "degrading"},
                        timeout=2
                    )
                    if response.ok:
                        result = response.json()
                        st.warning(f"‚ö†Ô∏è Scenario: Degrading - {result.get('affected_servers', 0)} servers affected")
                    else:
                        st.error(f"Failed to change scenario: {response.status_code}")
                except Exception as e:
                    st.error(f"Cannot connect to metrics generator at {generator_url}")

        with col3:
            if st.button("üî¥ Critical", width='stretch', key="scenario_critical"):
                try:
                    response = requests.post(
                        f"{generator_url}/scenario/set",
                        json={"scenario": "critical"},
                        timeout=2
                    )
                    if response.ok:
                        result = response.json()
                        st.error(f"üî¥ Scenario: Critical - {result.get('affected_servers', 0)} servers in crisis!")
                    else:
                        st.error(f"Failed to change scenario: {response.status_code}")
                except Exception as e:
                    st.error(f"Cannot connect to metrics generator at {generator_url}")

        # Show current scenario status
        try:
            scenario_response = requests.get(f"{generator_url}/scenario/status", timeout=1)
            if scenario_response.ok:
                status = scenario_response.json()
                st.info(f"üìä Current: {status['scenario'].upper()} | "
                        f"Affected: {status.get('total_affected', 0)} servers | "
                        f"Tick: {status.get('tick_count', 0)}")
        except:
            st.caption("üí° Tip: Metrics generator should be running on port 8001")
    else:
        st.warning("‚ö†Ô∏è Connect to daemon to use scenario control")

    st.divider()

    # Demo Mode
    st.subheader("üé¨ Demo Mode (Legacy)")

    demo_enabled = st.checkbox(
        "Enable Demo Mode",
        value=st.session_state.demo_mode,
        help="Generate and stream demo scenarios in real-time"
    )
    st.session_state.demo_mode = demo_enabled

    if demo_enabled:
        st.markdown("**Select Scenario:**")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("üü¢ Stable", width='stretch', disabled=st.session_state.demo_running):
                initialize_demo_generator('stable', fleet_size=90)
                st.success("‚úÖ Stable scenario initialized - All 90 servers streaming every 5s")

        with col2:
            if st.button("üü° Degrading", width='stretch', disabled=st.session_state.demo_running):
                initialize_demo_generator('degrading', fleet_size=90)
                st.success("‚úÖ Degrading scenario initialized - Servers will gradually degrade")

        with col3:
            if st.button("üî¥ Critical", width='stretch', disabled=st.session_state.demo_running):
                initialize_demo_generator('critical', fleet_size=90)
                st.success("‚úÖ Critical scenario initialized - Rapid degradation to critical levels")

        # Demo status
        if st.session_state.demo_running and st.session_state.demo_generator is not None:
            scenario_info = st.session_state.demo_generator.get_scenario_info()
            st.info(f"üé¨ Running: {st.session_state.demo_scenario.upper()}")

            # Show scenario progress
            tick_count = scenario_info['tick_count']
            elapsed = (datetime.now() - st.session_state.demo_start_time).total_seconds()
            st.caption(f"Ticks: {tick_count} | Elapsed: {elapsed:.0f}s | Streaming every 5s")

            # Show degrading servers
            if scenario_info['degrading_servers'] > 0:
                st.caption(f"‚ö†Ô∏è {scenario_info['degrading_servers']} servers degrading")

            if st.button("‚èπÔ∏è Stop Demo", width='stretch'):
                stop_demo()
                st.success("‚úÖ Demo stopped")

    st.divider()

    # Info
    st.subheader("üìä Dashboard Info")
    if st.session_state.last_update:
        st.caption(f"Last update: {st.session_state.last_update.strftime('%H:%M:%S')}")
    st.caption(f"Refresh interval: {refresh_interval}s")

    # Status indicator
    st.divider()
    if st.session_state.daemon_connected:
        if st.session_state.demo_running:
            st.info("üé¨ Demo Mode Active")
        else:
            st.success("üü¢ Dashboard Active")
    else:
        st.warning("üü° Daemon Offline")

# =============================================================================
# MAIN DASHBOARD
# =============================================================================

st.title("üîÆ TFT Monitoring Dashboard")
st.caption("Temporal Fusion Transformer - Real-time Server Monitoring & Prediction")

# Demo Mode: Stream data to daemon (time-based, no blocking)
if st.session_state.demo_running and st.session_state.demo_generator is not None:
    current_time = datetime.now()

    # Only generate tick if 5 seconds have passed since last tick
    should_tick = (
        st.session_state.last_demo_tick is None or
        (current_time - st.session_state.last_demo_tick).total_seconds() >= 5
    )

    if should_tick:
        # Generate next tick of data
        tick_data = st.session_state.demo_generator.generate_tick()

        # Convert to records and feed to daemon
        records = tick_data.to_dict('records')

        # Convert timestamps to strings for JSON serialization
        for record in records:
            if 'timestamp' in record:
                record['timestamp'] = str(record['timestamp'])

        if st.session_state.daemon_connected:
            # Feed data to daemon
            success = client.feed_data(records)

            if not success:
                st.warning("‚ö†Ô∏è Failed to feed demo data to daemon")

        # Update last tick time
        st.session_state.last_demo_tick = current_time

# Fetch current data (with smart caching to avoid re-fetching on UI changes)
if st.session_state.daemon_connected:
    # Only fetch if enough time has passed or no cached data
    should_fetch = (
        'cached_predictions' not in st.session_state or
        st.session_state.last_update is None or
        (datetime.now() - st.session_state.last_update).total_seconds() >= 1
    )

    if should_fetch:
        predictions = client.get_predictions()
        alerts = client.get_alerts()
        st.session_state.last_update = datetime.now()

        # Cache for fast UI updates
        st.session_state.cached_predictions = predictions
        st.session_state.cached_alerts = alerts

        # Store in history
        if predictions:
            st.session_state.history.append({
                'timestamp': datetime.now(),
                'predictions': predictions
            })
            # Keep last 100 entries
            st.session_state.history = st.session_state.history[-100:]
    else:
        # Use cached data (much faster for dropdown changes!)
        predictions = st.session_state.get('cached_predictions')
        alerts = st.session_state.get('cached_alerts')
else:
    predictions = None
    alerts = None
    st.warning("‚ö†Ô∏è Daemon not connected. Connect to see live predictions.")

# =============================================================================
# TABS
# =============================================================================

tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs([
    "üìä Overview",
    "üî• Heatmap",
    "‚ö†Ô∏è Top 5 Servers",
    "üìà Historical",
    "üí∞ Cost Avoidance",
    "ü§ñ Auto-Remediation",
    "üì± Alerting Strategy",
    "‚öôÔ∏è Advanced",
    "üó∫Ô∏è Roadmap"
])

# =============================================================================
# TAB 1: OVERVIEW
# =============================================================================

with tab1:
    if predictions:
        # Environment status
        status_text, status_color, status_emoji = get_health_status(predictions)

        # Top KPIs
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                label="Environment Status",
                value=f"{status_emoji} {status_text}",
                delta=None
            )

        with col2:
            env = predictions.get('environment', {})
            prob_30m = env.get('prob_30m', 0) * 100
            st.metric(
                label="Incident Risk (30m)",
                value=f"{prob_30m:.1f}%",
                delta=None,
                help="Probability of incident in next 30 minutes"
            )

        with col3:
            prob_8h = env.get('prob_8h', 0) * 100
            st.metric(
                label="Incident Risk (8h)",
                value=f"{prob_8h:.1f}%",
                delta=None,
                help="Probability of incident in next 8 hours"
            )

        with col4:
            server_preds = predictions.get('predictions', {})
            total_servers = len(server_preds)
            healthy_count = sum(1 for s, p in server_preds.items() if calculate_server_risk_score(p) < 20)
            st.metric(
                label="Fleet Status",
                value=f"{healthy_count}/{total_servers}",
                delta=None,
                help="Healthy servers / Total servers"
            )

        st.divider()

        # Server Risk Distribution
        st.subheader("üìä Fleet Risk Distribution")

        if server_preds:
            # Calculate risk scores
            server_risks = []
            for server_name, server_pred in server_preds.items():
                risk_score = calculate_server_risk_score(server_pred)
                server_risks.append({
                    'Server': server_name,
                    'Risk Score': risk_score,
                    'Status': 'Critical' if risk_score >= 70 else
                             'Warning' if risk_score >= 40 else
                             'Caution' if risk_score >= 20 else 'Healthy'
                })

            risk_df = pd.DataFrame(server_risks)

            col1, col2 = st.columns([2, 1])

            with col1:
                # Bar chart of risks
                fig = px.bar(
                    risk_df.sort_values('Risk Score', ascending=False).head(15),
                    x='Server',
                    y='Risk Score',
                    color='Risk Score',
                    color_continuous_scale=['green', 'yellow', 'orange', 'red'],
                    range_color=[0, 100],
                    title="Top 15 Servers by Risk Score",
                    height=400
                )
                fig.update_layout(xaxis_tickangle=-45)
                st.plotly_chart(fig)

            with col2:
                # Risk distribution pie
                status_counts = risk_df['Status'].value_counts()
                fig = px.pie(
                    values=status_counts.values,
                    names=status_counts.index,
                    title="Server Status Distribution",
                    color=status_counts.index,
                    color_discrete_map={
                        'Healthy': 'green',
                        'Caution': 'yellow',
                        'Warning': 'orange',
                        'Critical': 'red'
                    },
                    height=400
                )
                st.plotly_chart(fig)

        st.divider()

        # Recent Alerts
        st.subheader("üîî Active Alerts")

        if alerts:
            alert_list = alerts.get('alerts', [])
            if alert_list:
                alert_df = pd.DataFrame(alert_list)
                st.dataframe(alert_df, width='stretch', hide_index=True)
            else:
                st.success("‚úÖ No active alerts")
        else:
            st.info("No alert data available")

    else:
        st.info("üëà Connect to daemon to see live predictions")
        st.markdown("""
        **To get started:**

        1. Start the inference daemon:
           ```bash
           python tft_inference.py --daemon --port 8000
           ```

        2. The dashboard will automatically connect and display live predictions

        3. Predictions update every {refresh_interval} seconds
        """)

# =============================================================================
# TAB 2: HEATMAP
# =============================================================================

with tab2:
    st.subheader("üî• Server Fleet Heatmap")

    if predictions and predictions.get('predictions'):
        server_preds = predictions['predictions']

        # Metric selector
        metric_options = {
            'Risk Score': 'risk',
            'CPU (p90)': 'cpu',
            'Memory (p90)': 'memory',
            'Latency (p90)': 'latency'
        }

        selected_metric = st.selectbox(
            "Select metric to display",
            options=list(metric_options.keys()),
            index=0
        )

        metric_key = metric_options[selected_metric]

        # Build heatmap data
        heatmap_data = []
        for server_name, server_pred in server_preds.items():
            if metric_key == 'risk':
                value = calculate_server_risk_score(server_pred)
            elif metric_key == 'cpu':
                cpu = server_pred.get('cpu_percent', {})
                p90 = cpu.get('p90', [])
                value = max(p90[:6]) if len(p90) >= 6 else (max(p90) if p90 else 0)
            elif metric_key == 'memory':
                mem = server_pred.get('memory_percent', {})
                p90 = mem.get('p90', [])
                value = max(p90[:6]) if len(p90) >= 6 else (max(p90) if p90 else 0)
            elif metric_key == 'latency':
                lat = server_pred.get('load_average', {})
                p90 = lat.get('p90', [])
                value = max(p90[:6]) if len(p90) >= 6 else (max(p90) if p90 else 0)
            else:
                value = 0

            heatmap_data.append({
                'Server': server_name,
                'Value': value
            })

        heatmap_df = pd.DataFrame(heatmap_data)
        heatmap_df = heatmap_df.sort_values('Value', ascending=False)

        # Create grid layout (5 columns)
        servers_per_row = 5
        rows = [heatmap_df.iloc[i:i+servers_per_row] for i in range(0, len(heatmap_df), servers_per_row)]

        # Display as grid
        for row_data in rows:
            cols = st.columns(servers_per_row)
            for idx, (_, server_row) in enumerate(row_data.iterrows()):
                if idx < len(cols):
                    with cols[idx]:
                        server_name = server_row['Server']
                        value = server_row['Value']

                        # Determine color
                        if metric_key == 'risk':
                            color = get_risk_color(value)
                        else:
                            # Scale color based on value
                            if value > 90:
                                color = "#ff4444"
                            elif value > 70:
                                color = "#ff9900"
                            elif value > 50:
                                color = "#ffcc00"
                            else:
                                color = "#44ff44"

                        # Display server card
                        st.markdown(f"""
                        <div style="background-color: {color}; padding: 15px; border-radius: 5px; text-align: center; margin: 5px;">
                            <strong style="color: #000;">{server_name}</strong><br>
                            <span style="font-size: 24px; color: #000;">{value:.1f}</span>
                        </div>
                        """, unsafe_allow_html=True)

        st.divider()

        # Summary statistics
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Minimum", f"{heatmap_df['Value'].min():.1f}")
        with col2:
            st.metric("Average", f"{heatmap_df['Value'].mean():.1f}")
        with col3:
            st.metric("Maximum", f"{heatmap_df['Value'].max():.1f}")
        with col4:
            st.metric("Std Dev", f"{heatmap_df['Value'].std():.1f}")

    else:
        st.info("Connect to daemon to see server heatmap")

# =============================================================================
# TAB 3: TOP 5 SERVERS
# =============================================================================

with tab3:
    st.subheader("‚ö†Ô∏è Top 5 Problem Servers")

    if predictions and predictions.get('predictions'):
        server_preds = predictions['predictions']

        # Calculate risk scores
        server_risks = []
        for server_name, server_pred in server_preds.items():
            risk_score = calculate_server_risk_score(server_pred)
            server_risks.append({
                'server': server_name,
                'risk': risk_score,
                'pred': server_pred
            })

        # Sort by risk
        server_risks.sort(key=lambda x: x['risk'], reverse=True)
        top_5 = server_risks[:5]

        # Display each server
        for idx, server_info in enumerate(top_5):
            server_name = server_info['server']
            risk_score = server_info['risk']
            server_pred = server_info['pred']

            # Expander for each server
            with st.expander(f"#{idx+1} - {server_name} (Risk: {risk_score:.1f})", expanded=(idx == 0)):
                col1, col2 = st.columns([1, 2])

                with col1:
                    # Risk gauge
                    fig = go.Figure(go.Indicator(
                        mode="gauge+number",
                        value=risk_score,
                        title={'text': "Risk Score"},
                        gauge={
                            'axis': {'range': [0, 100]},
                            'bar': {'color': get_risk_color(risk_score)},
                            'steps': [
                                {'range': [0, 20], 'color': "lightgreen"},
                                {'range': [20, 40], 'color': "yellow"},
                                {'range': [40, 70], 'color': "orange"},
                                {'range': [70, 100], 'color': "red"}
                            ],
                            'threshold': {
                                'line': {'color': "black", 'width': 4},
                                'thickness': 0.75,
                                'value': risk_score
                            }
                        }
                    ))
                    fig.update_layout(height=250)
                    st.plotly_chart(fig, use_container_width=True, key=f"gauge_{server_name}")

                with col2:
                    # Show current vs predicted side-by-side
                    st.markdown("**Current State vs Predictions (30min ahead)**")

                    # Create comparison table
                    metric_rows = []

                    # CPU
                    if 'cpu_percent' in server_pred:
                        cpu = server_pred['cpu_percent']
                        current = cpu.get('current', 0)
                        p50 = cpu.get('p50', [])
                        if p50:
                            future = np.mean(p50[:6]) if len(p50) >= 6 else np.mean(p50)
                            delta = future - current
                            delta_str = f"+{delta:.1f}%" if delta > 0 else f"{delta:.1f}%"
                            metric_rows.append({
                                'Metric': 'CPU',
                                'Current': f"{current:.1f}%",
                                'Predicted': f"{future:.1f}%",
                                'Œî': delta_str
                            })

                    # Memory
                    if 'memory_percent' in server_pred:
                        mem = server_pred['memory_percent']
                        current = mem.get('current', 0)
                        p50 = mem.get('p50', [])
                        if p50:
                            future = np.mean(p50[:6]) if len(p50) >= 6 else np.mean(p50)
                            delta = future - current
                            delta_str = f"+{delta:.1f}%" if delta > 0 else f"{delta:.1f}%"
                            metric_rows.append({
                                'Metric': 'Memory',
                                'Current': f"{current:.1f}%",
                                'Predicted': f"{future:.1f}%",
                                'Œî': delta_str
                            })

                    # Latency (load_average)
                    if 'load_average' in server_pred:
                        lat = server_pred['load_average']
                        current = lat.get('current', 0)
                        p50 = lat.get('p50', [])
                        if p50:
                            future = np.mean(p50[:6]) if len(p50) >= 6 else np.mean(p50)
                            delta = future - current
                            delta_str = f"+{delta:.1f}ms" if delta > 0 else f"{delta:.1f}ms"
                            metric_rows.append({
                                'Metric': 'Latency',
                                'Current': f"{current:.1f}ms",
                                'Predicted': f"{future:.1f}ms",
                                'Œî': delta_str
                            })

                    # Disk
                    if 'disk_percent' in server_pred:
                        disk = server_pred['disk_percent']
                        current = disk.get('current', 0)
                        p50 = disk.get('p50', [])
                        if p50:
                            future = np.mean(p50[:6]) if len(p50) >= 6 else np.mean(p50)
                            delta = future - current
                            delta_str = f"+{delta:.1f}" if delta > 0 else f"{delta:.1f}"
                            metric_rows.append({
                                'Metric': 'Disk I/O',
                                'Current': f"{current:.1f} MB/s",
                                'Predicted': f"{future:.1f} MB/s",
                                'Œî': delta_str
                            })

                    # Display comparison table
                    if metric_rows:
                        df_comparison = pd.DataFrame(metric_rows)
                        st.dataframe(df_comparison, width='stretch', hide_index=True)

                        # Highlight if significant degradation is predicted
                        degrading_metrics = [row for row in metric_rows if '+' in row['Œî']]
                        if len(degrading_metrics) >= 2:
                            st.warning(f"‚ö†Ô∏è {len(degrading_metrics)} metrics predicted to increase")

                # Prediction timeline
                st.markdown("**Prediction Timeline (Next 8 hours)**")

                # Create timeline chart for CPU
                if 'cpu_percent' in server_pred:
                    cpu = server_pred['cpu_percent']
                    p10 = cpu.get('p10', [])
                    p50 = cpu.get('p50', [])
                    p90 = cpu.get('p90', [])

                    if p10 and p50 and p90:
                        # Create time axis (5-min intervals for 8 hours = 96 steps)
                        time_steps = list(range(len(p50)))

                        fig = go.Figure()

                        # Add confidence band
                        fig.add_trace(go.Scatter(
                            x=time_steps + time_steps[::-1],
                            y=p90 + p10[::-1],
                            fill='toself',
                            fillcolor='rgba(0,100,250,0.2)',
                            line=dict(color='rgba(255,255,255,0)'),
                            name='p10-p90 range',
                            showlegend=True
                        ))

                        # Add p50 line
                        fig.add_trace(go.Scatter(
                            x=time_steps,
                            y=p50,
                            mode='lines',
                            name='p50 (median)',
                            line=dict(color='blue', width=2)
                        ))

                        # Add threshold lines
                        fig.add_hline(y=90, line_dash="dash", line_color="red",
                                     annotation_text="Critical (90%)")
                        fig.add_hline(y=70, line_dash="dash", line_color="orange",
                                     annotation_text="Warning (70%)")

                        fig.update_layout(
                            title="CPU Forecast",
                            xaxis_title="Time Steps (5-min intervals)",
                            yaxis_title="CPU %",
                            height=300,
                            hovermode='x'
                        )

                        st.plotly_chart(fig, use_container_width=True, key=f"forecast_{server_name}")

    else:
        st.info("Connect to daemon to see top problem servers")

# =============================================================================
# TAB 4: HISTORICAL
# =============================================================================

with tab4:
    st.subheader("üìà Historical Trends")

    if st.session_state.history:
        # Time range selector
        col1, col2 = st.columns(2)

        with col1:
            lookback_minutes = st.slider(
                "Lookback period (minutes)",
                min_value=5,
                max_value=60,
                value=30,
                step=5
            )

        with col2:
            metric_to_plot = st.selectbox(
                "Metric to display",
                ["Environment Risk (30m)", "Environment Risk (8h)", "Fleet Health"]
            )

        # Filter history
        cutoff_time = datetime.now() - timedelta(minutes=lookback_minutes)
        recent_history = [h for h in st.session_state.history if h['timestamp'] >= cutoff_time]

        if recent_history:
            # Extract data
            timestamps = [h['timestamp'] for h in recent_history]

            if metric_to_plot == "Environment Risk (30m)":
                values = [h['predictions'].get('environment', {}).get('prob_30m', 0) * 100
                         for h in recent_history]
                ylabel = "Probability (%)"
                title = "Environment Incident Risk (30 minutes)"

            elif metric_to_plot == "Environment Risk (8h)":
                values = [h['predictions'].get('environment', {}).get('prob_8h', 0) * 100
                         for h in recent_history]
                ylabel = "Probability (%)"
                title = "Environment Incident Risk (8 hours)"

            else:  # Fleet Health
                values = []
                for h in recent_history:
                    preds = h['predictions'].get('predictions', {})
                    if preds:
                        healthy = sum(1 for s, p in preds.items() if calculate_server_risk_score(p) < 20)
                        total = len(preds)
                        values.append((healthy / total * 100) if total > 0 else 0)
                    else:
                        values.append(0)
                ylabel = "Healthy %"
                title = "Fleet Health Percentage"

            # Create chart
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=timestamps,
                y=values,
                mode='lines+markers',
                name=metric_to_plot,
                line=dict(color='blue', width=2),
                marker=dict(size=6)
            ))

            fig.update_layout(
                title=title,
                xaxis_title="Time",
                yaxis_title=ylabel,
                height=400,
                hovermode='x'
            )

            st.plotly_chart(fig)

            # Statistics
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Current", f"{values[-1]:.1f}")
            with col2:
                st.metric("Average", f"{np.mean(values):.1f}")
            with col3:
                st.metric("Min", f"{np.min(values):.1f}")
            with col4:
                st.metric("Max", f"{np.max(values):.1f}")

            # Download data
            st.divider()

            if st.button("üì• Download Historical Data (CSV)"):
                df = pd.DataFrame({
                    'timestamp': timestamps,
                    'value': values
                })
                csv = df.to_csv(index=False)
                st.download_button(
                    label="Download CSV",
                    data=csv,
                    file_name=f"tft_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
        else:
            st.info(f"No data collected in the last {lookback_minutes} minutes")

    else:
        st.info("No historical data yet. Data will accumulate as the dashboard runs.")

# =============================================================================
# TAB 5: COST AVOIDANCE
# =============================================================================

with tab5:
    st.subheader("üí∞ Cost Avoidance Dashboard")
    st.markdown("**POC Vision**: Real-time financial impact tracking")

    if predictions and predictions.get('predictions'):
        server_preds = predictions['predictions']
        env = predictions.get('environment', {})

        # Cost assumptions
        st.markdown("### üíµ Cost Assumptions (Configurable)")
        col1, col2, col3 = st.columns(3)

        with col1:
            cost_per_outage_hour = st.number_input(
                "Outage Cost ($/hour)",
                value=50000,
                step=5000,
                help="Average cost per hour of downtime for a critical server"
            )

        with col2:
            avg_outage_duration = st.number_input(
                "Avg Outage Duration (hours)",
                value=2.5,
                step=0.5,
                help="Average duration of an incident if not prevented"
            )

        with col3:
            prevention_rate = st.slider(
                "Prevention Success Rate (%)",
                min_value=50,
                max_value=100,
                value=85,
                help="Percentage of predicted incidents successfully prevented"
            )

        st.divider()

        # Calculate savings
        st.markdown("### üìä Projected Cost Avoidance")

        # Count servers at risk
        high_risk_servers = [s for s, p in server_preds.items()
                            if calculate_server_risk_score(p) >= 70]
        medium_risk_servers = [s for s, p in server_preds.items()
                              if 40 <= calculate_server_risk_score(p) < 70]

        # Calculate potential cost avoidance
        critical_incidents_prevented = len(high_risk_servers) * (prevention_rate / 100)
        warning_incidents_prevented = len(medium_risk_servers) * 0.3 * (prevention_rate / 100)

        total_incidents_prevented = critical_incidents_prevented + warning_incidents_prevented
        cost_avoided_per_incident = cost_per_outage_hour * avg_outage_duration
        total_cost_avoided = total_incidents_prevented * cost_avoided_per_incident

        # Monthly and annual projections
        daily_avoidance = total_cost_avoided
        monthly_avoidance = daily_avoidance * 30
        annual_avoidance = daily_avoidance * 365

        # Display key metrics
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric(
                "Incidents Prevented (Daily)",
                f"{total_incidents_prevented:.1f}",
                delta=None
            )

        with col2:
            st.metric(
                "Daily Cost Avoidance",
                f"${daily_avoidance:,.0f}",
                delta=None
            )

        with col3:
            st.metric(
                "Monthly Projection",
                f"${monthly_avoidance:,.0f}",
                delta=None,
                help="30-day projection"
            )

        with col4:
            st.metric(
                "Annual Projection",
                f"${annual_avoidance:,.0f}",
                delta=None,
                help="365-day projection"
            )

        st.divider()

        # ROI Calculator
        st.markdown("### üéØ ROI Analysis")

        col1, col2 = st.columns(2)

        with col1:
            project_cost = st.number_input(
                "Project Investment ($)",
                value=250000,
                step=25000,
                help="Total cost for development, deployment, and first year operations"
            )

        with col2:
            months_to_roi = (project_cost / monthly_avoidance) if monthly_avoidance > 0 else float('inf')

            if months_to_roi < 12:
                st.success(f"‚úÖ **ROI in {months_to_roi:.1f} months**")
                st.markdown(f"**Payback**: {months_to_roi:.1f} months")
                st.markdown(f"**First Year Net**: ${(annual_avoidance - project_cost):,.0f}")
            else:
                st.info(f"üìä **ROI in {months_to_roi:.1f} months**")

        st.divider()

        # At-Risk Servers Detail
        st.markdown("### üéØ Current At-Risk Servers")

        if high_risk_servers or medium_risk_servers:
            risk_breakdown = []

            for server in high_risk_servers:
                risk_breakdown.append({
                    'Server': server,
                    'Risk Level': 'Critical',
                    'Risk Score': calculate_server_risk_score(server_preds[server]),
                    'Potential Cost if Incident': f"${cost_avoided_per_incident:,.0f}",
                    'Status': 'üî¥ Action Required'
                })

            for server in medium_risk_servers[:5]:  # Top 5 medium risk
                risk_breakdown.append({
                    'Server': server,
                    'Risk Level': 'Warning',
                    'Risk Score': calculate_server_risk_score(server_preds[server]),
                    'Potential Cost if Incident': f"${cost_avoided_per_incident * 0.6:,.0f}",
                    'Status': 'üü† Monitor'
                })

            df_risks = pd.DataFrame(risk_breakdown)
            st.dataframe(df_risks, width='stretch', hide_index=True)
        else:
            st.success("‚úÖ No high-risk servers detected - Fleet is healthy!")

        st.divider()

        # Implementation Note
        st.info("""
        **üí° POC Implementation Note:**

        This tab demonstrates the financial impact tracking capability. In production, we would:

        - **Track actual incidents** prevented vs predicted (accuracy metrics)
        - **Integrate with ITSM** (ServiceNow, JIRA) for actual incident costs
        - **Historical cost avoidance** dashboard showing cumulative savings
        - **Per-profile cost models** (e.g., ML compute downtime costs more than generic servers)
        - **Executive reporting** with monthly/quarterly summaries

        **Business Case**: This system pays for itself in ~3-5 months based on typical financial services downtime costs.
        """)

    else:
        st.info("Connect to daemon to see cost avoidance projections")

# =============================================================================
# TAB 6: AUTO-REMEDIATION
# =============================================================================

with tab6:
    st.subheader("ü§ñ Auto-Remediation Strategy")
    st.markdown("**POC Vision**: Autonomous incident prevention")

    if predictions and predictions.get('predictions'):
        server_preds = predictions['predictions']

        st.markdown("""
        ### üéØ Remediation Actions (Would Be Triggered)

        This tab shows what auto-remediation actions **would be triggered** in a production environment.
        """)

        # Analyze servers and determine remediation actions
        remediation_plan = []

        for server_name, server_pred in server_preds.items():
            risk_score = calculate_server_risk_score(server_pred)

            # Determine remediation based on profile and risk
            if risk_score >= 70:
                # Infer profile from server name
                profile = 'unknown'
                if server_name.startswith('ppml'):
                    profile = 'ml_compute'
                elif server_name.startswith('ppdb'):
                    profile = 'database'
                elif server_name.startswith('ppweb'):
                    profile = 'web_api'
                elif server_name.startswith('pprisk'):
                    profile = 'risk_analytics'
                elif server_name.startswith('ppetl'):
                    profile = 'data_ingest'
                elif server_name.startswith('ppcon'):
                    profile = 'conductor_mgmt'
                else:
                    profile = 'generic'

                # Get predicted CPU
                cpu = server_pred.get('cpu_percent', {})
                p90_cpu = cpu.get('p90', [])
                max_predicted_cpu = max(p90_cpu[:6]) if len(p90_cpu) >= 6 else 0

                # Determine action based on profile
                if profile == 'ml_compute':
                    action = "üîß Scale up compute resources (+2 vCPUs)"
                    integration = "Spectrum Conductor API: POST /resources/scale"
                    eta = "2 minutes"
                elif profile == 'database':
                    action = "üíæ Enable connection pooling, scale read replicas"
                    integration = "Database Management API"
                    eta = "5 minutes"
                elif profile == 'web_api':
                    action = "üåê Scale out (+2 instances), enable rate limiting"
                    integration = "Load Balancer API + Kubernetes HPA"
                    eta = "3 minutes"
                elif profile == 'risk_analytics':
                    action = "üìä Queue batch jobs, scale compute resources"
                    integration = "Job Scheduler API"
                    eta = "4 minutes"
                else:
                    action = "‚öôÔ∏è Alert on-call team for manual review"
                    integration = "PagerDuty API"
                    eta = "Immediate"

                remediation_plan.append({
                    'Server': server_name,
                    'Profile': profile.replace('_', ' ').title(),
                    'Risk Score': risk_score,
                    'Predicted CPU (p90)': f"{max_predicted_cpu:.1f}%",
                    'Auto-Remediation': action,
                    'Integration Point': integration,
                    'ETA to Remediate': eta,
                    'Status': 'üî¥ Would Trigger Now'
                })

        if remediation_plan:
            st.markdown(f"### üö® {len(remediation_plan)} Auto-Remediations Would Be Triggered")

            df_remediation = pd.DataFrame(remediation_plan)
            st.dataframe(df_remediation, width='stretch', hide_index=True)

            st.divider()

            # Summary stats
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("Actions Queued", len(remediation_plan))

            with col2:
                auto_actions = len([r for r in remediation_plan if 'Scale' in r['Auto-Remediation'] or 'Enable' in r['Auto-Remediation']])
                st.metric("Autonomous Actions", auto_actions)

            with col3:
                manual_actions = len(remediation_plan) - auto_actions
                st.metric("Manual Review Required", manual_actions)

        else:
            st.success("‚úÖ No auto-remediation actions required - Fleet is healthy!")

        st.divider()

        # Integration Architecture
        st.markdown("### üèóÔ∏è Integration Architecture")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Phase 1: Auto-Scaling (Weeks 1-2)**
            - ‚úÖ Spectrum Conductor API integration
            - ‚úÖ Kubernetes HPA triggers
            - ‚úÖ Database connection pool tuning
            - ‚úÖ Load balancer configuration

            **Expected Outcome**: 85% of incidents auto-remediated
            """)

        with col2:
            st.markdown("""
            **Phase 2: Advanced Actions (Weeks 3-4)**
            - üîÑ Job rescheduling (batch workloads)
            - üîÑ Traffic rerouting (degraded services)
            - üîÑ Cache warming (predicted load spikes)
            - üîÑ Proactive restarts (memory leaks)

            **Expected Outcome**: 95% incident prevention rate
            """)

        st.divider()

        # Approval Workflow
        st.markdown("### ‚úÖ Approval Workflow (Configurable)")

        st.markdown("""
        **Safety Controls** (Production Implementation):

        1. **Low Risk (Score < 50)**: Auto-approve, log only
        2. **Medium Risk (50-70)**: Auto-approve with 30-second delay, allow manual override
        3. **High Risk (70-85)**: Require senior engineer approval
        4. **Critical Risk (>85)**: Require director-level approval OR auto-approve during off-hours

        **Rollback Strategy**:
        - All actions are reversible within 15 minutes
        - Automatic rollback if metrics don't improve within 10 minutes
        - Manual override always available via dashboard or CLI
        """)

        st.divider()

        # Implementation Note
        st.info("""
        **üí° POC Implementation Note:**

        This tab demonstrates autonomous remediation capabilities. The full implementation would include:

        - **API integrations** with Spectrum Conductor, Kubernetes, load balancers, databases
        - **Approval workflows** with configurable risk thresholds and escalation paths
        - **Audit logging** of all automated actions for compliance
        - **Success metrics** tracking remediation effectiveness
        - **Rollback mechanisms** for automated actions that don't improve metrics
        - **Human override** capabilities at any point in the workflow

        **Impact**: Reduces MTTR (Mean Time To Resolution) from hours to minutes, achieving 95%+ incident prevention rate.
        """)

    else:
        st.info("Connect to daemon to see auto-remediation strategies")

# =============================================================================
# TAB 7: ALERTING STRATEGY
# =============================================================================

with tab7:
    st.subheader("üì± Alerting & Notification Strategy")
    st.markdown("**POC Vision**: Intelligent alert routing and escalation")

    if predictions and predictions.get('predictions'):
        server_preds = predictions['predictions']
        env = predictions.get('environment', {})

        st.markdown("""
        ### üéØ Alert Routing (Would Be Sent)

        This tab shows what alerts **would be sent** based on current predictions.
        """)

        # Determine alert levels
        prob_30m = env.get('prob_30m', 0)
        prob_8h = env.get('prob_8h', 0)

        # Collect alerts to send
        alerts_to_send = []

        # Environment-level alerts
        if prob_30m > 0.7:
            alerts_to_send.append({
                'Severity': 'üî¥ P1 - Critical',
                'Type': 'Environment',
                'Message': f'CRITICAL: Environment incident probability 30m = {prob_30m*100:.1f}%',
                'Recipients': 'On-Call Engineer (PagerDuty)',
                'Delivery Method': 'üìû Phone Call + SMS + App Push',
                'Action Required': 'Immediate investigation and response',
                'Escalation': '15 min ‚Üí Senior Engineer ‚Üí 30 min ‚Üí Director'
            })
        elif prob_30m > 0.4:
            alerts_to_send.append({
                'Severity': 'üü† P2 - Warning',
                'Type': 'Environment',
                'Message': f'WARNING: Environment degrading, incident probability 30m = {prob_30m*100:.1f}%',
                'Recipients': 'Engineering Team (Email + Slack)',
                'Delivery Method': 'üìß Email + üí¨ Slack #ops-alerts',
                'Action Required': 'Monitor closely, prepare for potential escalation',
                'Escalation': '30 min ‚Üí On-Call Engineer (PagerDuty)'
            })
        elif prob_8h > 0.5:
            alerts_to_send.append({
                'Severity': 'üü° P3 - Caution',
                'Type': 'Environment',
                'Message': f'CAUTION: Elevated risk over 8 hours, probability = {prob_8h*100:.1f}%',
                'Recipients': 'Engineering Team (Email)',
                'Delivery Method': 'üìß Email to ops-team@company.com',
                'Action Required': 'Review dashboard, plan capacity if needed',
                'Escalation': 'None (informational)'
            })

        # Per-server alerts
        for server_name, server_pred in server_preds.items():
            risk_score = calculate_server_risk_score(server_pred)

            if risk_score >= 70:
                # Get profile
                profile = 'unknown'
                if server_name.startswith('ppml'):
                    profile = 'ML Compute'
                elif server_name.startswith('ppdb'):
                    profile = 'Database'
                elif server_name.startswith('ppweb'):
                    profile = 'Web/API'
                elif server_name.startswith('pprisk'):
                    profile = 'Risk Analytics'
                elif server_name.startswith('ppetl'):
                    profile = 'Data Ingest'
                else:
                    profile = 'Generic'

                alerts_to_send.append({
                    'Severity': 'üî¥ P1 - Critical' if risk_score >= 85 else 'üü† P2 - Warning',
                    'Type': f'Server ({profile})',
                    'Message': f'{server_name}: Critical resource exhaustion predicted (Risk: {risk_score:.0f}/100)',
                    'Recipients': 'On-Call Engineer' if risk_score >= 85 else 'Server Team',
                    'Delivery Method': 'üìû PagerDuty' if risk_score >= 85 else 'üí¨ Slack #server-ops',
                    'Action Required': 'Check server health, trigger auto-remediation if available',
                    'Escalation': '15 min ‚Üí Senior Engineer' if risk_score >= 85 else 'None'
                })

        if alerts_to_send:
            st.markdown(f"### üîî {len(alerts_to_send)} Alerts Would Be Sent")

            df_alerts = pd.DataFrame(alerts_to_send)
            st.dataframe(df_alerts, width='stretch', hide_index=True)

            st.divider()

            # Alert summary
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                p1_count = len([a for a in alerts_to_send if 'P1' in a['Severity']])
                st.metric("P1 (Critical)", p1_count)

            with col2:
                p2_count = len([a for a in alerts_to_send if 'P2' in a['Severity']])
                st.metric("P2 (Warning)", p2_count)

            with col3:
                p3_count = len([a for a in alerts_to_send if 'P3' in a['Severity']])
                st.metric("P3 (Caution)", p3_count)

            with col4:
                pagerduty_count = len([a for a in alerts_to_send if 'PagerDuty' in a['Recipients']])
                st.metric("PagerDuty Pages", pagerduty_count)

        else:
            st.success("‚úÖ No alerts required - All systems healthy!")

        st.divider()

        # Alert Routing Matrix
        st.markdown("### üìã Alert Routing Matrix")

        routing_matrix = pd.DataFrame({
            'Severity': ['üî¥ P1 - Critical', 'üü† P2 - Warning', 'üü° P3 - Caution', 'üü¢ P4 - Info'],
            'Threshold': ['Risk ‚â• 85 OR Prob30m > 70%', 'Risk 70-85 OR Prob30m 40-70%', 'Risk 40-70 OR Prob8h > 50%', 'Risk < 40'],
            'Initial Contact': ['On-Call Engineer (PagerDuty)', 'Server Team (Slack)', 'Engineering Team (Email)', 'Dashboard Only (Log)'],
            'Methods': ['Phone + SMS + App', 'Slack + Email', 'Email only', 'Log only'],
            'Response SLA': ['15 minutes', '30 minutes', '2 hours', 'Next business day'],
            'Escalation Path': ['15m ‚Üí Senior ‚Üí 30m ‚Üí Director', '30m ‚Üí On-Call', 'None', 'None']
        })

        st.dataframe(routing_matrix, width='stretch', hide_index=True)

        st.divider()

        # Integration Details
        st.markdown("### üîå Integration Points")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Immediate Alerting (Phase 1)**:
            - ‚úÖ PagerDuty integration (API)
            - ‚úÖ Slack webhooks (#ops-alerts, #server-ops)
            - ‚úÖ Email (SMTP to distribution lists)
            - ‚úÖ Dashboard notifications

            **Delivery Time**: < 30 seconds from prediction
            """)

        with col2:
            st.markdown("""
            **Advanced Features (Phase 2)**:
            - üîÑ SMS notifications (Twilio)
            - üîÑ Microsoft Teams integration
            - üîÑ ServiceNow ticket creation
            - üîÑ Mobile app push notifications

            **Intelligent Routing**: Context-aware escalation
            """)

        st.divider()

        # Alert Suppression
        st.markdown("### üîá Intelligent Alert Suppression")

        st.markdown("""
        **Smart Features** (Reduce Alert Fatigue):

        1. **Deduplication**: Same server, same issue ‚Üí single alert (no flooding)
        2. **Grouping**: Multiple servers in same profile degrading ‚Üí grouped alert
        3. **Scheduled Maintenance**: Suppress alerts during maintenance windows
        4. **Auto-Remediation Active**: Suppress alerts if auto-fix is already running
        5. **Escalation Delays**: Progressive escalation only if no acknowledgment

        **Result**: 80% reduction in alert noise, 95% increase in signal-to-noise ratio
        """)

        st.divider()

        # Implementation Note
        st.info("""
        **üí° POC Implementation Note:**

        This tab demonstrates intelligent alerting capabilities. Production implementation would include:

        - **Multi-channel integration**: PagerDuty, Slack, Email, SMS, Teams, ServiceNow
        - **Context-aware routing**: Profile-based escalation (e.g., DB issues go to DBA team)
        - **Alert lifecycle tracking**: From trigger ‚Üí acknowledgment ‚Üí resolution
        - **On-call schedule integration**: Route to current on-call engineer automatically
        - **Alert suppression rules**: Prevent alert storms during cascading incidents
        - **Feedback loop**: Track alert accuracy, adjust thresholds based on false positive rate

        **Impact**: Reduces alert fatigue by 80%, improves response time by 60%, ensures critical issues never go unnoticed.
        """)

    else:
        st.info("Connect to daemon to see alerting strategy")

# =============================================================================
# TAB 8: ADVANCED
# =============================================================================

with tab8:
    st.subheader("‚öôÔ∏è Advanced Settings & Diagnostics")

    # System Info
    st.markdown("### System Information")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**Dashboard**")
        st.code(f"""
Python Version: 3.10+
Streamlit Version: {st.__version__}
Session Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
History Size: {len(st.session_state.history)} entries
        """)

    with col2:
        st.markdown("**Daemon**")
        if st.session_state.daemon_connected:
            health = client.check_health()
            health_data = health.get('data', {})
            st.code(f"""
URL: {daemon_url}
Status: Connected ‚úÖ
Model Loaded: {health_data.get('model_loaded', 'Unknown')}
Uptime: {health_data.get('uptime', 'Unknown')}
            """)
        else:
            st.code(f"""
URL: {daemon_url}
Status: Not Connected ‚ùå
            """)

    st.divider()

    # Alert Thresholds
    st.markdown("### Alert Thresholds")

    st.info("üöß Alert threshold configuration coming soon")

    col1, col2 = st.columns(2)

    with col1:
        st.number_input("CPU Warning Threshold (%)", value=70, min_value=0, max_value=100)
        st.number_input("Memory Warning Threshold (%)", value=80, min_value=0, max_value=100)

    with col2:
        st.number_input("CPU Critical Threshold (%)", value=90, min_value=0, max_value=100)
        st.number_input("Memory Critical Threshold (%)", value=95, min_value=0, max_value=100)

    st.divider()

    # Debug Info
    with st.expander("üîç Debug Information"):
        st.markdown("**Session State**")
        st.json({
            'daemon_url': st.session_state.daemon_url,
            'daemon_connected': st.session_state.daemon_connected,
            'refresh_interval': st.session_state.refresh_interval,
            'history_size': len(st.session_state.history),
            'last_update': str(st.session_state.last_update)
        })

        if predictions:
            st.markdown("**Latest Predictions (Raw)**")
            st.json(predictions)

# =============================================================================
# TAB 9: ROADMAP
# =============================================================================

with tab9:
    st.subheader("üó∫Ô∏è Future Roadmap")
    st.markdown("**POC Success ‚Üí Production Excellence**: Planned enhancements for world-class monitoring")

    st.info("""
    **Philosophy**: This demo is already impressive. These enhancements would make it a **market-leading predictive monitoring platform**
    that competes with Datadog, New Relic, and Dynatrace.
    """)

    # Phase Overview
    st.markdown("### üìÖ Implementation Phases")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Phase 1", "5 Features", help="Production Essentials (Months 1-3)")
    with col2:
        st.metric("Phase 2", "5 Features", help="Scale & Reliability (Months 4-6)")
    with col3:
        st.metric("Phase 3", "5 Features", help="Advanced Automation (Months 7-12)")
    with col4:
        st.metric("Phase 4", "6 Features", help="Polish & Differentiation (Year 2)")

    st.divider()

    # Phase 1: Production Essentials
    with st.expander("üöÄ **Phase 1: Production Essentials** (Next 3 Months)", expanded=True):
        st.markdown("""
        ### 1. Automated Retraining Pipeline ‚≠ê‚≠ê‚≠ê
        **Priority**: HIGH | **Effort**: 2-3 weeks | **Value**: Production-critical

        Automatically detect fleet changes and retrain model when needed.

        **Features**:
        - Fleet drift monitoring (new/sunset servers detected)
        - Unknown prediction rate tracking
        - Automatic dataset regeneration from live metrics
        - Scheduled retraining workflows (nightly/weekly)
        - Blue-green model deployment with validation
        - Automatic rollback on validation failure

        **Business Value**: Zero-touch model maintenance, always-accurate predictions, scales to 1000+ servers

        ---

        ### 2. Action Recommendation System ‚≠ê‚≠ê‚≠ê
        **Priority**: HIGH | **Effort**: 4-6 weeks | **Value**: Game-changer

        Context-aware recommendations for predicted issues.

        **Recommendation Types**:
        - **Immediate Actions** (0-2h): "Scale web tier +2 servers", "Restart hung process", "Clear cache"
        - **Short-Term Actions** (2-8h): "Schedule deployment rollback", "Increase connection pool"
        - **Long-Term Actions** (1-7 days): "Optimize slow query", "Add database index"
        - **Preventive Actions**: "Schedule maintenance before predicted spike"

        **Confidence Scoring**: Action effectiveness, risk level, time required, reversibility

        **Business Value**: Reduce decision paralysis, empower junior SAs, faster MTTR by 70%

        ---

        ### 3. Advanced Dashboard Intelligence ‚≠ê‚≠ê‚≠ê
        **Priority**: HIGH | **Effort**: 3-4 weeks | **Value**: Better UX

        **Smart Features**:
        - **Predictive Insights**: "3 servers predicted to degrade in next 8 hours - ppweb001 likely CPU bottleneck (89% confidence)"
        - **What-If Analysis**: "What if I scale up this server?" ‚Üí Show prediction changes
        - **Trend Analysis**: "CPU trending up 12% week-over-week", "Memory leak detected"
        - **Intelligent Sorting**: Auto-prioritize by risk, group by profile, filter by confidence
        - **Comparison View**: Server vs server, current vs predicted, different scenarios

        **Business Value**: Faster decisions, reduced cognitive load, proactive operations

        ---

        ### 4. Alerting Integration ‚≠ê‚≠ê‚≠ê
        **Priority**: HIGH | **Effort**: 1-2 weeks | **Value**: Essential

        **Integrations**:
        - PagerDuty (create incidents for high-confidence predictions)
        - Slack (send notifications to channels)
        - Microsoft Teams (adaptive cards)
        - Email (digest emails)
        - JIRA/ServiceNow (auto-create tickets)

        **Smart Alerting**: Only actionable predictions, confidence-based routing, time-to-impact urgency, deduplication

        **Business Value**: Integrate with existing workflows, reduce alert fatigue, right alert at right time

        ---

        ### 5. Explainable AI (XAI) ‚≠ê‚≠ê‚≠ê
        **Priority**: HIGH | **Effort**: 3-4 weeks | **Value**: Trust & transparency

        **Techniques**:
        - SHAP values (feature importance)
        - Attention weights (which timesteps matter most)
        - Counterfactual explanations ("if X was lower, prediction would change")

        **Example Output**:
        ```
        Prediction: ppweb001 CPU ‚Üí 92% in 6 hours

        Explanation:
        ‚≠ê‚≠ê‚≠ê Recent trend (last 4h): +15% CPU increase
        ‚≠ê‚≠ê Historical pattern: Morning spike approaching (8 AM in 6h)
        ‚≠ê‚≠ê Similar servers: ppweb002/003 also trending up
        ‚≠ê Deployment correlation: New release 2h ago
        ```

        **Business Value**: Build trust, debug model errors, regulatory compliance, educational for SAs
        """)

    # Phase 2: Scale & Reliability
    with st.expander("üìà **Phase 2: Scale & Reliability** (Months 4-6)"):
        st.markdown("""
        ### 6. Online Learning During Inference
        Model learns from recent data without full retraining. Adapt to seasonal patterns automatically.

        ### 7. Model Performance Monitoring
        Track accuracy over time, confidence calibration, false positive/negative rates. Identify degradation early.

        ### 8. Multi-Region / Multi-Cluster Support
        Region selector in dashboard, cross-region anomaly correlation, region-specific models.

        ### 9. Root Cause Analysis (RCA) Engine
        Automatically identify likely causes: correlation analysis, dependency analysis, historical pattern matching, change correlation.

        ### 10. Observability Platform Integration
        Integrate with Datadog, New Relic, Prometheus. Ingest metrics, export predictions, correlate with logs/traces.
        """)

    # Phase 3: Advanced Automation
    with st.expander("ü§ñ **Phase 3: Advanced Automation** (Months 7-12)"):
        st.markdown("""
        ### 11. Automated Environment Fixes
        Auto-scaling triggers, service restarts, load balancer adjustments, cache clearing, circuit breaker activation.

        **Safety**: Confidence thresholds, approval workflows, rollback capability, audit logging, rate limiting.

        ### 12. Automated Runbook Execution
        Execute common remediation actions automatically: restart service, clear cache, scale service, rollback deployment.

        ### 13. Transfer Learning for New Environments
        Use pre-trained model for new customers/environments. Deploy predictions day 1 vs weeks of training.

        ### 14. Multi-Metric Predictions
        Predict CPU, memory, disk, network, latency simultaneously. Detect correlation issues.

        ### 15. Infrastructure-as-Code Integration
        Trigger infrastructure changes: Terraform, Ansible, Kubernetes, AWS Auto Scaling, CloudFormation.
        """)

    # Phase 4: Polish & Differentiation
    with st.expander("‚ú® **Phase 4: Polish & Differentiation** (Year 2)"):
        st.markdown("""
        ### 16. Mobile Dashboard
        Responsive design, push notifications, quick actions, simplified view, dark mode for on-call.

        ### 17. Historical Trend Dashboard
        30/60/90-day trends, capacity forecasting, cost projection, seasonality detection, growth rate analysis.

        ### 18. A/B Testing for Model Updates
        Deploy new model to 10% of fleet, compare vs old model, measure accuracy delta, gradual rollout.

        ### 19. Cloud Cost Predictions
        Predict next month's bill, identify optimization opportunities, forecast cost impact of scaling.

        ### 20. Executive Dashboard
        High-level metrics: system health score, incidents prevented, cost savings, MTTD/MTTR, uptime %.

        ### 21. Anomaly Detection Beyond Predictions
        Isolation Forest, Autoencoders, statistical process control. Catch issues predictions might miss.
        """)

    st.divider()

    # Competitive Positioning
    st.markdown("### üéØ Competitive Positioning")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        **vs. Datadog / New Relic**:
        - ‚úÖ 8-hour prediction horizon (they only alert on current state)
        - ‚úÖ Interactive scenario simulation (they're read-only)
        - ‚úÖ Action recommendations (they just show metrics)
        - ‚úÖ Profile-based transfer learning (they treat all servers the same)
        """)

    with col2:
        st.markdown("""
        **vs. Dynatrace**:
        - ‚úÖ Transparent ML (we explain predictions, they're black box)
        - ‚úÖ Customizable thresholds (we adapt to your environment)
        - ‚úÖ Open architecture (not vendor lock-in)
        - ‚úÖ Faster time-to-value (weeks not years)
        """)

    st.divider()

    # Success Metrics
    st.markdown("### üìä Success Metrics")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("""
        **Technical Metrics**:
        - Prediction accuracy > 85%
        - False positive rate < 10%
        - Inference latency < 2s
        - System uptime > 99.9%
        """)

    with col2:
        st.markdown("""
        **Business Metrics**:
        - Issues prevented/month
        - Cost savings (downtime + optimization)
        - Time saved for SAs
        - Faster MTTR
        """)

    with col3:
        st.markdown("""
        **Adoption Metrics**:
        - Daily active users
        - Predictions acted upon (%)
        - User satisfaction score
        - Feature usage rates
        """)

    st.divider()

    # Call to Action
    st.success("""
    ### üöÄ Next Steps

    This roadmap transforms an impressive demo into a **market-leading predictive monitoring platform**. The key is:

    1. ‚úÖ **Start with the demo** (already killer - you're seeing it now!)
    2. **Validate with real users** (get feedback from SAs, app owners, management)
    3. **Prioritize ruthlessly** (build what matters most based on user needs)
    4. **Ship iteratively** (release Phase 1 features one at a time, learn fast)

    **The interactive scenario system is your differentiator.** Everything else enhances that core value proposition:
    **predict issues before they happen, and tell people what to do about it**.
    """)

    st.info("""
    **üìÑ Full Roadmap Document**: See `Docs/FUTURE_ROADMAP.md` for complete technical details, effort estimates,
    implementation priorities, and business value analysis for all 21 planned features.
    """)

# =============================================================================
# AUTO-REFRESH (Non-blocking)
# =============================================================================

if auto_refresh and st.session_state.daemon_connected:
    # Check if enough time has passed since last update
    current_time = datetime.now()

    if st.session_state.last_update:
        time_since_update = (current_time - st.session_state.last_update).total_seconds()

        # In demo mode, refresh every 1 second
        if st.session_state.demo_running:
            if time_since_update >= 1:
                st.rerun()
        # Normal mode, refresh at configured interval
        elif time_since_update >= refresh_interval:
            st.rerun()
    else:
        # First run, trigger immediate refresh
        st.rerun()

# =============================================================================
# FOOTER
# =============================================================================

st.divider()
st.caption("üîÆ TFT Monitoring Dashboard | Built with Streamlit | Powered by Temporal Fusion Transformer")
