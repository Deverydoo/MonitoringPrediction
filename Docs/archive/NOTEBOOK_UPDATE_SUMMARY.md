# _StartHere.ipynb Update Summary

**Date:** 2025-10-08
**File:** [_StartHere.ipynb](_StartHere.ipynb)

---

## üéØ Update Overview

Completely rewrote the notebook to provide a streamlined, production-ready pipeline from data generation through model training to live dashboards.

---

## üìã New Notebook Structure

### **Cell 1: Import and Setup**
- Loads configuration
- Shows system parameters
- Sets up environment

### **Cell 2: Environment Validation**
- Checks all dependencies
- Validates PyArrow (Parquet support)
- Reports GPU availability

### **Cell 3: System Status Check**
- Shows existing datasets (Parquet-first)
- Lists trained models
- Device information

---

## üé¨ **DEMO MODE** (Cells 4-5)

### **Cell 4: Generate Demo Dataset**
```python
DEMO_DURATION_MIN = 5      # 5-minute simulation
DEMO_FLEET_SIZE = 10       # 10 servers
DEMO_SEED = 42             # Reproducible
```

**Features:**
- Predictable 4-phase incident pattern
- 5-minute duration perfect for testing
- ~600 data points
- Parquet output

**Incident Timeline:**
- 0:00-1:30 ‚Üí Stable baseline
- 1:30-2:30 ‚Üí Gradual escalation
- 2:30-3:30 ‚Üí Incident peak
- 3:30-5:00 ‚Üí Recovery

### **Cell 5: Run Demo Dashboard**
- Interactive visualization
- 5-second refresh rate
- Shows incident evolution
- Anomaly highlighting
- Press Ctrl+C to stop

---

## üè≠ **PRODUCTION MODE** (Cells 6-8)

### **Cell 6: Generate Production Dataset**
```python
TRAINING_HOURS = 720  # 30 days (recommended)
# OR
TRAINING_HOURS = 168  # 1 week
TRAINING_HOURS = 24   # Quick test
```

**Features:**
- Realistic server profiles
- Time-based patterns (diurnal, weekly)
- Parquet format (3-5x faster)
- ~130,000 samples for 30 days

### **Cell 7: Train TFT Model**
```python
TRAINING_EPOCHS = 20       # Default
PER_SERVER_MODE = False    # Fleet-wide or per-server
```

**Training Features:**
- Automatic GPU acceleration
- Early stopping (patience: 8)
- Learning rate monitoring
- Checkpoint saving
- TensorBoard logging
- Safetensors model format

**Modes:**
- **Fleet-wide**: Single model for all servers (faster, 10-15 min)
- **Per-server**: Specialized models (better accuracy, 30+ min)

### **Cell 8: Inspect Trained Model**
- Lists all trained models
- Shows latest model details
- File sizes and formats
- Verifies Safetensors format

---

## üìä **DASHBOARDS** (Cells 9, 11)

### **Cell 9: Production Dashboard**
- Uses training data
- Configurable runtime and refresh
- Fleet-wide metrics
- Anomaly detection
- Server-level trends

### **Cell 11: One-Command Demo**
- Alternative approach
- Combines generation + dashboard
- Uses `run_demo.py` function
- Perfect for quick demos

---

## üìö **REFERENCE** (Cells 10, 12)

### **Cell 10: Configuration Reference**
Shows all key config values:
- Data generation settings
- Model architecture
- Training parameters
- Prediction horizons
- Directory structure

### **Cell 12: Final Status & Next Steps**
- Complete system status
- Next action suggestions
- Command-line reference
- Documentation links

---

## üöÄ Usage Workflows

### **Quick Demo (5 minutes)**
Run cells in order:
1. Cell 1 - Import
2. Cell 2 - Validate environment
3. Cell 4 - Generate demo data
4. Cell 5 - Run demo dashboard

**Total time:** ~5 minutes

---

### **Production Training (30+ minutes)**
Run cells in order:
1. Cell 1-3 - Setup and status
2. Cell 6 - Generate 30 days of data (adjust `TRAINING_HOURS`)
3. Cell 7 - Train model (adjust `TRAINING_EPOCHS`)
4. Cell 8 - Inspect model
5. Cell 9 - Monitor with dashboard

**Total time:** 30-60 minutes depending on data size

---

### **Model Development**
1. Cell 3 - Check current status
2. Cell 6 - Generate fresh data
3. Cell 7 - Train with different parameters
4. Cell 8 - Compare models
5. Repeat

---

## üéØ Key Features

### **1. Dual Pipeline Support**
- **Demo**: Fast 5-minute simulation for testing
- **Production**: Full-scale training with configurable duration

### **2. Parquet-First Approach**
- All data generation uses Parquet
- 3-5x faster than CSV
- Smaller file sizes
- Better compression

### **3. Flexible Training**
- Fleet-wide or per-server models
- Configurable epochs and batch size
- GPU auto-detection
- Early stopping

### **4. Live Dashboards**
- Demo dashboard with incident pattern
- Production dashboard with training data
- Real-time metrics
- Anomaly detection

### **5. Configuration Integration**
- All cells use `CONFIG` from config.py
- Easy parameter adjustment
- Consistent defaults
- Single source of truth

---

## üìä Cell-by-Cell Summary

| Cell | Type | Purpose | Duration |
|------|------|---------|----------|
| 0 | Markdown | Introduction and overview | - |
| 1 | Code | Import and setup | < 1 sec |
| 2 | Code | Environment validation | 1-2 sec |
| 3 | Code | System status check | 1-2 sec |
| 4 | Code | Demo data generation | 10-30 sec |
| 5 | Code | Demo dashboard | 5 min |
| 6 | Code | Production data generation | 1-10 min |
| 7 | Code | Model training | 10-30 min |
| 8 | Code | Model inspection | < 1 sec |
| 9 | Code | Production dashboard | 10+ min |
| 10 | Code | Configuration reference | < 1 sec |
| 11 | Code | One-command demo | 5 min |
| 12 | Code | Final status | 1-2 sec |

**Total cells:** 13 (vs. 18 before)
**Removed:** 5 outdated/redundant cells

---

## ‚úÖ What Was Removed

1. **Old generate_dataset calls** - Replaced with proper imports
2. **JSON-based prediction examples** - Outdated, system is Parquet-first
3. **Matplotlib visualization cell** - Redundant with dashboards
4. **Old dashboard import** - Using refactored version
5. **Empty cells** - Cleanup

---

## üîß Configuration Defaults

All configurable via variables at top of cells:

### Demo Mode
```python
DEMO_DURATION_MIN = 5
DEMO_FLEET_SIZE = 10
DEMO_SEED = 42
```

### Production Mode
```python
TRAINING_HOURS = 720        # Adjust based on needs
TRAINING_EPOCHS = 20        # Adjust for accuracy
PER_SERVER_MODE = False     # True for specialized models
```

### Dashboards
```python
DASHBOARD_RUNTIME_MIN = 10
DASHBOARD_REFRESH_SEC = 10
```

---

## üí° Tips & Best Practices

### **For Quick Testing:**
```python
TRAINING_HOURS = 24
TRAINING_EPOCHS = 10
```
**Time:** ~10 minutes total

### **For Production Quality:**
```python
TRAINING_HOURS = 720
TRAINING_EPOCHS = 30
PER_SERVER_MODE = True
```
**Time:** 1-2 hours total

### **For Demos:**
- Use Cell 4 + Cell 5 (demo data + dashboard)
- Or use Cell 11 (one-command)
- Shows incident pattern clearly

### **For Development:**
- Run Cell 3 frequently to check status
- Use Cell 10 to verify configuration
- Adjust epochs to 5-10 for fast iteration

---

## üö® Common Issues & Solutions

### **Issue: Dashboard doesn't show data**
**Solution:** Ensure data was generated first (Cell 4 or Cell 6)

### **Issue: Training takes too long**
**Solution:** Reduce `TRAINING_HOURS` or `TRAINING_EPOCHS`

### **Issue: Out of memory during training**
**Solution:** Reduce `CONFIG['batch_size']` in config.py

### **Issue: No GPU detected**
**Solution:** Check CUDA installation, system will use CPU (slower)

---

## üìà Performance Expectations

### Data Generation
- **24 hours:** 10-30 seconds
- **168 hours (1 week):** 1-2 minutes
- **720 hours (30 days):** 3-5 minutes

### Model Training
- **CPU (24h data):** 15-20 minutes
- **CPU (720h data):** 45-60 minutes
- **GPU (24h data):** 5-10 minutes
- **GPU (720h data):** 15-30 minutes

### Dashboard
- **Demo:** 5 minutes (fixed)
- **Production:** User-configurable, typically 10-30 minutes

---

## üéì Learning Path

### **Beginner:**
1. Run Cells 1-3 (setup and status)
2. Run Cell 4-5 (demo)
3. Understand the incident pattern
4. Read DEMO_README.md

### **Intermediate:**
1. Complete beginner path
2. Run Cell 6 with 24 hours
3. Run Cell 7 with 10 epochs
4. Inspect model in Cell 8
5. Read REPOMAP.md

### **Advanced:**
1. Complete intermediate path
2. Generate 720 hours of data
3. Train with per-server models
4. Monitor training in TensorBoard
5. Customize config.py
6. Read training phase documentation

---

## üìö Related Documentation

- [README.md](README.md) - Main project documentation
- [REPOMAP.md](REPOMAP.md) - Complete repository map
- [DEMO_README.md](DEMO_README.md) - Demo guide
- [SETUP_DEMO.md](SETUP_DEMO.md) - Setup instructions
- [MAIN_PY_OPTIMIZATIONS.md](MAIN_PY_OPTIMIZATIONS.md) - CLI optimizations
- [config.py](config.py) - Configuration file

---

## üéâ Summary

The updated notebook provides:

‚úÖ **Clear structure** - Organized into demo/production sections
‚úÖ **Complete pipeline** - Data ‚Üí Training ‚Üí Dashboard
‚úÖ **Parquet-first** - Modern, fast data format
‚úÖ **Flexible training** - Fleet-wide or per-server
‚úÖ **Live dashboards** - Interactive visualization
‚úÖ **Well-documented** - Inline comments and markdown
‚úÖ **Configurable** - Easy parameter adjustment
‚úÖ **Production-ready** - Real-world workflows

**Total improvement:** 13 streamlined cells vs. 18 before, better organized, more powerful.

---

**Updated by:** Claude Code
**Review Status:** Ready for use
**Tested:** Structure verified, imports checked
