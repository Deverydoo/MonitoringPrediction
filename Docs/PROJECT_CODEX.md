# PROJECT CODEX - Rules & Conventions

**Version:** 1.0.0
**Status:** ‚ö†Ô∏è AUTHORITATIVE - All development must follow these rules
**Last Updated:** 2025-10-11

---

## üéØ Purpose

This document defines the immutable rules, conventions, and standards for the TFT Monitoring Prediction System. All contributors and AI assistants must follow these guidelines.

---

## üìú Core Principles

### 1. Model-First Development
> **"If it doesn't use the model, it is rejected."**

- ‚úÖ All predictions MUST come from the TFT model
- ‚ùå No heuristics, no fallback logic, no "smart guesses"
- ‚úÖ Heuristics ONLY acceptable for graceful degradation when daemon unavailable
- ‚úÖ Always prefer model predictions over any other approach

### 2. Contract-Driven Development
> **DATA_CONTRACT.md is law.**

- ‚úÖ All schema changes must update DATA_CONTRACT.md FIRST
- ‚úÖ All code must validate against contract before processing
- ‚úÖ Breaking changes require version bump and migration guide
- ‚ùå Never modify schemas without updating contract

### 3. Profile-Based Architecture
> **Servers are grouped by role, not treated individually.**

- ‚úÖ All training data must include profile column
- ‚úÖ Model must use profile as static_categorical
- ‚úÖ New servers inherit profile patterns automatically
- ‚ùå Never train without profile feature enabled

### 4. Parquet-First Data
> **JSON is legacy, Parquet is standard.**

- ‚úÖ Always use Parquet for training data (10-100x faster)
- ‚úÖ CSV acceptable for small datasets (<10K rows)
- ‚ùå JSON only for configuration files, not data
- ‚úÖ All generators must output Parquet by default

### 5. Hash-Based Stability
> **Server IDs must be deterministic and stable.**

- ‚úÖ Use SHA256 hash-based encoding for all server names
- ‚ùå Never use sequential encoding (0,1,2,3...)
- ‚úÖ Save server_mapping.json with every model
- ‚úÖ Always decode server IDs back to names in output

---

## üèóÔ∏è Architecture Rules

### File Structure Standards

**Core Modules:**
```
‚îú‚îÄ‚îÄ _StartHere.ipynb          # PRIMARY INTERFACE - Use this first
‚îú‚îÄ‚îÄ main.py                   # CLI interface
‚îú‚îÄ‚îÄ config.py                 # SINGLE SOURCE for all config
‚îú‚îÄ‚îÄ metrics_generator.py      # Data generation
‚îú‚îÄ‚îÄ tft_trainer.py            # Model training
‚îú‚îÄ‚îÄ tft_inference.py          # Inference daemon
‚îú‚îÄ‚îÄ tft_dashboard_web.py      # Web dashboard (ONLY dashboard)
‚îú‚îÄ‚îÄ server_encoder.py         # Server encoding utility
‚îú‚îÄ‚îÄ data_validator.py         # Contract validation
‚îî‚îÄ‚îÄ common_utils.py           # Shared utilities
```

**Data Structure:**
```
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ server_metrics.parquet      # Training data
‚îÇ   ‚îú‚îÄ‚îÄ metrics_metadata.json       # Metadata
‚îÇ   ‚îî‚îÄ‚îÄ server_mapping.json         # Name‚ÜîID mapping
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ tft_model_YYYYMMDD_HHMMSS/
‚îÇ       ‚îú‚îÄ‚îÄ model.safetensors       # Weights
‚îÇ       ‚îú‚îÄ‚îÄ config.json             # Architecture
‚îÇ       ‚îú‚îÄ‚îÄ training_info.json      # Metadata
‚îÇ       ‚îî‚îÄ‚îÄ server_mapping.json     # CRITICAL for inference
‚îî‚îÄ‚îÄ Docs/
    ‚îú‚îÄ‚îÄ ESSENTIAL_RAG.md            # Quick reference
    ‚îú‚îÄ‚îÄ PROJECT_CODEX.md            # This file
    ‚îú‚îÄ‚îÄ DATA_CONTRACT.md            # Schema spec
    ‚îú‚îÄ‚îÄ SERVER_PROFILES.md          # Profile system
    ‚îî‚îÄ‚îÄ INDEX.md                    # Navigation
```

### Naming Conventions

**Server Names:**
- ML Compute: `ppml####` (e.g., ppml0001, ppml0099)
- Database: `ppdb###` (e.g., ppdb001, ppdb150)
- Web/API: `ppweb###` (e.g., ppweb001, ppweb500)
- Conductor: `ppcon##` (e.g., ppcon01, ppcon99)
- Data Ingest: `ppetl###` (e.g., ppetl001, ppetl100)
- Risk Analytics: `pprisk###` (e.g., pprisk001, pprisk050)
- Generic: `ppgen###` (e.g., ppgen001, ppgen100)

**File Naming:**
- Models: `tft_model_YYYYMMDD_HHMMSS/`
- Training data: `server_metrics.parquet` (standardized)
- Metadata: `metrics_metadata.json`, `training_info.json`
- Mappings: `server_mapping.json` (never rename)

**Variable Naming:**
- Column names: snake_case (`cpu_pct`, `mem_pct`, `disk_io_mb_s`)
- Python variables: snake_case (`server_name`, `time_idx`)
- Classes: PascalCase (`ServerEncoder`, `DataValidator`)
- Constants: UPPER_SNAKE (`VALID_STATES`, `CONTRACT_VERSION`)

---

## üîí Schema Rules

### Immutable Columns (REQUIRED)
```python
REQUIRED_COLUMNS = [
    'timestamp',      # datetime - ISO8601 format
    'server_name',    # string - Original hostname
    'cpu_pct',        # float - 0.0 to 100.0
    'mem_pct',        # float - 0.0 to 100.0
    'disk_io_mb_s',   # float - 0.0+
    'latency_ms',     # float - 0.0+
    'state',          # string - One of VALID_STATES
    'profile'         # string - One of 7 profiles (NEW)
]
```

### Immutable States (EXACTLY 8)
```python
VALID_STATES = [
    'critical_issue',   # Severe problems
    'healthy',          # Normal operations
    'heavy_load',       # High utilization
    'idle',            # Low activity
    'maintenance',      # Scheduled maintenance
    'morning_spike',    # Peak usage periods
    'offline',         # Server unavailable
    'recovery'          # Post-incident recovery
]
```

### Immutable Profiles (EXACTLY 7)
```python
VALID_PROFILES = [
    'ml_compute',       # ML training nodes
    'database',         # Oracle, Postgres, MongoDB
    'web_api',          # REST endpoints, gateways
    'conductor_mgmt',   # Job scheduling
    'data_ingest',      # Kafka, Spark, ETL
    'risk_analytics',   # VaR, Monte Carlo
    'generic'           # Fallback
]
```

**Rule:** Adding/removing states or profiles requires:
1. Update DATA_CONTRACT.md
2. Version bump (e.g., 1.0.0 ‚Üí 2.0.0)
3. Regenerate ALL training data
4. Retrain ALL models
5. Update ALL documentation

---

## üß™ Validation Rules

### Pre-Training Validation
```python
# REQUIRED before training
validator = DataValidator(strict=True)
is_valid, errors, warnings = validator.validate_schema(df)

if not is_valid:
    print(f"[ERROR] Validation failed: {errors}")
    sys.exit(1)

if warnings:
    print(f"[WARNING] {warnings}")
    # Continue but log warnings
```

### Pre-Inference Validation
```python
# REQUIRED before inference
is_compatible, errors = validator.validate_model_compatibility(
    model_dir, input_df
)

if not is_compatible:
    print(f"[ERROR] Model incompatible: {errors}")
    sys.exit(1)
```

### Model Loading Validation
```python
# REQUIRED when loading model
mapping_file = model_dir / "server_mapping.json"
if not mapping_file.exists():
    raise FileNotFoundError(
        "server_mapping.json not found. "
        "Retrain model with updated tft_trainer.py"
    )
```

---

## üìä Training Rules

### Data Generation Standards
```python
# REQUIRED parameters
--hours >= 24          # Minimum 1 day
--hours = 720          # RECOMMENDED for production (30 days)
--offline_mode dense   # REQUIRED for realistic data
--out_dir ./training/  # Standardized output location
```

### Fleet Composition Standards
**Default (90 servers):**
- WEB_API: 25 (28%)
- ML_COMPUTE: 20 (22%)
- DATABASE: 15 (17%)
- DATA_INGEST: 10 (11%)
- RISK_ANALYTICS: 8 (9%)
- GENERIC: 7 (8%)
- CONDUCTOR_MGMT: 5 (5%)

**Rule:** Production fleets should maintain realistic proportions

### Training Requirements
```python
# MINIMUM for viable model
--epochs >= 5

# RECOMMENDED for production
--epochs >= 20

# REQUIRED features
--static_categoricals = ['profile']  # Transfer learning
--categorical_encoders = {
    'server_id': NaNLabelEncoder(add_nan=True),
    'state': NaNLabelEncoder(add_nan=True),
    'profile': NaNLabelEncoder(add_nan=True)
}
```

### Training Output Requirements
**MUST save:**
1. `model.safetensors` - Model weights
2. `config.json` - Architecture config
3. `training_info.json` - Metadata with contract version
4. `server_mapping.json` - CRITICAL for inference

**Rule:** Training fails if any of these files are not saved

---

## üîÑ Inference Rules

### Daemon Requirements
```python
# REQUIRED for production
--daemon              # Run as background service
--port 8000          # Standard port
--model-dir ./models/latest/  # Must have server_mapping.json
```

### API Endpoint Standards
```
GET  /health          # Must return {"status": "ok", "model_loaded": bool}
GET  /status          # Must return model info, uptime
GET  /predictions/current  # Must decode server names
GET  /alerts/active   # Must include server names (not IDs)
WS   /ws/predictions  # Future: streaming predictions
```

### Prediction Output Format
```python
{
    'server_name': 'ppml0015',  # DECODED name, not ID
    'profile': 'ml_compute',     # Profile for context
    'prediction_time': 'ISO8601',
    'predictions': {
        '30min': {'cpu_pct': 65.2, 'mem_pct': 72.1, ...},
        '1hr': {...},
        '8hr': {...}
    },
    'quantiles': {
        'p10': {...},  # Lower bound
        'p50': {...},  # Median
        'p90': {...}   # Upper bound
    }
}
```

**Rule:** Never return server IDs in final output, always decode

---

## üé® Dashboard Rules

### Web Dashboard Standards
- ‚úÖ Use `tft_dashboard_web.py` (Streamlit)
- ‚ùå Terminal dashboards deprecated
- ‚úÖ Connect to daemon via REST API
- ‚úÖ Include demo modes (Healthy/Degrading/Critical)
- ‚úÖ Display server names (not IDs)
- ‚úÖ Show profile information
- ‚úÖ Real-time updates (configurable refresh rate)

### Visualization Standards
**Required Panels:**
1. Overview - Fleet health summary
2. Heatmap - Visual risk grid
3. Top Servers - Problem servers with predictions
4. Historical - Trend analysis
5. Advanced - Settings, debug, model info

**Color Coding:**
- üü¢ Green: Healthy (risk < 0.3)
- üü° Yellow: Warning (risk 0.3-0.7)
- üî¥ Red: Critical (risk > 0.7)

---

## üß© Integration Rules

### Python Environment
```bash
# REQUIRED
conda activate py310

# REQUIRED packages
torch>=2.0
lightning>=2.0
pytorch-forecasting
safetensors
pandas
pyarrow          # For Parquet
streamlit        # For dashboard
fastapi          # For daemon
uvicorn          # For daemon
```

### Import Standards
```python
# Standard library first
import json
import sys
from pathlib import Path

# Third-party second
import pandas as pd
import torch
from pytorch_forecasting import TimeSeriesDataSet

# Local modules third
from config import *
from server_encoder import ServerEncoder
from data_validator import DataValidator
```

---

## üìù Documentation Rules

### Required Documentation
**Every new feature requires:**
1. Update ESSENTIAL_RAG.md
2. Update DATA_CONTRACT.md (if schema changes)
3. Update PROJECT_CODEX.md (if new rules)
4. Create/update specific guide (e.g., SERVER_PROFILES.md)
5. Update INDEX.md navigation

### Session Summary Requirements
**At end of every session, create:**
- `SESSION_YYYY-MM-DD_SUMMARY.md`
- Include: start/end time, duration, accomplishments
- Update: PROJECT_SUMMARY.md change notes
- List: modified files, next steps

### Documentation Style
- Use emoji sparingly (‚úÖ ‚ùå ‚ö†Ô∏è üîÑ only)
- Include code examples for complex concepts
- Provide "Before/After" comparisons for changes
- Include quick reference sections
- Mark deprecated features clearly

---

## üö® Error Handling Rules

### Validation Errors
```python
# ALWAYS provide context
raise ValueError(
    f"Invalid state '{state}'. "
    f"Must be one of: {VALID_STATES}. "
    f"See DATA_CONTRACT.md for details."
)
```

### File Not Found Errors
```python
# ALWAYS provide fix instructions
raise FileNotFoundError(
    f"server_mapping.json not found in {model_dir}. "
    f"This file is required for decoding predictions. "
    f"Fix: Retrain model with updated tft_trainer.py"
)
```

### Dimension Mismatch Errors
```python
# ALWAYS include contract info
raise RuntimeError(
    f"State count mismatch: model has {model_states}, "
    f"contract requires {len(VALID_STATES)}. "
    f"Contract version: {CONTRACT_VERSION}. "
    f"Fix: Retrain model with current contract."
)
```

**Rule:** All errors must include:
1. What went wrong
2. Why it matters
3. How to fix it
4. Relevant documentation reference

---

## üîê Security Rules

### Data Protection
- ‚ùå Never commit training data to git
- ‚ùå Never commit model weights to git (use Git LFS if needed)
- ‚úÖ Use `.gitignore` for `training/`, `models/`, `demo_data/`
- ‚úÖ Sanitize server names in public documentation

### API Security
- ‚úÖ Validate all inputs before processing
- ‚úÖ Rate limit API endpoints
- ‚úÖ Log all prediction requests
- ‚ùå Never expose raw model tensors via API

---

## üß™ Testing Rules

### Unit Testing Requirements
**Every utility module must have:**
```python
if __name__ == '__main__':
    # Test basic functionality
    # Test edge cases
    # Test error conditions
    print("‚úÖ All tests passed")
```

### Integration Testing Requirements
**Before every release:**
1. Generate fresh training data
2. Train model for 1 epoch (smoke test)
3. Start daemon, verify /health endpoint
4. Launch dashboard, verify connection
5. Test unknown server handling
6. Verify server name decoding

### Manual Testing Checklist
- [ ] Data generation produces correct schema
- [ ] Training saves all required files
- [ ] Inference daemon starts without errors
- [ ] Dashboard connects to daemon
- [ ] Predictions decode server names correctly
- [ ] Unknown servers handled gracefully
- [ ] Demo modes work correctly

---

## üéØ Performance Rules

### Data Loading
- ‚úÖ Always use Parquet for datasets >10K rows
- ‚úÖ Use chunking for datasets >1M rows
- ‚ùå Never load entire dataset into memory if >10GB
- ‚úÖ Profile memory usage for large datasets

### Model Training
- ‚úÖ Use GPU if available (50-100x faster)
- ‚úÖ Use mixed precision (FP16/BF16) for large models
- ‚úÖ Save checkpoints every 5 epochs
- ‚úÖ Implement early stopping (patience=3)

### Inference
- ‚úÖ Batch predictions when possible
- ‚úÖ Cache common predictions (optional)
- ‚úÖ Target <100ms latency per server
- ‚ùå Never block on I/O in prediction loop

---

## üîÑ Version Control Rules

### Commit Messages
```
Format: <type>: <short description>

Types:
- feat: New feature
- fix: Bug fix
- docs: Documentation only
- refactor: Code restructuring
- perf: Performance improvement
- test: Adding tests
- chore: Maintenance

Example:
feat: Add profile-based transfer learning to TFT trainer
```

### Branch Strategy
- `main` - Production ready code
- `develop` - Integration branch
- `feature/profile-system` - Feature branches
- `hotfix/dimension-mismatch` - Urgent fixes

### What NOT to Commit
- `training/` - Training data
- `models/` - Model weights
- `demo_data/` - Demo datasets
- `.ipynb_checkpoints/` - Notebook checkpoints
- `__pycache__/` - Python cache

---

## üéì Development Workflow

### Standard Workflow
```bash
# 1. Activate environment
conda activate py310

# 2. Generate data
jupyter notebook _StartHere.ipynb  # Cell 4

# 3. Train model
# In notebook, Cell 6 (10 epochs minimum)

# 4. Validate
python data_validator.py training/server_metrics.parquet

# 5. Test inference
python tft_inference.py --daemon --port 8000

# 6. Launch dashboard
streamlit run tft_dashboard_web.py

# 7. Test end-to-end
# Use dashboard demo modes
```

### Making Schema Changes
```bash
# 1. Update contract FIRST
vim Docs/DATA_CONTRACT.md
# Bump version, document changes

# 2. Update code
# - metrics_generator.py
# - tft_trainer.py
# - tft_inference.py

# 3. Regenerate everything
rm -rf training/* models/*
jupyter notebook _StartHere.ipynb

# 4. Test thoroughly
python data_validator.py training/server_metrics.parquet
# Train, test inference, test dashboard

# 5. Document
# Update ESSENTIAL_RAG.md, create session summary
```

---

## ‚ö†Ô∏è Breaking Change Protocol

### When Breaking Changes Are Needed

**Step 1: Documentation**
1. Update DATA_CONTRACT.md
2. Bump version (1.0.0 ‚Üí 2.0.0)
3. Create MIGRATIONS.md with upgrade guide

**Step 2: Code Updates**
1. Update metrics_generator.py
2. Update tft_trainer.py
3. Update tft_inference.py
4. Update data_validator.py

**Step 3: Data Regeneration**
1. Delete old training data
2. Delete old models
3. Generate fresh data
4. Retrain models

**Step 4: Validation**
1. Run full test suite
2. Test end-to-end workflow
3. Verify dashboard integration
4. Test unknown server handling

**Step 5: Communication**
1. Update all documentation
2. Create session summary
3. Notify team of changes
4. Update README with migration guide

---

## üìä Metrics & Monitoring

### Required Metrics
**During Training:**
- Training loss per epoch
- Validation loss per epoch
- Learning rate progression
- Estimated time remaining

**During Inference:**
- Predictions per second
- Average latency
- Error rate
- Unknown server count

**Dashboard:**
- Refresh rate
- Connection status
- Model version
- Last prediction time

---

## üéØ Quality Standards

### Code Quality
- ‚úÖ Type hints for function signatures
- ‚úÖ Docstrings for all classes/functions
- ‚úÖ Error handling with context
- ‚úÖ Logging for important events
- ‚úÖ Configuration via config.py, not hardcoded

### Documentation Quality
- ‚úÖ Clear purpose statement
- ‚úÖ Prerequisites listed
- ‚úÖ Code examples included
- ‚úÖ Troubleshooting section
- ‚úÖ Last updated timestamp

### Model Quality
- ‚úÖ Training loss converges
- ‚úÖ Validation loss < 1.5x training loss
- ‚úÖ Unknown server handling tested
- ‚úÖ Profile feature enabled
- ‚úÖ All required files saved

---

## üöÄ Production Readiness Checklist

**Before Deployment:**
- [ ] Data contract validated
- [ ] Model trained with profiles
- [ ] Inference daemon tested
- [ ] Dashboard tested
- [ ] Unknown servers tested
- [ ] Error handling tested
- [ ] Performance benchmarked
- [ ] Documentation complete
- [ ] Session summary created
- [ ] Backup strategy defined

---

## üìû Quick Reference

### Contract Version
**Current:** 1.0.0
**Location:** `Docs/DATA_CONTRACT.md`

### Model Version
**Current:** 3.0.0 (Profile-Based Transfer Learning)
**Location:** `models/tft_model_*/training_info.json`

### Python Environment
**Required:** py310 (Python 3.10)
**Activation:** `conda activate py310`

### Critical Files
- `DATA_CONTRACT.md` - Schema spec
- `SERVER_PROFILES.md` - Profile definitions
- `ESSENTIAL_RAG.md` - Quick reference
- `PROJECT_CODEX.md` - This file

---

## üéâ Success Criteria

**A feature is complete when:**
- ‚úÖ Code follows all codex rules
- ‚úÖ Data contract validated
- ‚úÖ Tests pass
- ‚úÖ Documentation updated
- ‚úÖ End-to-end workflow tested
- ‚úÖ Session summary created
- ‚úÖ No regressions introduced

---

**Version:** 1.0.0
**Status:** AUTHORITATIVE
**Last Updated:** 2025-10-11
**Maintained By:** Project Team
**Review Frequency:** Before any major changes

‚ö†Ô∏è **THIS CODEX IS LAW - ALL DEVELOPMENT MUST FOLLOW THESE RULES**
