{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b664434c-2386-4102-9816-fec64191fc93",
   "metadata": {},
   "source": [
    "# TFT MONITORING SYSTEM\n",
    "\n",
    "## Temporal Fusion Transformer for Server Monitoring\n",
    "\n",
    "### ğŸš€ STREAMLINED TFT WORKFLOW:\n",
    "1. `setup()` - Initialize TFT environment\n",
    "2. `generate_dataset()` - Generate realistic server metrics\n",
    "3. `train()` - Train TFT model with PyTorch Forecasting\n",
    "4. `test()` - Test multi-horizon predictions\n",
    "5. `demo()` - Run live monitoring demo\n",
    "\n",
    "### ğŸ¯ TFT FEATURES:\n",
    "- **Multi-horizon forecasting**: Predict 6 steps ahead (30 minutes)\n",
    "- **Attention mechanism**: Identify important features automatically\n",
    "- **Uncertainty quantification**: Get confidence intervals with predictions\n",
    "- **GPU acceleration**: Optimized for CUDA with mixed precision\n",
    "- **Secure storage**: Models saved with Safetensors format\n",
    "\n",
    "### ğŸ“Š MONITORING:\n",
    "- `status()` - Check system status\n",
    "- `cleanup()` - Clean old files\n",
    "\n",
    "**Architecture:** PyTorch 2.0.1 + PyTorch Lightning 2.0.2 + PyTorch Forecasting\n",
    "\n",
    "**Model:** TemporalFusionTransformer with attention-based feature importance\n",
    "\n",
    "#### Generate dataset\n",
    "python metrics_generator.py --hours 168 --output training/metrics_dataset.json\n",
    "\n",
    "#### Train model\n",
    "python tft_model_trainer.py --epochs 30 --batch-size 32\n",
    "\n",
    "#### Run inference\n",
    "python tft_inference.py --input-file test_data.json --output-file predictions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14b987-a41d-47fb-8189-d316f3820a23",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Troubleshooting & Advanced Usage\n",
    "\n",
    "### Common Commands:\n",
    "- `status()` - Complete system status\n",
    "- `cleanup()` - Clean old checkpoints and logs\n",
    "- `generate_dataset(hours=X, force_regenerate=True)` - Regenerate data\n",
    "\n",
    "### Configuration:\n",
    "Modify `CONFIG` in `config.py` for advanced settings:\n",
    "```python\n",
    "CONFIG['epochs'] = 50              # More training\n",
    "CONFIG['batch_size'] = 64          # Larger batches (if GPU allows)\n",
    "CONFIG['prediction_horizon'] = 12  # Predict 1 hour ahead\n",
    "CONFIG['context_length'] = 48      # Use 4 hours of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76483fea-1cfd-4532-96ed-ae58139eeff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:config:ğŸ“– Configuration loaded: ./tft_config.json\n",
      "INFO:common_utils:âœ… Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:ğŸ¯ TFT Monitoring System initialized\n",
      "INFO:common_utils:ğŸ“Š Dataset: âœ…\n",
      "INFO:common_utils:ğŸ¤– Model: âŒ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] ğŸ¯ TFT Monitoring System initialized\n",
      "[14:52:16] ğŸ“Š Dataset: âœ…\n",
      "[14:52:16] ğŸ¤– Model: âŒ\n",
      "ğŸ¯ TFT Monitoring System - Temporal Fusion Transformer\n",
      "ğŸ“ˆ Multi-horizon time-series prediction for server monitoring\n",
      "âš¡ PyTorch Forecasting + GPU acceleration\n",
      "\n",
      "Type quick_start_guide() for usage instructions\n",
      "Type status() to check system status\n",
      "ğŸ¯ TFT Monitoring System\n",
      "ğŸ“ˆ Temporal Fusion Transformer for Server Prediction\n",
      "âš¡ Ready for GPU-accelerated time-series forecasting\n"
     ]
    }
   ],
   "source": [
    "# Import the streamlined TFT system\n",
    "from main_notebook import *\n",
    "from config import CONFIG, get_system_info\n",
    "\n",
    "print(\"ğŸ¯ TFT Monitoring System\")\n",
    "print(\"ğŸ“ˆ Temporal Fusion Transformer for Server Prediction\")\n",
    "print(f\"âš¡ Ready for GPU-accelerated time-series forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8054224-54f2-4d0e-8686-2cb416315964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:ğŸš€ Setting up TFT monitoring system...\n",
      "INFO:config:ğŸ” Validating TFT environment...\n",
      "INFO:config:âœ… PyTorch: 2.0.1+cu118\n",
      "INFO:config:âœ… PyTorch Lightning: 2.0.9\n",
      "INFO:config:âœ… PyTorch Forecasting available\n",
      "INFO:config:âœ… Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸš€ Environment: pytorch_cuda\n",
      "INFO:config:ğŸ“Š Batch size optimized: 32\n",
      "INFO:config:âš¡ Mixed precision: True\n",
      "INFO:metrics_generator:ğŸ–¥ï¸  Created 57 server profiles:\n",
      "INFO:metrics_generator:   Heavy usage servers: 24\n",
      "INFO:metrics_generator:   Problem child servers: 2\n",
      "INFO:metrics_generator:ğŸ“Š Initialized generator for 57 servers\n",
      "INFO:metrics_generator:â±ï¸  Poll interval: 5s (12 samples/minute)\n",
      "INFO:common_utils:âœ… TFT setup complete!\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸ” Validating TFT environment...\n",
      "INFO:config:âœ… PyTorch: 2.0.1+cu118\n",
      "INFO:config:âœ… PyTorch Lightning: 2.0.9\n",
      "INFO:config:âœ… PyTorch Forecasting available\n",
      "INFO:config:âœ… Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸš€ Environment: pytorch_cuda\n",
      "INFO:config:ğŸ“Š Batch size optimized: 32\n",
      "INFO:config:âš¡ Mixed precision: True\n",
      "INFO:common_utils:ğŸ® Environment: pytorch_cuda\n",
      "INFO:common_utils:ğŸ”¥ GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸ” Validating TFT environment...\n",
      "INFO:config:âœ… PyTorch: 2.0.1+cu118\n",
      "INFO:config:âœ… PyTorch Lightning: 2.0.9\n",
      "INFO:config:âœ… PyTorch Forecasting available\n",
      "INFO:config:âœ… Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:ğŸš€ Environment: pytorch_cuda\n",
      "INFO:config:ğŸ“Š Batch size optimized: 32\n",
      "INFO:config:âš¡ Mixed precision: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Setting up TFT Monitoring System...\n",
      "This includes: environment validation, directories, GPU detection\n",
      "[14:52:34] ğŸš€ Setting up TFT monitoring system...\n",
      "[14:52:34] âœ… TFT setup complete!\n",
      "[14:52:34] ğŸ® Environment: pytorch_cuda\n",
      "[14:52:34] ğŸ”¥ GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "\n",
      "âœ… TFT setup complete!\n",
      "\n",
      "ğŸ–¥ï¸  System Configuration:\n",
      "   Environment: pytorch_cuda\n",
      "   Framework: pytorch_forecasting\n",
      "   GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "\n",
      "ğŸ¯ TFT Model Configuration:\n",
      "   Context length: 24 steps (2 hours)\n",
      "   Prediction horizon: 6 steps (30 minutes)\n",
      "   Batch size: 32 (optimized for your hardware)\n",
      "   Mixed precision: True\n",
      "\n",
      "Next: generate_dataset() to create training data\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup TFT environment\n",
    "print(\"ğŸš€ Setting up TFT Monitoring System...\")\n",
    "print(\"This includes: environment validation, directories, GPU detection\")\n",
    "\n",
    "setup_success = setup()\n",
    "\n",
    "if setup_success:\n",
    "    print(\"\\nâœ… TFT setup complete!\")\n",
    "    \n",
    "    # Show system information\n",
    "    info = get_system_info()\n",
    "    print(f\"\\nğŸ–¥ï¸  System Configuration:\")\n",
    "    print(f\"   Environment: {info['environment']}\")\n",
    "    print(f\"   Framework: {info['framework']}\")\n",
    "    if info.get('gpu_name'):\n",
    "        print(f\"   GPU: {info['gpu_name']} ({info['gpu_memory_gb']}GB)\")\n",
    "    \n",
    "    print(f\"\\nğŸ¯ TFT Model Configuration:\")\n",
    "    print(f\"   Context length: {CONFIG['context_length']} steps (2 hours)\")\n",
    "    print(f\"   Prediction horizon: {CONFIG['prediction_horizon']} steps (30 minutes)\")\n",
    "    print(f\"   Batch size: {CONFIG['batch_size']} (optimized for your hardware)\")\n",
    "    print(f\"   Mixed precision: {CONFIG['mixed_precision']}\")\n",
    "    \n",
    "    print(\"\\nNext: generate_dataset() to create training data\")\n",
    "else:\n",
    "    print(\"\\nâŒ Setup failed. Check PyTorch Forecasting installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9339b-6d0b-40f2-8365-90412a64f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check current system status\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d8a87e-3c77-4c15-a985-c5ee8d8d1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:ğŸ“Š Generating 168 hours of TFT training data...\n",
      "INFO:common_utils:ğŸ¯ Target: ~114,912 samples\n",
      "INFO:metrics_generator:ğŸš€ Starting dataset generation for 168 hours (7.0 days)\n",
      "INFO:metrics_generator:ğŸ“… Generated timeframe sequence: 67 periods\n",
      "INFO:metrics_generator:   idle: 6336 minutes (62.9%)\n",
      "INFO:metrics_generator:   heavy_load: 449 minutes (4.5%)\n",
      "INFO:metrics_generator:   healthy: 2883 minutes (28.6%)\n",
      "INFO:metrics_generator:   critical_issue: 16 minutes (0.2%)\n",
      "INFO:metrics_generator:   recovery: 36 minutes (0.4%)\n",
      "INFO:metrics_generator:   offline: 14 minutes (0.1%)\n",
      "INFO:metrics_generator:   morning_spike: 193 minutes (1.9%)\n",
      "INFO:metrics_generator:   maintenance: 153 minutes (1.5%)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3024 samples for idle (252 minutes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š GENERATING TFT TRAINING DATASET\n",
      "==================================================\n",
      "ğŸ¯ Creating realistic server metrics with temporal patterns\n",
      "â±ï¸  Default: 168 hours (1 week) across 57 servers\n",
      "ğŸ“ˆ Features: CPU, Memory, Disk, Load, Network, Java metrics\n",
      "ğŸ”„ Patterns: idle, healthy, spikes, critical, recovery states\n",
      "\n",
      "Generating 168 hours of data...\n",
      "[14:53:12] ğŸ“Š Generating 168 hours of TFT training data...\n",
      "[14:53:12] ğŸ¯ Target: ~114,912 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metrics_generator:ğŸ”„ Generating 1284 samples for heavy_load (107 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2688 samples for healthy (224 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3144 samples for idle (262 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2028 samples for healthy (169 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1212 samples for heavy_load (101 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 60 samples for critical_issue (5 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1608 samples for healthy (134 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 60 samples for critical_issue (5 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 72 samples for offline (6 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1560 samples for healthy (130 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1488 samples for healthy (124 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3132 samples for idle (261 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3744 samples for idle (312 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 72 samples for critical_issue (6 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 96 samples for offline (8 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 4020 samples for idle (335 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1800 samples for healthy (150 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3672 samples for idle (306 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1560 samples for healthy (130 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3264 samples for idle (272 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 300 samples for morning_spike (25 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 156 samples for maintenance (13 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2244 samples for healthy (187 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 504 samples for morning_spike (42 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 384 samples for morning_spike (32 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3900 samples for idle (325 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2244 samples for healthy (187 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3492 samples for idle (291 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2580 samples for idle (215 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2928 samples for idle (244 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1404 samples for heavy_load (117 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2520 samples for healthy (210 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2580 samples for healthy (215 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 180 samples for maintenance (15 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2376 samples for idle (198 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 4308 samples for idle (359 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2580 samples for idle (215 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3312 samples for idle (276 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2232 samples for healthy (186 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1752 samples for healthy (146 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2064 samples for healthy (172 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 252 samples for maintenance (21 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 504 samples for morning_spike (42 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 288 samples for maintenance (24 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3792 samples for idle (316 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 204 samples for maintenance (17 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 288 samples for morning_spike (24 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3924 samples for idle (327 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3060 samples for idle (255 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 336 samples for morning_spike (28 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 3900 samples for idle (325 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1488 samples for heavy_load (124 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 276 samples for maintenance (23 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2796 samples for idle (233 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 276 samples for maintenance (23 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2064 samples for healthy (172 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 4248 samples for idle (354 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2352 samples for healthy (196 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1812 samples for healthy (151 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 204 samples for maintenance (17 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 2856 samples for idle (238 minutes)\n",
      "INFO:metrics_generator:ğŸ”„ Generating 1980 samples for idle (165 minutes)\n",
      "INFO:metrics_generator:âœ… Dataset generation completed!\n",
      "INFO:metrics_generator:   Total samples: 6,894,720\n",
      "INFO:metrics_generator:   Normal samples: 6,461,156 (93.7%)\n",
      "INFO:metrics_generator:   Anomaly samples: 433,564 (6.3%)\n",
      "INFO:metrics_generator:   Servers: 57\n",
      "INFO:metrics_generator:   Time span: 168 hours (7.0 days)\n",
      "INFO:metrics_generator:ğŸ’¾ Saving dataset to training\\metrics_dataset.json\n",
      "INFO:metrics_generator:âœ… Dataset saved successfully (6686.4 MB)\n",
      "INFO:common_utils:âœ… Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:âœ… Dataset validation passed: 6894720 samples\n",
      "INFO:common_utils:âœ… Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:ğŸ‰ Dataset generation completed!\n",
      "INFO:common_utils:   ğŸ“Š Total samples: 6,894,720\n",
      "INFO:common_utils:   â±ï¸  Time span: 0.0 hours\n",
      "INFO:common_utils:   ğŸ–¥ï¸  Servers: 57\n",
      "INFO:common_utils:   âš ï¸  Anomaly ratio: 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:04:59] ğŸ‰ Dataset generation completed!\n",
      "[15:04:59]    ğŸ“Š Total samples: 6,894,720\n",
      "[15:04:59]    â±ï¸  Time span: 0.0 hours\n",
      "[15:04:59]    ğŸ–¥ï¸  Servers: 57\n",
      "[15:04:59]    âš ï¸  Anomaly ratio: 0.0%\n",
      "\n",
      "âœ… Dataset generation completed!\n",
      "ğŸ“Š Dataset includes:\n",
      "   - Realistic server behavioral patterns\n",
      "   - Time-series with 5-minute polling intervals\n",
      "   - Normal operations and anomaly conditions\n",
      "   - Multiple server profiles (production, staging, etc.)\n",
      "\n",
      "Next: train() to train the TFT model\n"
     ]
    }
   ],
   "source": [
    "# 3. Generate TFT training dataset\n",
    "print(\"ğŸ“Š GENERATING TFT TRAINING DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ¯ Creating realistic server metrics with temporal patterns\")\n",
    "print(\"â±ï¸  Default: 168 hours (1 week) across 57 servers\")\n",
    "print(\"ğŸ“ˆ Features: CPU, Memory, Disk, Load, Network, Java metrics\")\n",
    "print(\"ğŸ”„ Patterns: idle, healthy, spikes, critical, recovery states\")\n",
    "print()\n",
    "\n",
    "# Generate 1 week of data (can be customized)\n",
    "HOURS = 168  # 1 week - adjust as needed\n",
    "print(f\"Generating {HOURS} hours of data...\")\n",
    "\n",
    "generation_success = generate_dataset(hours=HOURS)\n",
    "\n",
    "if generation_success:\n",
    "    print(f\"\\nâœ… Dataset generation completed!\")\n",
    "    print(\"ğŸ“Š Dataset includes:\")\n",
    "    print(\"   - Realistic server behavioral patterns\")\n",
    "    print(\"   - Time-series with 5-minute polling intervals\")\n",
    "    print(\"   - Normal operations and anomaly conditions\")\n",
    "    print(\"   - Multiple server profiles (production, staging, etc.)\")\n",
    "    print(\"\\nNext: train() to train the TFT model\")\n",
    "else:\n",
    "    print(\"\\nâŒ Dataset generation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccae5a8-a16f-4904-a947-f765bef6323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:ğŸ‹ï¸ Training TFT model...\n",
      "INFO:common_utils:ğŸ¯ Model: Temporal Fusion Transformer\n",
      "INFO:config:ğŸ® PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:common_utils:âš¡ Environment: pytorch_cuda\n",
      "INFO:common_utils:ğŸ“Š Config: 30 epochs, batch size 32\n",
      "INFO:common_utils:ğŸ¯ TFT Model Trainer Initialized (BERT Replacement)\n",
      "INFO:common_utils:ğŸ“Š Using PyTorch Forecasting framework\n",
      "INFO:common_utils:ğŸ® Model: Temporal Fusion Transformer\n",
      "INFO:common_utils:ğŸ‹ï¸ Starting TFT model training (BERT replacement)\n",
      "INFO:common_utils:ğŸ”§ Framework: PyTorch Forecasting TFT\n",
      "INFO:common_utils:ğŸ“Š Training on metrics dataset only (ignoring language dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‹ï¸ TRAINING TFT MODEL\n",
      "========================================\n",
      "ğŸ¤– Model: Temporal Fusion Transformer\n",
      "âš¡ Framework: PyTorch Forecasting\n",
      "ğŸ¯ Task: Multi-horizon time-series prediction\n",
      "\n",
      "[15:05:03] ğŸ‹ï¸ Training TFT model...\n",
      "[15:05:03] ğŸ¯ Model: Temporal Fusion Transformer\n",
      "[15:05:03] âš¡ Environment: pytorch_cuda\n",
      "[15:05:03] ğŸ“Š Config: 30 epochs, batch size 32\n",
      "[15:05:03] ğŸ¯ TFT Model Trainer Initialized (BERT Replacement)\n",
      "[15:05:03] ğŸ“Š Using PyTorch Forecasting framework\n",
      "[15:05:03] ğŸ® Model: Temporal Fusion Transformer\n",
      "[15:05:03] ğŸ‹ï¸ Starting TFT model training (BERT replacement)\n",
      "[15:05:03] ğŸ”§ Framework: PyTorch Forecasting TFT\n",
      "[15:05:03] ğŸ“Š Training on metrics dataset only (ignoring language dataset)\n"
     ]
    }
   ],
   "source": [
    "# 4. Train TFT model\n",
    "print(\"ğŸ‹ï¸ TRAINING TFT MODEL\")\n",
    "print(\"=\"*40)\n",
    "print(\"ğŸ¤– Model: Temporal Fusion Transformer\")\n",
    "print(\"âš¡ Framework: PyTorch Forecasting\")\n",
    "print(\"ğŸ¯ Task: Multi-horizon time-series prediction\")\n",
    "print()\n",
    "\n",
    "training_success = train()\n",
    "\n",
    "if training_success:\n",
    "    print(\"\\nğŸ‰ TFT training completed!\")\n",
    "    print(\"ğŸ’¡ Model capabilities:\")\n",
    "    print(\"   âœ… Multi-step ahead forecasting\")\n",
    "    print(\"   âœ… Attention-based feature selection\")\n",
    "    print(\"   âœ… Uncertainty quantification\")\n",
    "    print(\"   âœ… Anomaly detection\")\n",
    "    print(\"\\nNext: test() to validate predictions\")\n",
    "else:\n",
    "    print(\"\\nâŒ Training failed - check dataset and GPU memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1670c3b-9506-48a7-b83b-8f2ea82f4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test TFT model predictions\n",
    "print(\"ğŸ§ª TESTING TFT MODEL\")\n",
    "print(\"=\"*30)\n",
    "print(\"Testing scenarios:\")\n",
    "print(\"â€¢ Normal operation trends\")\n",
    "print(\"â€¢ Gradual performance degradation\")\n",
    "print(\"â€¢ Spike pattern detection\")\n",
    "print()\n",
    "\n",
    "test_success = test()\n",
    "\n",
    "if test_success:\n",
    "    print(\"\\nâœ… TFT model testing successful!\")\n",
    "    print(\"ğŸ’¡ Model demonstrates:\")\n",
    "    print(\"   - Accurate multi-horizon predictions\")\n",
    "    print(\"   - Uncertainty quantification\")\n",
    "    print(\"   - Automatic alert generation\")\n",
    "    print(\"   - Feature importance analysis\")\n",
    "    print(\"\\nNext: demo() to run live monitoring\")\n",
    "else:\n",
    "    print(\"\\nâŒ Testing failed - check model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45208a10-27b1-4012-bebe-e54edbb3b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Run TFT monitoring demo\n",
    "print(\"ğŸ­ TFT MONITORING DEMO\")\n",
    "print(\"=\"*25)\n",
    "print(\"Features:\")\n",
    "print(\"â€¢ Real-time multi-horizon forecasting\")\n",
    "print(\"â€¢ Attention-based predictions\")\n",
    "print(\"â€¢ Automated alert generation\")\n",
    "print(\"â€¢ Uncertainty quantification\")\n",
    "print()\n",
    "\n",
    "# Customize demo duration\n",
    "DEMO_MINUTES = 3\n",
    "\n",
    "print(f\"Running {DEMO_MINUTES}-minute live demo...\")\n",
    "print(\"ğŸ”® Will simulate real-time server monitoring with TFT predictions\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    demo_success = demo(minutes=DEMO_MINUTES)\n",
    "    \n",
    "    if demo_success:\n",
    "        print(\"\\nâœ… TFT demo completed!\")\n",
    "        print(\"ğŸ¯ Demo showcased:\")\n",
    "        print(\"   - Multi-step ahead predictions\")\n",
    "        print(\"   - Real-time anomaly detection\")\n",
    "        print(\"   - Attention mechanism insights\")\n",
    "        print(\"   - Uncertainty-aware forecasting\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Demo encountered issues\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâ¹ï¸  Demo stopped by user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea52012-b06b-4078-96ea-faba8218b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Final system status and summary\n",
    "print(\"ğŸ“‹ FINAL TFT SYSTEM STATUS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "status()\n",
    "\n",
    "print(\"\\nğŸ‰ TFT SYSTEM COMPLETE!\")\n",
    "print(\"=\"*30)\n",
    "print(\"Your TFT monitoring system includes:\")\n",
    "print(\"  âœ… Temporal Fusion Transformer model\")\n",
    "print(\"  âœ… Multi-horizon forecasting (6 steps ahead)\")\n",
    "print(\"  âœ… Attention-based feature importance\")\n",
    "print(\"  âœ… GPU-accelerated training pipeline\")\n",
    "print(\"  âœ… Safetensors secure model storage\")\n",
    "print(\"  âœ… Real-time anomaly detection\")\n",
    "print(\"  âœ… Uncertainty quantification\")\n",
    "print()\n",
    "print(\"ğŸ”§ NEXT STEPS:\")\n",
    "print(\"  â€¢ Connect to real MongoDB data sources\")\n",
    "print(\"  â€¢ Customize alert thresholds in config.py\")\n",
    "print(\"  â€¢ Set up continuous retraining pipeline\")\n",
    "print(\"  â€¢ Deploy for production monitoring\")\n",
    "print()\n",
    "print(\"ğŸ’¡ COMMAND LINE USAGE:\")\n",
    "print(\"  python metrics_generator.py --hours 168\")\n",
    "print(\"  python tft_model_trainer.py --epochs 30\")\n",
    "print(\"  python tft_inference.py --input-file data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f58358-c496-4273-a4e7-eb9c2adc9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Quick command reference\n",
    "def show_commands():\n",
    "    \"\"\"Show available TFT system commands.\"\"\"\n",
    "    print(\"ğŸ”§ TFT SYSTEM COMMANDS\")\n",
    "    print(\"=\"*30)\n",
    "    print()\n",
    "    print(\"ğŸ“Š Dataset Management:\")\n",
    "    print(\"generate_dataset(hours=168)     # Generate training data\")\n",
    "    print(\"generate_dataset(hours=720, force_regenerate=True)  # 30 days, force regen\")\n",
    "    print()\n",
    "    print(\"ğŸ‹ï¸ Model Training:\")\n",
    "    print(\"train()                         # Train TFT model\")\n",
    "    print(\"train(resume=True)              # Resume from checkpoint\")\n",
    "    print()\n",
    "    print(\"ğŸ§ª Testing & Demo:\")\n",
    "    print(\"test()                          # Test model predictions\")\n",
    "    print(\"demo(minutes=5)                 # Live monitoring demo\")\n",
    "    print()\n",
    "    print(\"ğŸ” System Management:\")\n",
    "    print(\"status()                        # System status\")\n",
    "    print(\"cleanup()                       # Clean old files\")\n",
    "    print(\"quick_start_guide()             # Full documentation\")\n",
    "    print()\n",
    "    print(\"âš™ï¸  Configuration:\")\n",
    "    print(\"CONFIG['epochs'] = 50           # Adjust training epochs\")\n",
    "    print(\"CONFIG['batch_size'] = 64       # Adjust batch size\")\n",
    "    print(\"CONFIG['prediction_horizon'] = 12  # Predict further ahead\")\n",
    "\n",
    "# Show commands\n",
    "show_commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feef038-074d-4fba-808e-fab3c75dd7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de56814-6916-4486-a51f-820769085b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dcb05-a904-46c2-9780-2910dca3e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f89e52-654b-4adb-b4d8-9520b70b1c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414bf8d-7fea-429d-af20-e2ac1c42a707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c64b89-0c7c-4197-91be-b15582f08fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595b54-0610-44b6-ad89-56e505a037c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ede1b4-9b32-40bc-a17a-f106dcba2886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702cdf-261c-4504-a54b-6b5b5506169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbc05c-969c-475d-93e1-2abb8fe8ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
