{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b664434c-2386-4102-9816-fec64191fc93",
   "metadata": {},
   "source": [
    "# TFT MONITORING SYSTEM\n",
    "\n",
    "## Temporal Fusion Transformer for Server Monitoring\n",
    "\n",
    "### 🚀 STREAMLINED TFT WORKFLOW:\n",
    "1. `setup()` - Initialize TFT environment\n",
    "2. `generate_dataset()` - Generate realistic server metrics\n",
    "3. `train()` - Train TFT model with PyTorch Forecasting\n",
    "4. `test()` - Test multi-horizon predictions\n",
    "5. `demo()` - Run live monitoring demo\n",
    "\n",
    "### 🎯 TFT FEATURES:\n",
    "- **Multi-horizon forecasting**: Predict 6 steps ahead (30 minutes)\n",
    "- **Attention mechanism**: Identify important features automatically\n",
    "- **Uncertainty quantification**: Get confidence intervals with predictions\n",
    "- **GPU acceleration**: Optimized for CUDA with mixed precision\n",
    "- **Secure storage**: Models saved with Safetensors format\n",
    "\n",
    "### 📊 MONITORING:\n",
    "- `status()` - Check system status\n",
    "- `cleanup()` - Clean old files\n",
    "\n",
    "**Architecture:** PyTorch 2.0.1 + PyTorch Lightning 2.0.2 + PyTorch Forecasting\n",
    "\n",
    "**Model:** TemporalFusionTransformer with attention-based feature importance\n",
    "\n",
    "#### Generate dataset\n",
    "python metrics_generator.py --hours 168 --output training/metrics_dataset.json\n",
    "\n",
    "#### Train model\n",
    "python tft_model_trainer.py --epochs 30 --batch-size 32\n",
    "\n",
    "#### Run inference\n",
    "python tft_inference.py --input-file test_data.json --output-file predictions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af14b987-a41d-47fb-8189-d316f3820a23",
   "metadata": {},
   "source": [
    "## 🛠️ Troubleshooting & Advanced Usage\n",
    "\n",
    "### Common Commands:\n",
    "- `status()` - Complete system status\n",
    "- `cleanup()` - Clean old checkpoints and logs\n",
    "- `generate_dataset(hours=X, force_regenerate=True)` - Regenerate data\n",
    "\n",
    "### Configuration:\n",
    "Modify `CONFIG` in `config.py` for advanced settings:\n",
    "```python\n",
    "CONFIG['epochs'] = 50              # More training\n",
    "CONFIG['batch_size'] = 64          # Larger batches (if GPU allows)\n",
    "CONFIG['prediction_horizon'] = 12  # Predict 1 hour ahead\n",
    "CONFIG['context_length'] = 48      # Use 4 hours of history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76483fea-1cfd-4532-96ed-ae58139eeff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:config:📖 Configuration loaded: ./tft_config.json\n",
      "INFO:common_utils:✅ Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:🎯 TFT Monitoring System initialized\n",
      "INFO:common_utils:📊 Dataset: ✅\n",
      "INFO:common_utils:🤖 Model: ❌\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:16] 🎯 TFT Monitoring System initialized\n",
      "[14:52:16] 📊 Dataset: ✅\n",
      "[14:52:16] 🤖 Model: ❌\n",
      "🎯 TFT Monitoring System - Temporal Fusion Transformer\n",
      "📈 Multi-horizon time-series prediction for server monitoring\n",
      "⚡ PyTorch Forecasting + GPU acceleration\n",
      "\n",
      "Type quick_start_guide() for usage instructions\n",
      "Type status() to check system status\n",
      "🎯 TFT Monitoring System\n",
      "📈 Temporal Fusion Transformer for Server Prediction\n",
      "⚡ Ready for GPU-accelerated time-series forecasting\n"
     ]
    }
   ],
   "source": [
    "# Import the streamlined TFT system\n",
    "from main_notebook import *\n",
    "from config import CONFIG, get_system_info\n",
    "\n",
    "print(\"🎯 TFT Monitoring System\")\n",
    "print(\"📈 Temporal Fusion Transformer for Server Prediction\")\n",
    "print(f\"⚡ Ready for GPU-accelerated time-series forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8054224-54f2-4d0e-8686-2cb416315964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:🚀 Setting up TFT monitoring system...\n",
      "INFO:config:🔍 Validating TFT environment...\n",
      "INFO:config:✅ PyTorch: 2.0.1+cu118\n",
      "INFO:config:✅ PyTorch Lightning: 2.0.9\n",
      "INFO:config:✅ PyTorch Forecasting available\n",
      "INFO:config:✅ Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🚀 Environment: pytorch_cuda\n",
      "INFO:config:📊 Batch size optimized: 32\n",
      "INFO:config:⚡ Mixed precision: True\n",
      "INFO:metrics_generator:🖥️  Created 57 server profiles:\n",
      "INFO:metrics_generator:   Heavy usage servers: 24\n",
      "INFO:metrics_generator:   Problem child servers: 2\n",
      "INFO:metrics_generator:📊 Initialized generator for 57 servers\n",
      "INFO:metrics_generator:⏱️  Poll interval: 5s (12 samples/minute)\n",
      "INFO:common_utils:✅ TFT setup complete!\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🔍 Validating TFT environment...\n",
      "INFO:config:✅ PyTorch: 2.0.1+cu118\n",
      "INFO:config:✅ PyTorch Lightning: 2.0.9\n",
      "INFO:config:✅ PyTorch Forecasting available\n",
      "INFO:config:✅ Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🚀 Environment: pytorch_cuda\n",
      "INFO:config:📊 Batch size optimized: 32\n",
      "INFO:config:⚡ Mixed precision: True\n",
      "INFO:common_utils:🎮 Environment: pytorch_cuda\n",
      "INFO:common_utils:🔥 GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🔍 Validating TFT environment...\n",
      "INFO:config:✅ PyTorch: 2.0.1+cu118\n",
      "INFO:config:✅ PyTorch Lightning: 2.0.9\n",
      "INFO:config:✅ PyTorch Forecasting available\n",
      "INFO:config:✅ Metrics dataset found: training\\metrics_dataset.json\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:config:🚀 Environment: pytorch_cuda\n",
      "INFO:config:📊 Batch size optimized: 32\n",
      "INFO:config:⚡ Mixed precision: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Setting up TFT Monitoring System...\n",
      "This includes: environment validation, directories, GPU detection\n",
      "[14:52:34] 🚀 Setting up TFT monitoring system...\n",
      "[14:52:34] ✅ TFT setup complete!\n",
      "[14:52:34] 🎮 Environment: pytorch_cuda\n",
      "[14:52:34] 🔥 GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "\n",
      "✅ TFT setup complete!\n",
      "\n",
      "🖥️  System Configuration:\n",
      "   Environment: pytorch_cuda\n",
      "   Framework: pytorch_forecasting\n",
      "   GPU: NVIDIA GeForce RTX 4090 (22GB)\n",
      "\n",
      "🎯 TFT Model Configuration:\n",
      "   Context length: 24 steps (2 hours)\n",
      "   Prediction horizon: 6 steps (30 minutes)\n",
      "   Batch size: 32 (optimized for your hardware)\n",
      "   Mixed precision: True\n",
      "\n",
      "Next: generate_dataset() to create training data\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup TFT environment\n",
    "print(\"🚀 Setting up TFT Monitoring System...\")\n",
    "print(\"This includes: environment validation, directories, GPU detection\")\n",
    "\n",
    "setup_success = setup()\n",
    "\n",
    "if setup_success:\n",
    "    print(\"\\n✅ TFT setup complete!\")\n",
    "    \n",
    "    # Show system information\n",
    "    info = get_system_info()\n",
    "    print(f\"\\n🖥️  System Configuration:\")\n",
    "    print(f\"   Environment: {info['environment']}\")\n",
    "    print(f\"   Framework: {info['framework']}\")\n",
    "    if info.get('gpu_name'):\n",
    "        print(f\"   GPU: {info['gpu_name']} ({info['gpu_memory_gb']}GB)\")\n",
    "    \n",
    "    print(f\"\\n🎯 TFT Model Configuration:\")\n",
    "    print(f\"   Context length: {CONFIG['context_length']} steps (2 hours)\")\n",
    "    print(f\"   Prediction horizon: {CONFIG['prediction_horizon']} steps (30 minutes)\")\n",
    "    print(f\"   Batch size: {CONFIG['batch_size']} (optimized for your hardware)\")\n",
    "    print(f\"   Mixed precision: {CONFIG['mixed_precision']}\")\n",
    "    \n",
    "    print(\"\\nNext: generate_dataset() to create training data\")\n",
    "else:\n",
    "    print(\"\\n❌ Setup failed. Check PyTorch Forecasting installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9339b-6d0b-40f2-8365-90412a64f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check current system status\n",
    "status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6d8a87e-3c77-4c15-a985-c5ee8d8d1e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:📊 Generating 168 hours of TFT training data...\n",
      "INFO:common_utils:🎯 Target: ~114,912 samples\n",
      "INFO:metrics_generator:🚀 Starting dataset generation for 168 hours (7.0 days)\n",
      "INFO:metrics_generator:📅 Generated timeframe sequence: 67 periods\n",
      "INFO:metrics_generator:   idle: 6336 minutes (62.9%)\n",
      "INFO:metrics_generator:   heavy_load: 449 minutes (4.5%)\n",
      "INFO:metrics_generator:   healthy: 2883 minutes (28.6%)\n",
      "INFO:metrics_generator:   critical_issue: 16 minutes (0.2%)\n",
      "INFO:metrics_generator:   recovery: 36 minutes (0.4%)\n",
      "INFO:metrics_generator:   offline: 14 minutes (0.1%)\n",
      "INFO:metrics_generator:   morning_spike: 193 minutes (1.9%)\n",
      "INFO:metrics_generator:   maintenance: 153 minutes (1.5%)\n",
      "INFO:metrics_generator:🔄 Generating 3024 samples for idle (252 minutes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 GENERATING TFT TRAINING DATASET\n",
      "==================================================\n",
      "🎯 Creating realistic server metrics with temporal patterns\n",
      "⏱️  Default: 168 hours (1 week) across 57 servers\n",
      "📈 Features: CPU, Memory, Disk, Load, Network, Java metrics\n",
      "🔄 Patterns: idle, healthy, spikes, critical, recovery states\n",
      "\n",
      "Generating 168 hours of data...\n",
      "[14:53:12] 📊 Generating 168 hours of TFT training data...\n",
      "[14:53:12] 🎯 Target: ~114,912 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:metrics_generator:🔄 Generating 1284 samples for heavy_load (107 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2688 samples for healthy (224 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3144 samples for idle (262 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2028 samples for healthy (169 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1212 samples for heavy_load (101 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 60 samples for critical_issue (5 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1608 samples for healthy (134 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 60 samples for critical_issue (5 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 72 samples for offline (6 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1560 samples for healthy (130 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1488 samples for healthy (124 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3132 samples for idle (261 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3744 samples for idle (312 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 72 samples for critical_issue (6 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 96 samples for offline (8 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 4020 samples for idle (335 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1800 samples for healthy (150 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3672 samples for idle (306 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1560 samples for healthy (130 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3264 samples for idle (272 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 300 samples for morning_spike (25 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 156 samples for maintenance (13 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 108 samples for recovery (9 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2244 samples for healthy (187 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 504 samples for morning_spike (42 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 384 samples for morning_spike (32 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3900 samples for idle (325 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2244 samples for healthy (187 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3492 samples for idle (291 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2580 samples for idle (215 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2928 samples for idle (244 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1404 samples for heavy_load (117 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2520 samples for healthy (210 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2580 samples for healthy (215 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 180 samples for maintenance (15 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2376 samples for idle (198 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 4308 samples for idle (359 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2580 samples for idle (215 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3312 samples for idle (276 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2232 samples for healthy (186 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1752 samples for healthy (146 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2064 samples for healthy (172 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 252 samples for maintenance (21 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 504 samples for morning_spike (42 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 288 samples for maintenance (24 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3792 samples for idle (316 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 204 samples for maintenance (17 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 288 samples for morning_spike (24 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3924 samples for idle (327 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3060 samples for idle (255 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 336 samples for morning_spike (28 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 3900 samples for idle (325 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1488 samples for heavy_load (124 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 276 samples for maintenance (23 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2796 samples for idle (233 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 276 samples for maintenance (23 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2064 samples for healthy (172 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 4248 samples for idle (354 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2352 samples for healthy (196 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1812 samples for healthy (151 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 204 samples for maintenance (17 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 2856 samples for idle (238 minutes)\n",
      "INFO:metrics_generator:🔄 Generating 1980 samples for idle (165 minutes)\n",
      "INFO:metrics_generator:✅ Dataset generation completed!\n",
      "INFO:metrics_generator:   Total samples: 6,894,720\n",
      "INFO:metrics_generator:   Normal samples: 6,461,156 (93.7%)\n",
      "INFO:metrics_generator:   Anomaly samples: 433,564 (6.3%)\n",
      "INFO:metrics_generator:   Servers: 57\n",
      "INFO:metrics_generator:   Time span: 168 hours (7.0 days)\n",
      "INFO:metrics_generator:💾 Saving dataset to training\\metrics_dataset.json\n",
      "INFO:metrics_generator:✅ Dataset saved successfully (6686.4 MB)\n",
      "INFO:common_utils:✅ Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:✅ Dataset validation passed: 6894720 samples\n",
      "INFO:common_utils:✅ Loaded metrics dataset: metrics_dataset.json\n",
      "INFO:common_utils:🎉 Dataset generation completed!\n",
      "INFO:common_utils:   📊 Total samples: 6,894,720\n",
      "INFO:common_utils:   ⏱️  Time span: 0.0 hours\n",
      "INFO:common_utils:   🖥️  Servers: 57\n",
      "INFO:common_utils:   ⚠️  Anomaly ratio: 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:04:59] 🎉 Dataset generation completed!\n",
      "[15:04:59]    📊 Total samples: 6,894,720\n",
      "[15:04:59]    ⏱️  Time span: 0.0 hours\n",
      "[15:04:59]    🖥️  Servers: 57\n",
      "[15:04:59]    ⚠️  Anomaly ratio: 0.0%\n",
      "\n",
      "✅ Dataset generation completed!\n",
      "📊 Dataset includes:\n",
      "   - Realistic server behavioral patterns\n",
      "   - Time-series with 5-minute polling intervals\n",
      "   - Normal operations and anomaly conditions\n",
      "   - Multiple server profiles (production, staging, etc.)\n",
      "\n",
      "Next: train() to train the TFT model\n"
     ]
    }
   ],
   "source": [
    "# 3. Generate TFT training dataset\n",
    "print(\"📊 GENERATING TFT TRAINING DATASET\")\n",
    "print(\"=\"*50)\n",
    "print(\"🎯 Creating realistic server metrics with temporal patterns\")\n",
    "print(\"⏱️  Default: 168 hours (1 week) across 57 servers\")\n",
    "print(\"📈 Features: CPU, Memory, Disk, Load, Network, Java metrics\")\n",
    "print(\"🔄 Patterns: idle, healthy, spikes, critical, recovery states\")\n",
    "print()\n",
    "\n",
    "# Generate 1 week of data (can be customized)\n",
    "HOURS = 168  # 1 week - adjust as needed\n",
    "print(f\"Generating {HOURS} hours of data...\")\n",
    "\n",
    "generation_success = generate_dataset(hours=HOURS)\n",
    "\n",
    "if generation_success:\n",
    "    print(f\"\\n✅ Dataset generation completed!\")\n",
    "    print(\"📊 Dataset includes:\")\n",
    "    print(\"   - Realistic server behavioral patterns\")\n",
    "    print(\"   - Time-series with 5-minute polling intervals\")\n",
    "    print(\"   - Normal operations and anomaly conditions\")\n",
    "    print(\"   - Multiple server profiles (production, staging, etc.)\")\n",
    "    print(\"\\nNext: train() to train the TFT model\")\n",
    "else:\n",
    "    print(\"\\n❌ Dataset generation failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccae5a8-a16f-4904-a947-f765bef6323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:common_utils:🏋️ Training TFT model...\n",
      "INFO:common_utils:🎯 Model: Temporal Fusion Transformer\n",
      "INFO:config:🎮 PyTorch CUDA: NVIDIA GeForce RTX 4090 (22GB)\n",
      "INFO:common_utils:⚡ Environment: pytorch_cuda\n",
      "INFO:common_utils:📊 Config: 30 epochs, batch size 32\n",
      "INFO:common_utils:🎯 TFT Model Trainer Initialized (BERT Replacement)\n",
      "INFO:common_utils:📊 Using PyTorch Forecasting framework\n",
      "INFO:common_utils:🎮 Model: Temporal Fusion Transformer\n",
      "INFO:common_utils:🏋️ Starting TFT model training (BERT replacement)\n",
      "INFO:common_utils:🔧 Framework: PyTorch Forecasting TFT\n",
      "INFO:common_utils:📊 Training on metrics dataset only (ignoring language dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏋️ TRAINING TFT MODEL\n",
      "========================================\n",
      "🤖 Model: Temporal Fusion Transformer\n",
      "⚡ Framework: PyTorch Forecasting\n",
      "🎯 Task: Multi-horizon time-series prediction\n",
      "\n",
      "[15:05:03] 🏋️ Training TFT model...\n",
      "[15:05:03] 🎯 Model: Temporal Fusion Transformer\n",
      "[15:05:03] ⚡ Environment: pytorch_cuda\n",
      "[15:05:03] 📊 Config: 30 epochs, batch size 32\n",
      "[15:05:03] 🎯 TFT Model Trainer Initialized (BERT Replacement)\n",
      "[15:05:03] 📊 Using PyTorch Forecasting framework\n",
      "[15:05:03] 🎮 Model: Temporal Fusion Transformer\n",
      "[15:05:03] 🏋️ Starting TFT model training (BERT replacement)\n",
      "[15:05:03] 🔧 Framework: PyTorch Forecasting TFT\n",
      "[15:05:03] 📊 Training on metrics dataset only (ignoring language dataset)\n"
     ]
    }
   ],
   "source": [
    "# 4. Train TFT model\n",
    "print(\"🏋️ TRAINING TFT MODEL\")\n",
    "print(\"=\"*40)\n",
    "print(\"🤖 Model: Temporal Fusion Transformer\")\n",
    "print(\"⚡ Framework: PyTorch Forecasting\")\n",
    "print(\"🎯 Task: Multi-horizon time-series prediction\")\n",
    "print()\n",
    "\n",
    "training_success = train()\n",
    "\n",
    "if training_success:\n",
    "    print(\"\\n🎉 TFT training completed!\")\n",
    "    print(\"💡 Model capabilities:\")\n",
    "    print(\"   ✅ Multi-step ahead forecasting\")\n",
    "    print(\"   ✅ Attention-based feature selection\")\n",
    "    print(\"   ✅ Uncertainty quantification\")\n",
    "    print(\"   ✅ Anomaly detection\")\n",
    "    print(\"\\nNext: test() to validate predictions\")\n",
    "else:\n",
    "    print(\"\\n❌ Training failed - check dataset and GPU memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1670c3b-9506-48a7-b83b-8f2ea82f4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test TFT model predictions\n",
    "print(\"🧪 TESTING TFT MODEL\")\n",
    "print(\"=\"*30)\n",
    "print(\"Testing scenarios:\")\n",
    "print(\"• Normal operation trends\")\n",
    "print(\"• Gradual performance degradation\")\n",
    "print(\"• Spike pattern detection\")\n",
    "print()\n",
    "\n",
    "test_success = test()\n",
    "\n",
    "if test_success:\n",
    "    print(\"\\n✅ TFT model testing successful!\")\n",
    "    print(\"💡 Model demonstrates:\")\n",
    "    print(\"   - Accurate multi-horizon predictions\")\n",
    "    print(\"   - Uncertainty quantification\")\n",
    "    print(\"   - Automatic alert generation\")\n",
    "    print(\"   - Feature importance analysis\")\n",
    "    print(\"\\nNext: demo() to run live monitoring\")\n",
    "else:\n",
    "    print(\"\\n❌ Testing failed - check model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45208a10-27b1-4012-bebe-e54edbb3b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Run TFT monitoring demo\n",
    "print(\"🎭 TFT MONITORING DEMO\")\n",
    "print(\"=\"*25)\n",
    "print(\"Features:\")\n",
    "print(\"• Real-time multi-horizon forecasting\")\n",
    "print(\"• Attention-based predictions\")\n",
    "print(\"• Automated alert generation\")\n",
    "print(\"• Uncertainty quantification\")\n",
    "print()\n",
    "\n",
    "# Customize demo duration\n",
    "DEMO_MINUTES = 3\n",
    "\n",
    "print(f\"Running {DEMO_MINUTES}-minute live demo...\")\n",
    "print(\"🔮 Will simulate real-time server monitoring with TFT predictions\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    demo_success = demo(minutes=DEMO_MINUTES)\n",
    "    \n",
    "    if demo_success:\n",
    "        print(\"\\n✅ TFT demo completed!\")\n",
    "        print(\"🎯 Demo showcased:\")\n",
    "        print(\"   - Multi-step ahead predictions\")\n",
    "        print(\"   - Real-time anomaly detection\")\n",
    "        print(\"   - Attention mechanism insights\")\n",
    "        print(\"   - Uncertainty-aware forecasting\")\n",
    "    else:\n",
    "        print(\"\\n❌ Demo encountered issues\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n⏹️  Demo stopped by user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea52012-b06b-4078-96ea-faba8218b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Final system status and summary\n",
    "print(\"📋 FINAL TFT SYSTEM STATUS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "status()\n",
    "\n",
    "print(\"\\n🎉 TFT SYSTEM COMPLETE!\")\n",
    "print(\"=\"*30)\n",
    "print(\"Your TFT monitoring system includes:\")\n",
    "print(\"  ✅ Temporal Fusion Transformer model\")\n",
    "print(\"  ✅ Multi-horizon forecasting (6 steps ahead)\")\n",
    "print(\"  ✅ Attention-based feature importance\")\n",
    "print(\"  ✅ GPU-accelerated training pipeline\")\n",
    "print(\"  ✅ Safetensors secure model storage\")\n",
    "print(\"  ✅ Real-time anomaly detection\")\n",
    "print(\"  ✅ Uncertainty quantification\")\n",
    "print()\n",
    "print(\"🔧 NEXT STEPS:\")\n",
    "print(\"  • Connect to real MongoDB data sources\")\n",
    "print(\"  • Customize alert thresholds in config.py\")\n",
    "print(\"  • Set up continuous retraining pipeline\")\n",
    "print(\"  • Deploy for production monitoring\")\n",
    "print()\n",
    "print(\"💡 COMMAND LINE USAGE:\")\n",
    "print(\"  python metrics_generator.py --hours 168\")\n",
    "print(\"  python tft_model_trainer.py --epochs 30\")\n",
    "print(\"  python tft_inference.py --input-file data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f58358-c496-4273-a4e7-eb9c2adc9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Quick command reference\n",
    "def show_commands():\n",
    "    \"\"\"Show available TFT system commands.\"\"\"\n",
    "    print(\"🔧 TFT SYSTEM COMMANDS\")\n",
    "    print(\"=\"*30)\n",
    "    print()\n",
    "    print(\"📊 Dataset Management:\")\n",
    "    print(\"generate_dataset(hours=168)     # Generate training data\")\n",
    "    print(\"generate_dataset(hours=720, force_regenerate=True)  # 30 days, force regen\")\n",
    "    print()\n",
    "    print(\"🏋️ Model Training:\")\n",
    "    print(\"train()                         # Train TFT model\")\n",
    "    print(\"train(resume=True)              # Resume from checkpoint\")\n",
    "    print()\n",
    "    print(\"🧪 Testing & Demo:\")\n",
    "    print(\"test()                          # Test model predictions\")\n",
    "    print(\"demo(minutes=5)                 # Live monitoring demo\")\n",
    "    print()\n",
    "    print(\"🔍 System Management:\")\n",
    "    print(\"status()                        # System status\")\n",
    "    print(\"cleanup()                       # Clean old files\")\n",
    "    print(\"quick_start_guide()             # Full documentation\")\n",
    "    print()\n",
    "    print(\"⚙️  Configuration:\")\n",
    "    print(\"CONFIG['epochs'] = 50           # Adjust training epochs\")\n",
    "    print(\"CONFIG['batch_size'] = 64       # Adjust batch size\")\n",
    "    print(\"CONFIG['prediction_horizon'] = 12  # Predict further ahead\")\n",
    "\n",
    "# Show commands\n",
    "show_commands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feef038-074d-4fba-808e-fab3c75dd7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de56814-6916-4486-a51f-820769085b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dcb05-a904-46c2-9780-2910dca3e62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f89e52-654b-4adb-b4d8-9520b70b1c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414bf8d-7fea-429d-af20-e2ac1c42a707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c64b89-0c7c-4197-91be-b15582f08fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66595b54-0610-44b6-ad89-56e505a037c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ede1b4-9b32-40bc-a17a-f106dcba2886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702cdf-261c-4504-a54b-6b5b5506169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbc05c-969c-475d-93e1-2abb8fe8ced3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
