{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b664434c-2386-4102-9816-fec64191fc93",
   "metadata": {},
   "source": [
    "# TFT MONITORING SYSTEM\n",
    "\n",
    "## Temporal Fusion Transformer for Server Monitoring\n",
    "\n",
    "### ğŸš€ STREAMLINED TFT WORKFLOW:\n",
    "1. `setup()` - Initialize TFT environment\n",
    "2. `generate_dataset()` - Generate realistic server metrics\n",
    "3. `train()` - Train TFT model with PyTorch Forecasting\n",
    "4. `test()` - Test multi-horizon predictions\n",
    "5. `demo()` - Run live monitoring demo\n",
    "\n",
    "### ğŸ¯ TFT FEATURES:\n",
    "- **Multi-horizon forecasting**: Predict 6 steps ahead (30 minutes)\n",
    "- **Attention mechanism**: Identify important features automatically\n",
    "- **Uncertainty quantification**: Get confidence intervals with predictions\n",
    "- **GPU acceleration**: Optimized for CUDA with mixed precision\n",
    "- **Secure storage**: Models saved with Safetensors format\n",
    "\n",
    "### ğŸ“Š MONITORING:\n",
    "- `status()` - Check system status\n",
    "- `cleanup()` - Clean old files\n",
    "\n",
    "**Architecture:** PyTorch 2.0.1 + PyTorch Lightning 2.0.2 + PyTorch Forecasting\n",
    "\n",
    "**Model:** TemporalFusionTransformer with attention-based feature importance\n",
    "\n",
    "#### Generate dataset\n",
    "python metrics_generator.py --hours 168 --output training/metrics_dataset.json\n",
    "\n",
    "#### Train model\n",
    "python tft_model_trainer.py --epochs 30 --batch-size 32\n",
    "\n",
    "#### Run inference\n",
    "python tft_inference.py --input-file test_data.json --output-file predictions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de56814-6916-4486-a51f-820769085b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clean TFT monitoring system\n",
    "from main import setup, generate_dataset, train, predict, status\n",
    "from config import CONFIG\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸ¯ TFT Monitoring System - Production Version\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Modules loaded successfully\")\n",
    "print(f\"ğŸ“Š Default time span: {CONFIG['time_span_hours']} hours\")\n",
    "print(f\"ğŸ–¥ï¸  Servers: {CONFIG['servers_count']}\")\n",
    "print(f\"ğŸ¯ Prediction horizon: {CONFIG['prediction_horizon']} steps (30 min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dcb05-a904-46c2-9780-2910dca3e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup and validate environment\n",
    "print(\"STEP 1: Environment Setup\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if setup():\n",
    "    print(\"\\nâœ… Environment ready for TFT training!\")\n",
    "    print(\"\\nNext: Generate dataset with your desired hours\")\n",
    "else:\n",
    "    print(\"\\nâŒ Setup failed - check dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f89e52-654b-4adb-b4d8-9520b70b1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check current system status\n",
    "print(\"STEP 2: System Status\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a2fac-a9b1-40fc-b156-3fe20cdb36ef",
   "metadata": {},
   "source": [
    "## ğŸ“Š Dataset Generation\n",
    "\n",
    "- Pass hours directly to override config default\n",
    "- Generates realistic server patterns\n",
    "- Includes temporal variations (idle, spike, heavy load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c64b89-0c7c-4197-91be-b15582f08fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate dataset - NOW PROPERLY USES HOURS PARAMETER!\n",
    "from metrics_generator import generate_dataset\n",
    "print(\"STEP 3: Dataset Generation\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Generate 2 weeks of data (336 hours)\n",
    "HOURS = 24  # Change this to any value you want\n",
    "\n",
    "print(f\"\\nğŸš€ Generating {HOURS} hours of server metrics...\")\n",
    "print(f\"ğŸ“Š This will create ~{HOURS * 12 * CONFIG['servers_count']:,} samples\")\n",
    "\n",
    "# Works with existing notebook code\n",
    "success = generate_dataset(hours=HOURS, output_file=\"./training/metrics_dataset.json\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… Dataset generation complete!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Generation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516aebac-a847-468a-83e5-4e3bf31f1ed9",
   "metadata": {},
   "source": [
    "## ğŸ‹ï¸ Model Training\n",
    "\n",
    "Train the Temporal Fusion Transformer:\n",
    "- Multi-horizon forecasting (6 steps ahead)\n",
    "- Attention-based feature importance\n",
    "- Quantile loss for uncertainty estimation\n",
    "- Automatic GPU acceleration if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702cdf-261c-4504-a54b-6b5b5506169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train TFT model\n",
    "print(\"STEP 4: TFT Model Training\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Optional: Adjust training parameters\n",
    "EPOCHS = 1  # Reduce for faster testing\n",
    "\n",
    "print(f\"\\nğŸ‹ï¸ Training TFT for {EPOCHS} epochs...\")\n",
    "print(\"âš¡ This will use GPU if available\")\n",
    "print(\"ğŸ“Š Features: Multi-horizon prediction, attention mechanism\")\n",
    "\n",
    "success = train(epochs=EPOCHS, dataset_path=\"./training/\")\n",
    "\n",
    "if success:\n",
    "    print(\"\\nğŸ‰ Training completed successfully!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Training failed - check logs above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebbc05c-969c-475d-93e1-2abb8fe8ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "from pathlib import Path\n",
    "\n",
    "models_dir = Path(CONFIG['models_dir'])\n",
    "if models_dir.exists():\n",
    "    model_dirs = sorted(models_dir.glob('tft_model_*'))\n",
    "    if model_dirs:\n",
    "        latest_model = model_dirs[-1]\n",
    "        print(f\"âœ… Latest model: {latest_model.name}\")\n",
    "        \n",
    "        # Check model files\n",
    "        files = list(latest_model.glob('*'))\n",
    "        print(\"\\nğŸ“¦ Model contents:\")\n",
    "        for f in files:\n",
    "            size_kb = f.stat().st_size / 1024\n",
    "            print(f\"   {f.name}: {size_kb:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83953434-2b7f-44b1-9623-2decec170ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple usage\n",
    "from tft_dashboard import run_dashboard\n",
    "run_dashboard(runtime_min=15, refresh_sec=30, fleet_size=25)\n",
    "\n",
    "# Advanced usage\n",
    "from tft_dashboard import LiveDashboard, CONFIG\n",
    "config = CONFIG.copy()\n",
    "config['TOTAL_RUNTIME_MIN'] = 20\n",
    "config['FLEET_SIZE'] = 30\n",
    "dashboard = LiveDashboard(config=config)\n",
    "dashboard.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8c270-b813-4fdd-82df-8eb5bd0c8f26",
   "metadata": {},
   "source": [
    "## ğŸ”® Inference & Predictions\n",
    "\n",
    "Run predictions on:\n",
    "- Sample data (automatic generation)\n",
    "- Your own metrics\n",
    "- Real-time data streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60fc6f-fd98-472c-9dcb-4fc1b5ed976a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Run predictions with sample data\n",
    "print(\"STEP 5: Model Inference\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"\\nğŸ”® Running predictions on sample data...\")\n",
    "\n",
    "# Make predictions\n",
    "results = predict()\n",
    "\n",
    "if results and 'predictions' in results:\n",
    "    print(\"\\nğŸ“ˆ Predictions (next 30 minutes):\")\n",
    "    for metric, values in results['predictions'].items():\n",
    "        current = values[0]\n",
    "        future = values[-1]\n",
    "        trend = \"ğŸ“ˆ\" if future > current else \"ğŸ“‰\" if future < current else \"â¡ï¸\"\n",
    "        print(f\"   {metric}: {current:.1f} {trend} {future:.1f}\")\n",
    "    \n",
    "    if results.get('alerts'):\n",
    "        print(f\"\\nâš ï¸  {len(results['alerts'])} alerts generated:\")\n",
    "        for alert in results['alerts'][:3]:\n",
    "            icon = \"ğŸ”´\" if alert['severity'] == 'critical' else \"ğŸŸ¡\"\n",
    "            print(f\"   {icon} {alert['metric']}: {alert['value']:.1f} (step {alert['steps_ahead']})\")\n",
    "    else:\n",
    "        print(\"\\nâœ… No alerts - system healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19c80b-bb17-41b8-9f21-829268e8ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Test with custom metrics data\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"STEP 6: Custom Predictions\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create custom metrics showing gradual CPU increase\n",
    "custom_data = []\n",
    "base_cpu = 40\n",
    "for i in range(30):  # 30 time points = 2.5 hours\n",
    "    custom_data.append({\n",
    "        'timestamp': (datetime.now() - timedelta(minutes=5*i)).isoformat(),\n",
    "        'cpu_percent': base_cpu + (i * 1.5) + np.random.normal(0, 3),  # Gradual increase\n",
    "        'memory_percent': 60 + np.random.normal(0, 5),\n",
    "        'disk_percent': 45 + np.random.normal(0, 2),\n",
    "        'load_average': 2.0 + (i * 0.05) + np.random.normal(0, 0.2)\n",
    "    })\n",
    "\n",
    "print(\"\\nğŸ“Š Testing with trending CPU increase scenario...\")\n",
    "results = predict(custom_data)\n",
    "\n",
    "if results and 'alerts' in results:\n",
    "    critical = [a for a in results['alerts'] if a['severity'] == 'critical']\n",
    "    warnings = [a for a in results['alerts'] if a['severity'] == 'warning']\n",
    "    \n",
    "    print(f\"\\nğŸš¨ Alert Summary:\")\n",
    "    print(f\"   Critical: {len(critical)}\")\n",
    "    print(f\"   Warnings: {len(warnings)}\")\n",
    "    \n",
    "    if critical:\n",
    "        print(\"\\nğŸ”´ Critical Alerts:\")\n",
    "        for alert in critical[:2]:\n",
    "            print(f\"   {alert['metric']} will reach {alert['value']:.1f} in {alert['steps_ahead']*5} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ce81f-4afc-4b4f-9e9e-9b15ee4823c8",
   "metadata": {},
   "source": [
    "## ğŸ“Š Visualization & Analysis\n",
    "\n",
    "Optional: Visualize predictions and trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0964e2e-579a-4a0f-be18-f73d0219f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Optional: Visualize predictions\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    if results and 'predictions' in results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        fig.suptitle('TFT Predictions - Next 30 Minutes', fontsize=14)\n",
    "        \n",
    "        metrics = list(results['predictions'].keys())[:4]\n",
    "        \n",
    "        for idx, (ax, metric) in enumerate(zip(axes.flat, metrics)):\n",
    "            if metric in results['predictions']:\n",
    "                values = results['predictions'][metric]\n",
    "                time_points = [i*5 for i in range(len(values))]\n",
    "                \n",
    "                ax.plot(time_points, values, 'b-', linewidth=2, label='Prediction')\n",
    "                ax.fill_between(time_points, \n",
    "                               [v*0.9 for v in values], \n",
    "                               [v*1.1 for v in values], \n",
    "                               alpha=0.2, color='blue', label='Uncertainty')\n",
    "                \n",
    "                # Add threshold lines\n",
    "                if metric in CONFIG['alert_thresholds']:\n",
    "                    warning = CONFIG['alert_thresholds'][metric]['warning']\n",
    "                    critical = CONFIG['alert_thresholds'][metric]['critical']\n",
    "                    ax.axhline(y=warning, color='orange', linestyle='--', alpha=0.7, label='Warning')\n",
    "                    ax.axhline(y=critical, color='red', linestyle='--', alpha=0.7, label='Critical')\n",
    "                \n",
    "                ax.set_title(metric.replace('_', ' ').title())\n",
    "                ax.set_xlabel('Minutes Ahead')\n",
    "                ax.set_ylabel('Value')\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                ax.legend(loc='best', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"ğŸ“Š Visualization complete\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸  Matplotlib not installed - skipping visualization\")\n",
    "    print(\"   Install with: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc67e59-c2bc-4481-92f1-8f7fc9368165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enhanced_inference import predict_8_hours\n",
    "\n",
    "# Simple prediction\n",
    "results = predict_8_hours(visualize=True)\n",
    "\n",
    "results = predict_8_hours(\n",
    "    data=None,  # This will generate sample data\n",
    "    visualize=True,\n",
    "    save_plots=\"./plots/my_analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade0de6-cf15-4227-a710-6f7f27f3b1af",
   "metadata": {},
   "source": [
    "## ğŸ¯ Production Deployment\n",
    "\n",
    "### Command Line Usage\n",
    "```bash\n",
    "# Generate larger datasets\n",
    "python metrics_generator.py --hours 720  # 30 days\n",
    "\n",
    "# Train with custom parameters\n",
    "python tft_trainer.py --epochs 50 --batch-size 64\n",
    "\n",
    "# Run inference on JSON file\n",
    "python tft_inference.py --input metrics.json --output predictions.json\n",
    "\n",
    "# Use main interface\n",
    "python main.py generate --hours 720\n",
    "python main.py train --epochs 50\n",
    "python main.py predict --input data.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbc193-db27-40db-a6ab-a160d991b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct module usage\n",
    "from metrics_generator import generate_dataset\n",
    "from tft_trainer import train_model\n",
    "from tft_inference import predict\n",
    "\n",
    "# Generate 30 days\n",
    "dataset = generate_dataset(hours=720)\n",
    "\n",
    "# Train with custom config\n",
    "model_path = train_model({'epochs': 50, 'batch_size': 64})\n",
    "\n",
    "# Predict\n",
    "results = predict(data, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008aed9-159a-477d-b370-0c31a62880cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Cell 17 - Code**\n",
    "```python\n",
    "# 8. Final system check\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ‰ TFT MONITORING SYSTEM READY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "status()\n",
    "\n",
    "print(\"\\nğŸ’¡ Quick Reference:\")\n",
    "print(\"   generate_dataset(hours=336)  # Generate 2 weeks\")\n",
    "print(\"   train(epochs=30)             # Train model\")\n",
    "print(\"   predict(data)                # Run predictions\")\n",
    "print(\"   status()                     # Check status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac83151d-9dba-40d8-8066-8bd3d5a9da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Export configuration for reference\n",
    "import json\n",
    "\n",
    "config_summary = {\n",
    "    'time_span_hours': CONFIG['time_span_hours'],\n",
    "    'servers_count': CONFIG['servers_count'],\n",
    "    'prediction_horizon': CONFIG['prediction_horizon'],\n",
    "    'context_length': CONFIG['context_length'],\n",
    "    'batch_size': CONFIG['batch_size'],\n",
    "    'epochs': CONFIG['epochs'],\n",
    "    'alert_thresholds': CONFIG['alert_thresholds']\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Current Configuration:\")\n",
    "print(json.dumps(config_summary, indent=2))\n",
    "\n",
    "# Save for reference\n",
    "with open('tft_config_summary.json', 'w') as f:\n",
    "    json.dump(config_summary, f, indent=2)\n",
    "print(\"\\nğŸ’¾ Configuration saved to: tft_config_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53934dde-0c83-49f7-b4fb-69197e673476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422980d1-1fb8-4eee-b9c8-24d9628e1ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fcf354-1e0f-4eda-85ef-eef4fdc1f6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
