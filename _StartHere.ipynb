{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b664434c-2386-4102-9816-fec64191fc93",
   "metadata": {},
   "source": [
    "# üöÄ TFT Monitoring System - Complete Pipeline\n",
    "\n",
    "## Temporal Fusion Transformer for Server Monitoring & Prediction\n",
    "\n",
    "### üìã **What This Notebook Does:**\n",
    "1. **Setup & Validation** - Check environment and dependencies\n",
    "2. **Demo Data Generation** - Create realistic 5-minute server fleet simulation\n",
    "3. **Production Data Generation** - Generate large-scale training datasets\n",
    "4. **Model Training** - Train TFT models (fleet-wide or per-server)\n",
    "5. **Live Dashboards** - Interactive monitoring with real-time visualization\n",
    "\n",
    "### üéØ **Key Features:**\n",
    "- **Multi-horizon forecasting**: Predict up to 8 hours ahead (96 timesteps)\n",
    "- **Parquet-first**: Fast binary format for large datasets\n",
    "- **Attention mechanism**: Automatic feature importance detection\n",
    "- **Per-server models**: Train specialized models for each server\n",
    "- **Live dashboards**: Real-time monitoring with anomaly detection\n",
    "\n",
    "### ‚è±Ô∏è **Estimated Cell Execution Times:**\n",
    "- **Cells 1-3** (Setup): < 5 seconds each\n",
    "- **Cell 4** (Demo Data): ~5-10 seconds\n",
    "- **Cell 5** (Demo Dashboard): Runs continuously (5 minutes total)\n",
    "- **Cell 6** (24h Dataset): ~30-60 seconds | (720h Dataset): ~5-10 minutes\n",
    "- **Cell 7** (Train 20 epochs): **~6-10 hours** | (Train 5 epochs): ~1.5-2.5 hours\n",
    "- **Cell 8** (Inspect): < 1 second\n",
    "- **Cell 9** (Dashboard): Runs continuously\n",
    "- **Cells 10-12**: < 2 seconds each\n",
    "\n",
    "### ‚ö° **Quick Start:**\n",
    "Run cells in order for a complete demo, or jump to specific sections:\n",
    "- **Demo** ‚Üí Cells 2-6 (5 minutes)\n",
    "- **Production Training** ‚Üí Cells 7-10 (1-10 hours depending on epochs)\n",
    "- **Dashboard** ‚Üí Cells 11-12 (continuous)\n",
    "\n",
    "---\n",
    "\n",
    "**Architecture:** PyTorch 2.0+ | Lightning 2.0+ | PyTorch Forecasting 1.0  \n",
    "**Model:** TemporalFusionTransformer with multi-head attention  \n",
    "**Hardware:** Best with GPU (RTX 4090 or similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de56814-6916-4486-a51f-820769085b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TFT Monitoring System - Optimized Pipeline\n",
      "============================================================\n",
      "‚úÖ Configuration loaded\n",
      "üìä Training time span: 720 hours\n",
      "üñ•Ô∏è  Fleet size: 15 servers\n",
      "üîÆ Prediction horizon: 96 steps (8 hours)\n",
      "üìà Context length: 288 steps (24 hours)\n",
      "============================================================\n",
      "\n",
      "‚è±Ô∏è  Cell execution time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import and Setup\n",
    "# Expected time: < 5 seconds\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from config import CONFIG\n",
    "\n",
    "print(\"üéØ TFT Monitoring System - Optimized Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"üìä Training time span: {CONFIG['time_span_hours']} hours\")\n",
    "print(f\"üñ•Ô∏è  Fleet size: {CONFIG['servers_count']} servers\")\n",
    "print(f\"üîÆ Prediction horizon: {CONFIG['prediction_horizon']} steps (8 hours)\")\n",
    "print(f\"üìà Context length: {CONFIG['context_length']} steps (24 hours)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b1dcb05-a904-46c2-9780-2910dca3e62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç STEP 1: Environment Validation\n",
      "------------------------------------------------------------\n",
      "üîç Validating environment...\n",
      "‚úÖ PyTorch: 2.0.1+cu118\n",
      "‚úÖ Lightning: 2.0.2\n",
      "‚úÖ PyTorch Forecasting: 1.0.0\n",
      "‚úÖ Pandas: 2.2.2\n",
      "‚úÖ PyArrow (Parquet): 14.0.2\n",
      "üî• Device: GPU (NVIDIA GeForce RTX 4090)\n",
      "\n",
      "‚úÖ Environment ready for TFT training!\n",
      "üì¶ All dependencies installed\n",
      "üöÄ Ready to proceed with data generation\n",
      "\n",
      "‚è±Ô∏è  Cell execution time: 7.84 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Environment Validation\n",
    "# Expected time: < 5 seconds\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from main import setup\n",
    "\n",
    "print(\"üîç STEP 1: Environment Validation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if setup():\n",
    "    print(\"\\n‚úÖ Environment ready for TFT training!\")\n",
    "    print(\"üì¶ All dependencies installed\")\n",
    "    print(\"üöÄ Ready to proceed with data generation\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Setup failed - install missing dependencies\")\n",
    "    print(\"   pip install torch lightning pytorch-forecasting safetensors pandas pyarrow\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f89e52-654b-4adb-b4d8-9520b70b1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä STEP 2: System Status\n",
      "------------------------------------------------------------\n",
      "üîç System Status\n",
      "==================================================\n",
      "‚úÖ Datasets (Parquet): 1 file(s)\n",
      "   Latest: server_metrics.parquet\n",
      "   Rows: 432,000\n",
      "   Servers: 25\n",
      "   Time range: 2025-10-09 14:22:07.728110+00:00 to 2025-10-10 14:22:02.728110+00:00\n",
      "‚úÖ Models: 1 trained model(s)\n",
      "   Latest: tft_model_20251010_122056\n",
      "   Format: Safetensors ‚úÖ\n",
      "üî• Device: GPU (NVIDIA GeForce RTX 4090)\n",
      "\n",
      "üí° Tip: Run this cell anytime to check datasets, models, and device status\n",
      "\n",
      "‚è±Ô∏è  Cell execution time: 0.16 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: System Status Check\n",
    "# Expected time: < 2 seconds\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from main import status\n",
    "\n",
    "print(\"üìä STEP 2: System Status\")\n",
    "print(\"-\" * 60)\n",
    "status()\n",
    "print(\"\\nüí° Tip: Run this cell anytime to check datasets, models, and device status\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a2fac-a9b1-40fc-b156-3fe20cdb36ef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üé¨ DEMO MODE: Quick 5-Minute Simulation\n",
    "\n",
    "Generate demo data with configurable health scenarios for testing and visualization.\n",
    "\n",
    "**Scenarios:**\n",
    "- **HEALTHY** - 100% healthy system, stable baselines, no issues\n",
    "- **DEGRADING** (default) - System starts healthy and gradually degrades (CPU, RAM, IOWait increase)\n",
    "- **CRITICAL** - System starts healthy, then shows acute failure signs with severe spikes\n",
    "\n",
    "**DEGRADING Pattern:**\n",
    "- `0:00-1:30` - Stable baseline (healthy)\n",
    "- `1:30-2:30` - Gradual escalation (warnings)\n",
    "- `2:30-3:30` - Incident peak (critical)\n",
    "- `3:30-5:00` - Recovery to normal\n",
    "\n",
    "Perfect for testing dashboards and understanding the system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c64b89-0c7c-4197-91be-b15582f08fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Generate Demo Dataset (5 minutes with configurable scenario)\n",
    "# Expected time: 5-10 seconds\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from demo_data_generator import generate_demo_dataset\n",
    "\n",
    "print(\"üé¨ STEP 3: Demo Data Generation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Configuration - ADJUST THESE VALUES\n",
    "DEMO_DURATION_MIN = 5      # 5-minute simulation\n",
    "DEMO_FLEET_SIZE = 10       # 10 servers\n",
    "DEMO_SEED = 42            # Reproducible results\n",
    "DEMO_SCENARIO = 'degrading'  # Options: 'healthy', 'degrading', 'critical'\n",
    "DEMO_OUTPUT_DIR = \"./demo_data/\"\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Duration: {DEMO_DURATION_MIN} minutes\")\n",
    "print(f\"   Fleet size: {DEMO_FLEET_SIZE} servers\")\n",
    "print(f\"   Scenario: {DEMO_SCENARIO.upper()}\")\n",
    "print(f\"   Random seed: {DEMO_SEED}\")\n",
    "print(f\"   Output: {DEMO_OUTPUT_DIR}\")\n",
    "print()\n",
    "\n",
    "scenario_descriptions = {\n",
    "    'healthy': '100% healthy system, no issues',\n",
    "    'degrading': 'Gradual resource exhaustion (CPU, RAM, IOWait)',\n",
    "    'critical': 'Acute failures with severe spikes'\n",
    "}\n",
    "print(f\"üìù Scenario: {scenario_descriptions.get(DEMO_SCENARIO, 'Unknown')}\")\n",
    "print()\n",
    "\n",
    "# Generate demo data\n",
    "success = generate_demo_dataset(\n",
    "    output_dir=DEMO_OUTPUT_DIR,\n",
    "    duration_minutes=DEMO_DURATION_MIN,\n",
    "    fleet_size=DEMO_FLEET_SIZE,\n",
    "    seed=DEMO_SEED,\n",
    "    scenario=DEMO_SCENARIO\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ Demo dataset generated successfully!\")\n",
    "    print(f\"üìÅ Location: {DEMO_OUTPUT_DIR}demo_dataset.parquet\")\n",
    "    print(f\"üìä Data points: ~{DEMO_DURATION_MIN * 12 * DEMO_FLEET_SIZE:,}\")\n",
    "    print(\"\\nüéØ Ready for dashboard visualization!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Demo generation failed\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516aebac-a847-468a-83e5-4e3bf31f1ed9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä DEMO DASHBOARD: Interactive Visualization\n",
    "\n",
    "Run the live dashboard with demo data. This shows:\n",
    "- Fleet-wide aggregate metrics\n",
    "- Per-server trends\n",
    "- Anomaly detection and highlighting\n",
    "- Real-time metric updates\n",
    "\n",
    "**Note:** Dashboard will refresh every 5 seconds and show the incident pattern evolving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb702cdf-261c-4504-a54b-6b5b5506169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Run Demo Dashboard (Interactive)\n",
    "# Expected time: Runs continuously for ~5 minutes (duration of demo data)\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from tft_dashboard_refactored import run_dashboard\n",
    "\n",
    "print(\"üìä STEP 4: Demo Dashboard\")\n",
    "print(\"-\" * 60)\n",
    "print(\"üöÄ Launching interactive dashboard...\")\n",
    "print(\"‚è±Ô∏è  Will run until data is exhausted\")\n",
    "print(\"üì° Tick interval: 5 seconds (data ingestion)\")\n",
    "print(\"üîÑ Refresh interval: 30 seconds (visualization)\")\n",
    "print(\"‚ö†Ô∏è  Press Ctrl+C to stop early\")\n",
    "print()\n",
    "\n",
    "# Run dashboard with demo data\n",
    "try:\n",
    "    run_dashboard(\n",
    "        data_path=\"./demo_data/demo_dataset.parquet\",\n",
    "        data_format='parquet',\n",
    "        tick_interval_sec=5,   # Ingest data every 5 seconds (like real-time)\n",
    "        refresh_sec=30,        # Refresh visualizations every 30 seconds\n",
    "        save_plots=False\n",
    "    )\n",
    "    print(\"\\n‚úÖ Dashboard completed!\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚è∏Ô∏è  Dashboard stopped by user\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Dashboard error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "_mins = int(_cell_elapsed // 60)\n",
    "_secs = int(_cell_elapsed % 60)\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_mins}m {_secs}s ({_cell_elapsed:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebbc05c-969c-475d-93e1-2abb8fe8ced3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè≠ PRODUCTION MODE: Large-Scale Training\n",
    "\n",
    "Generate production-quality datasets for serious model training.\n",
    "\n",
    "**Options:**\n",
    "- **24 hours** (default) - Quick training, good for testing (~30-60 seconds generation)\n",
    "- **168 hours** (1 week) - Captures weekly patterns (~2-3 minutes generation)\n",
    "- **720 hours** (30 days) - Best performance, captures all patterns (~5-10 minutes generation)\n",
    "\n",
    "Generated data is in Parquet format (3-5x faster than CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83953434-2b7f-44b1-9623-2decec170ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ STEP 5: Production Data Generation\n",
      "------------------------------------------------------------\n",
      "‚öôÔ∏è  Configuration:\n",
      "   Time span: 24 hours (1.0 days)\n",
      "   Servers: 15\n",
      "   Estimated samples: ~4,320\n",
      "   Output: ./training/\n",
      "\n",
      "üöÄ Generating production dataset...\n",
      "‚è±Ô∏è  This may take several minutes for large datasets...\n",
      "\n",
      "‚è∞ Time Range:\n",
      "   Start: 2025-10-09 16:33:54.663072+00:00\n",
      "   End:   2025-10-10 16:33:49.663072+00:00\n",
      "   Duration: 0 days 23:59:55\n",
      "   (Data ends at current time, starts 24 hours ago)\n",
      "\n",
      "üìä Parquet written: training\\server_metrics.parquet (432,000 rows, 27.9 MB)\n",
      "\n",
      "‚úÖ Production dataset generated!\n",
      "üìÅ Location: ./training/\n",
      "üéØ Ready for model training!\n",
      "üìä Latest file: server_metrics.parquet (27.9 MB)\n",
      "\n",
      "‚è±Ô∏è  Cell execution time: 4m 21s (261.8 seconds)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Generate Production Training Dataset\n",
    "# Expected time: 24h=30-60s | 168h=2-3min | 720h=5-10min\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from metrics_generator import generate_dataset\n",
    "\n",
    "print(\"üè≠ STEP 5: Production Data Generation\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Configuration - ADJUST THESE VALUES\n",
    "#TRAINING_HOURS = 720  # 30 days recommended for best results\n",
    "# TRAINING_HOURS = 168  # 1 week for faster training\n",
    "TRAINING_HOURS = 24   # Quick test\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Time span: {TRAINING_HOURS} hours ({TRAINING_HOURS/24:.1f} days)\")\n",
    "print(f\"   Servers: {CONFIG['servers_count']}\")\n",
    "print(f\"   Estimated samples: ~{TRAINING_HOURS * 12 * CONFIG['servers_count']:,}\")\n",
    "print(f\"   Output: {CONFIG['training_dir']}\")\n",
    "print()\n",
    "\n",
    "print(\"üöÄ Generating production dataset...\")\n",
    "print(\"‚è±Ô∏è  This may take several minutes for large datasets...\")\n",
    "\n",
    "success = generate_dataset(hours=TRAINING_HOURS)\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ Production dataset generated!\")\n",
    "    print(f\"üìÅ Location: {CONFIG['training_dir']}\")\n",
    "    print(\"üéØ Ready for model training!\")\n",
    "    \n",
    "    # Show what was created\n",
    "    training_path = Path(CONFIG['training_dir'])\n",
    "    parquet_files = list(training_path.glob(\"*.parquet\"))\n",
    "    if parquet_files:\n",
    "        latest = max(parquet_files, key=lambda p: p.stat().st_mtime)\n",
    "        size_mb = latest.stat().st_size / (1024 * 1024)\n",
    "        print(f\"üìä Latest file: {latest.name} ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Generation failed\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "_mins = int(_cell_elapsed // 60)\n",
    "_secs = int(_cell_elapsed % 60)\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_mins}m {_secs}s ({_cell_elapsed:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8c270-b813-4fdd-82df-8eb5bd0c8f26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ MODEL TRAINING: TFT Neural Network\n",
    "\n",
    "Train the Temporal Fusion Transformer on your data.\n",
    "\n",
    "**Options:**\n",
    "- **Fleet-wide model** - Single model for all servers (faster)\n",
    "- **Per-server models** - Specialized model per server (better accuracy)\n",
    "\n",
    "**Training Features:**\n",
    "- Automatic GPU acceleration\n",
    "- Early stopping to prevent overfitting\n",
    "- Learning rate monitoring\n",
    "- Checkpoint saving\n",
    "- TensorBoard logging\n",
    "\n",
    "**‚è±Ô∏è Expected Training Times (RTX 4090):**\n",
    "- **5 epochs**: ~1.5-2.5 hours\n",
    "- **10 epochs**: ~3-5 hours\n",
    "- **20 epochs**: ~6-10 hours\n",
    "- **30 epochs**: ~9-15 hours\n",
    "\n",
    "*Times vary based on dataset size and GPU. Each epoch ~20-30 minutes on 432K samples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e60fc6f-fd98-472c-9dcb-4fc1b5ed976a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ STEP 6: Model Training\n",
      "------------------------------------------------------------\n",
      "‚öôÔ∏è  Configuration:\n",
      "   Epochs: 10\n",
      "   Batch size: 32\n",
      "   Learning rate: 0.01\n",
      "   Mode: Fleet-wide\n",
      "   Dataset: ./training/\n",
      "\n",
      "‚è±Ô∏è  Estimated training time: 3h 20m - 5h 0m\n",
      "   (Based on ~20-30 minutes per epoch on RTX 4090 with 432K samples)\n",
      "\n",
      "üöÄ Starting TFT training...\n",
      "üî• Using GPU if available\n",
      "\n",
      "[TRAIN] Starting TFT training (Phase 2 optimized)...\n",
      " Random seed set to 42 for reproducibility\n",
      "[SEARCH] Looking for dataset in: D:\\machine_learning\\MonitoringPrediction\\training\n",
      "[DIR] Files found: ['desktop.ini', 'metrics_metadata.json', 'server_metrics.parquet']\n",
      "[INFO] Loading parquet dataset: training\\server_metrics.parquet\n",
      "[OK] Loaded 432,000 records from parquet\n",
      "[PREP] Preparing data for TFT training...\n",
      "[INFO] Original columns: ['timestamp', 'server_name', 'profile', 'state', 'problem_child', 'cpu_pct', 'mem_pct', 'disk_io_mb_s', 'net_in_mb_s', 'net_out_mb_s', 'latency_ms', 'error_rate', 'gc_pause_ms', 'container_oom', 'notes']\n",
      "[INFO] Using server column: server_name\n",
      "[INFO] Mapped cpu_pct -> cpu_percent\n",
      "[INFO] Mapped mem_pct -> memory_percent\n",
      "[INFO] Mapped disk_io_mb_s -> disk_percent\n",
      "[INFO] Mapped latency_ms -> load_average\n",
      "[INFO] Mapped state -> status\n",
      "[INFO] Encoded 25 server_names to server_id\n",
      "[INFO] Available metrics: ['cpu_percent', 'memory_percent', 'disk_percent', 'load_average']\n",
      "[OK] Data prepared: (432000, 26)\n",
      "[INFO] Final columns: ['timestamp', 'server_name', 'profile', 'state', 'problem_child', 'cpu_pct', 'mem_pct', 'disk_io_mb_s', 'net_in_mb_s', 'net_out_mb_s', 'latency_ms', 'error_rate', 'gc_pause_ms', 'container_oom', 'notes', 'time_idx', 'hour', 'day_of_week', 'month', 'is_weekend', 'cpu_percent', 'memory_percent', 'disk_percent', 'load_average', 'status', 'server_id']\n",
      "[INFO] Creating TimeSeriesDataSets...\n",
      "[INFO] Min series length: 17280\n",
      "[INFO] Using encoder length: 288, prediction length: 96\n",
      "[INFO] Validation split: 20.0% | Training cutoff: 13824\n",
      "[INFO] Single-target mode: cpu_percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Training samples: 348000\n",
      "[OK] Validation samples: 25\n",
      " Data loading: 4 workers, pin_memory=True\n",
      "[OK] Model created with 86,841 parameters\n",
      "[SAVE] Checkpointing enabled: ./checkpoints/\n",
      "[INFO] TensorBoard logging: ./logs/tft_training\\20251010_124323\n",
      "[TRAIN] Learning rate monitoring enabled\n",
      "[INFO] Enhanced progress reporting enabled\n",
      "[STOP] Early stopping: patience=8\n",
      "[START] Training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 40    \n",
      "3  | prescalers                         | ModuleDict                      | 384   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 5.7 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 18.7 K\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 9.8 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K \n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K \n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 2.4 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K \n",
      "20 | output_layer                       | Linear                          | 231   \n",
      "----------------------------------------------------------------------------------------\n",
      "86.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "86.8 K    Total params\n",
      "0.347     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "[START] TRAINING STARTED\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ade30c4ec34a42a0abdc9c50e6a848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Epoch 1/10 completed in 1587.5s\n",
      "   Train Loss: 2.8871 | Val Loss: 3.5738 [BEST] NEW BEST\n",
      "   Progress: [1/10] 10.0%\n",
      "   ETA: 238.1 min | Elapsed: 26.5 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 3.574\n",
      "Epoch 0, global step 10875: 'val_loss' reached 3.57376 (best 3.57376), saving model to 'checkpoints\\\\tft-epoch=00-val_loss=3.5738.ckpt' as top 3\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Train TFT Model (Fleet-wide)\n",
    "# Expected time: 5 epochs=1.5-2.5h | 20 epochs=6-10h | 30 epochs=9-15h\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from main import train\n",
    "\n",
    "print(\"ü§ñ STEP 6: Model Training\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Configuration - ADJUST THESE VALUES\n",
    "TRAINING_EPOCHS = 10  # Default: 20, increase for better accuracy\n",
    "PER_SERVER_MODE = False  # Set to True for per-server models\n",
    "\n",
    "print(f\"‚öôÔ∏è  Configuration:\")\n",
    "print(f\"   Epochs: {TRAINING_EPOCHS}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   Mode: {'Per-server' if PER_SERVER_MODE else 'Fleet-wide'}\")\n",
    "print(f\"   Dataset: {CONFIG['training_dir']}\")\n",
    "print()\n",
    "\n",
    "# Estimate training time\n",
    "est_mins_low = TRAINING_EPOCHS * 20\n",
    "est_mins_high = TRAINING_EPOCHS * 30\n",
    "print(f\"‚è±Ô∏è  Estimated training time: {est_mins_low//60}h {est_mins_low%60}m - {est_mins_high//60}h {est_mins_high%60}m\")\n",
    "print(\"   (Based on ~20-30 minutes per epoch on RTX 4090 with 432K samples)\")\n",
    "print()\n",
    "\n",
    "print(\"üöÄ Starting TFT training...\")\n",
    "print(\"üî• Using GPU if available\")\n",
    "print()\n",
    "\n",
    "model_path = train(\n",
    "    dataset_path=CONFIG['training_dir'],\n",
    "    epochs=TRAINING_EPOCHS,\n",
    "    per_server=PER_SERVER_MODE\n",
    ")\n",
    "\n",
    "if model_path:\n",
    "    print(\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"üìÅ Model saved: {model_path}\")\n",
    "    print(\"üéØ Ready for inference and prediction!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Training failed - check logs above\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "_hours = int(_cell_elapsed // 3600)\n",
    "_mins = int((_cell_elapsed % 3600) // 60)\n",
    "_secs = int(_cell_elapsed % 60)\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_hours}h {_mins}m {_secs}s ({_cell_elapsed:.1f} seconds total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b19c80b-bb17-41b8-9f21-829268e8ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Inspect Trained Model\n",
    "# Expected time: < 1 second\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîç STEP 7: Model Inspection\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "models_dir = Path(CONFIG['models_dir'])\n",
    "\n",
    "if models_dir.exists():\n",
    "    model_dirs = sorted(models_dir.glob('tft_model_*'), key=lambda p: p.stat().st_mtime)\n",
    "    \n",
    "    if model_dirs:\n",
    "        print(f\"‚úÖ Found {len(model_dirs)} trained model(s)\\n\")\n",
    "        \n",
    "        # Show latest model\n",
    "        latest_model = model_dirs[-1]\n",
    "        print(f\"üì¶ Latest Model: {latest_model.name}\")\n",
    "        print(f\"üìÖ Created: {latest_model.stat().st_mtime}\")\n",
    "        print()\n",
    "        \n",
    "        # List model files\n",
    "        print(\"üìÅ Model Contents:\")\n",
    "        for file in sorted(latest_model.glob('*')):\n",
    "            size_kb = file.stat().st_size / 1024\n",
    "            if size_kb > 1024:\n",
    "                print(f\"   {file.name}: {size_kb/1024:.1f} MB\")\n",
    "            else:\n",
    "                print(f\"   {file.name}: {size_kb:.1f} KB\")\n",
    "        \n",
    "        # Check for safetensors\n",
    "        if (latest_model / \"model.safetensors\").exists():\n",
    "            print(\"\\n‚úÖ Model format: Safetensors (secure)\")\n",
    "        elif (latest_model / \"model.pth\").exists():\n",
    "            print(\"\\n‚ö†Ô∏è  Model format: PyTorch (legacy)\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå No models found - run training first\")\n",
    "else:\n",
    "    print(\"‚ùå Models directory not found\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2ce81f-4afc-4b4f-9e9e-9b15ee4823c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä PRODUCTION DASHBOARD: Live Monitoring\n",
    "\n",
    "Run the dashboard with production training data for continuous monitoring.\n",
    "\n",
    "This dashboard reads from your training dataset and shows:\n",
    "- Real-time metric trends\n",
    "- Fleet-wide aggregates\n",
    "- Anomaly detection\n",
    "- Critical server identification\n",
    "\n",
    "**Use Cases:**\n",
    "- Monitor model training data quality\n",
    "- Validate data generation patterns\n",
    "- Test alerting thresholds\n",
    "- Demonstrate system capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0964e2e-579a-4a0f-be18-f73d0219f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Run Production Dashboard with Training Data\n",
    "# Expected time: Runs continuously (user-controlled)\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from tft_dashboard_refactored import run_dashboard\n",
    "\n",
    "print(\"üìä STEP 8: Production Dashboard\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Configuration\n",
    "DASHBOARD_TICK_INTERVAL_SEC = 5   # Ingest data every 5 seconds\n",
    "DASHBOARD_REFRESH_SEC = 30         # Refresh dashboard every 30 seconds\n",
    "\n",
    "# Find latest training data\n",
    "training_path = Path(CONFIG['training_dir'])\n",
    "parquet_files = list(training_path.glob(\"*.parquet\"))\n",
    "\n",
    "if parquet_files:\n",
    "    latest_data = max(parquet_files, key=lambda p: p.stat().st_mtime)\n",
    "    \n",
    "    print(f\"üìÅ Data source: {latest_data.name}\")\n",
    "    print(f\"üì° Tick interval: every {DASHBOARD_TICK_INTERVAL_SEC} seconds (data ingestion)\")\n",
    "    print(f\"üîÑ Refresh interval: every {DASHBOARD_REFRESH_SEC} seconds (visualization)\")\n",
    "    print(\"‚ö†Ô∏è  Press Ctrl+C to stop\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        run_dashboard(\n",
    "            data_path=str(latest_data),\n",
    "            data_format='parquet',\n",
    "            tick_interval_sec=DASHBOARD_TICK_INTERVAL_SEC,\n",
    "            refresh_sec=DASHBOARD_REFRESH_SEC,\n",
    "            save_plots=False\n",
    "        )\n",
    "        print(\"\\n‚úÖ Dashboard completed!\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚è∏Ô∏è  Dashboard stopped by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Dashboard error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå No training data found\")\n",
    "    print(\"   Run Cell 6 to generate production dataset first\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "_mins = int(_cell_elapsed // 60)\n",
    "_secs = int(_cell_elapsed % 60)\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_mins}m {_secs}s ({_cell_elapsed:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc67e59-c2bc-4481-92f1-8f7fc9368165",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ QUICK REFERENCE\n",
    "\n",
    "### Common Workflows\n",
    "\n",
    "**Quick Demo (5 minutes):**\n",
    "```python\n",
    "# Run cells 1-5 for complete demo with dashboard\n",
    "```\n",
    "\n",
    "**Production Training:**\n",
    "```python\n",
    "# 1. Generate data (Cell 6)\n",
    "# 2. Train model (Cell 7)\n",
    "# 3. Inspect model (Cell 8)\n",
    "```\n",
    "\n",
    "**Monitoring:**\n",
    "```python\n",
    "# Demo dashboard: Cell 5\n",
    "# Production dashboard: Cell 9\n",
    "```\n",
    "\n",
    "### Configuration Shortcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade0de6-cf15-4227-a710-6f7f27f3b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Quick Configuration Reference\n",
    "# Expected time: < 1 second\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "print(\"‚öôÔ∏è  CONFIGURATION QUICK REFERENCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìä Data Generation:\")\n",
    "print(f\"   CONFIG['time_span_hours'] = {CONFIG['time_span_hours']}\")\n",
    "print(f\"   CONFIG['servers_count'] = {CONFIG['servers_count']}\")\n",
    "print(f\"   CONFIG['training_dir'] = '{CONFIG['training_dir']}'\")\n",
    "\n",
    "print(\"\\nü§ñ Model Architecture:\")\n",
    "print(f\"   CONFIG['hidden_size'] = {CONFIG['hidden_size']}\")\n",
    "print(f\"   CONFIG['attention_heads'] = {CONFIG['attention_heads']}\")\n",
    "print(f\"   CONFIG['dropout'] = {CONFIG['dropout']}\")\n",
    "\n",
    "print(\"\\nüèãÔ∏è  Training:\")\n",
    "print(f\"   CONFIG['epochs'] = {CONFIG['epochs']}\")\n",
    "print(f\"   CONFIG['batch_size'] = {CONFIG['batch_size']}\")\n",
    "print(f\"   CONFIG['learning_rate'] = {CONFIG['learning_rate']}\")\n",
    "print(f\"   CONFIG['early_stopping_patience'] = {CONFIG['early_stopping_patience']}\")\n",
    "\n",
    "print(\"\\nüîÆ Prediction:\")\n",
    "print(f\"   CONFIG['prediction_horizon'] = {CONFIG['prediction_horizon']} steps (8 hours)\")\n",
    "print(f\"   CONFIG['context_length'] = {CONFIG['context_length']} steps (24 hours)\")\n",
    "print(f\"   CONFIG['min_encoder_length'] = {CONFIG['min_encoder_length']}\")\n",
    "\n",
    "print(\"\\nüìÅ Directories:\")\n",
    "print(f\"   Training: {CONFIG['training_dir']}\")\n",
    "print(f\"   Models: {CONFIG['models_dir']}\")\n",
    "print(f\"   Checkpoints: {CONFIG['checkpoints_dir']}\")\n",
    "print(f\"   Logs: {CONFIG['logs_dir']}\")\n",
    "\n",
    "print(\"\\nüí° Tip: Edit config.py to change these defaults\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efbc193-db27-40db-a6ab-a160d991b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: One-Command Demo Runner (Alternative)\n",
    "# Expected time: ~5 minutes (continuous dashboard)\n",
    "# This is equivalent to running run_demo.py from command line\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from run_demo import run_demo\n",
    "\n",
    "print(\"üöÄ ONE-COMMAND DEMO\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This cell combines data generation + dashboard in one step\")\n",
    "print()\n",
    "\n",
    "# Run complete demo\n",
    "run_demo(\n",
    "    duration_minutes=5,\n",
    "    fleet_size=10,\n",
    "    seed=42,\n",
    "    scenario='degrading',  # Options: 'healthy', 'degrading', 'critical'\n",
    "    tick_interval_seconds=5,   # Ingest data every 5 seconds (real-time simulation)\n",
    "    refresh_seconds=30,        # Refresh dashboard every 30 seconds\n",
    "    output_dir=\"./demo_data/\",\n",
    "    regenerate=False  # Set to True to force new data\n",
    ")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "_mins = int(_cell_elapsed // 60)\n",
    "_secs = int(_cell_elapsed % 60)\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_mins}m {_secs}s ({_cell_elapsed:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008aed9-159a-477d-b370-0c31a62880cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Final System Status\n",
    "# Expected time: < 2 seconds\n",
    "\n",
    "import time\n",
    "_cell_start = time.time()\n",
    "\n",
    "from main import status\n",
    "\n",
    "print(\"üéâ PIPELINE COMPLETE - FINAL STATUS\")\n",
    "print(\"=\" * 60)\n",
    "status()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TFT Monitoring System Ready!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìö Next Steps:\")\n",
    "print(\"   ‚Ä¢ Run demo dashboard (Cell 5)\")\n",
    "print(\"   ‚Ä¢ Train production model (Cell 7)\")\n",
    "print(\"   ‚Ä¢ Monitor with live dashboard (Cell 9)\")\n",
    "print(\"   ‚Ä¢ Check model performance in TensorBoard\")\n",
    "print()\n",
    "print(\"üí° Command Line:\")\n",
    "print(\"   python run_demo.py              # Quick demo\")\n",
    "print(\"   python main.py status           # Check status\")\n",
    "print(\"   python main.py generate --hours 720\")\n",
    "print(\"   python main.py train --epochs 30\")\n",
    "print()\n",
    "print(\"üìñ Documentation: See README.md and REPOMAP.md\")\n",
    "\n",
    "_cell_elapsed = time.time() - _cell_start\n",
    "print(f\"\\n‚è±Ô∏è  Cell execution time: {_cell_elapsed:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
