# Production Data Adapters

**Version:** 1.0.0
**Purpose:** Fetch real server metrics from production data stores and forward to TFT Inference Daemon

---

## 📋 Overview

These adapters provide production integration between your existing monitoring infrastructure (Linborg) and the TFT predictive monitoring system. They act as bridges, continuously fetching metrics and forwarding them for AI-powered predictions.

```
┌──────────────────────────────────────────────────────────────┐
│              PRODUCTION ARCHITECTURE                         │
└──────────────────────────────────────────────────────────────┘

Linborg Monitoring → MongoDB/Elasticsearch → Adapter → TFT Daemon → Dashboard
  (collects data)    (stores metrics)      (fetches)   (predicts)   (visualizes)
```

---

## 🗂️ Available Adapters

### 1. **MongoDB Adapter** (`mongodb_adapter.py`)
Fetches metrics from MongoDB collections.

**Best for:**
- ✅ Direct MongoDB storage of Linborg metrics
- ✅ Time-series collections
- ✅ Document-based metrics storage

### 2. **Elasticsearch Adapter** (`elasticsearch_adapter.py`)
Fetches metrics from Elasticsearch indices.

**Best for:**
- ✅ ELK stack (Elasticsearch + Logstash + Kibana)
- ✅ Filebeat/Metricbeat ingestion
- ✅ Time-series indices with rotation

⚠️ **Licensing Note:** Elasticsearch adapter uses the official `elasticsearch-py` client (read-only operations). Ensure compliance with Elastic License 2.0 or your organization's license agreement.

---

## 🚀 Quick Start

### Step 0: Generate API Key

**IMPORTANT:** The adapters require an API key to communicate with the TFT Inference Daemon. This key is automatically generated by the system.

```bash
# From project root directory
python generate_api_key.py

# This creates:
#   - .env file with TFT_API_KEY
#   - .streamlit/secrets.toml for dashboard
```

The adapters will **automatically load the API key from the `.env` file**. You do NOT need to manually copy it to your adapter configuration files.

### Step 1: Install Dependencies

```bash
# MongoDB adapter
pip install pymongo

# Elasticsearch adapter
pip install elasticsearch

# Both
pip install pymongo elasticsearch requests
```

### Step 2: Create Configuration

```bash
# MongoDB
cp mongodb_adapter_config.json.template mongodb_adapter_config.json
# Edit mongodb_adapter_config.json with your credentials

# Elasticsearch
cp elasticsearch_adapter_config.json.template elasticsearch_adapter_config.json
# Edit elasticsearch_adapter_config.json with your credentials
```

### Step 3: Test Connection

```bash
# Test MongoDB adapter (fetch once)
python mongodb_adapter.py --once --verbose

# Test Elasticsearch adapter (fetch once)
python elasticsearch_adapter.py --once --verbose
```

### Step 4: Run in Production

```bash
# MongoDB adapter daemon (continuous streaming)
python mongodb_adapter.py --daemon --interval 5

# Elasticsearch adapter daemon (continuous streaming)
python elasticsearch_adapter.py --daemon --interval 5
```

---

## ⚙️ Configuration

### MongoDB Configuration (`mongodb_adapter_config.json`)

```json
{
  "mongodb": {
    "uri": "mongodb://mongo.example.com:27017",
    "database": "linborg",
    "collection": "server_metrics",
    "username": "tft_readonly",
    "password": "your-secure-password"
  },
  "tft_daemon": {
    "url": "http://localhost:8000"
    // API key automatically loaded from .env file
    // No need to specify api_key here
  }
}
```

**MongoDB Connection URI formats:**
```bash
# Standalone
mongodb://localhost:27017

# With authentication
mongodb://username:password@localhost:27017

# Replica set
mongodb://host1:27017,host2:27017,host3:27017/?replicaSet=myReplicaSet

# MongoDB Atlas
mongodb+srv://username:password@cluster.mongodb.net/database
```

---

### Elasticsearch Configuration (`elasticsearch_adapter_config.json`)

```json
{
  "elasticsearch": {
    "hosts": ["es1.example.com:9200", "es2.example.com:9200"],
    "index_pattern": "linborg-metrics-*",
    "username": "tft_readonly",
    "password": "your-secure-password",
    "use_ssl": true,
    "verify_certs": true,
    "ca_certs": "/path/to/ca.pem"
  },
  "tft_daemon": {
    "url": "http://localhost:8000"
    // API key automatically loaded from .env file
    // No need to specify api_key here
  }
}
```

**Elasticsearch Index Patterns:**
```bash
# Time-based indices
"linborg-metrics-*"           # Matches: linborg-metrics-2025.10.17
"server-metrics-2025.*"       # Matches: server-metrics-2025.10.17
"metrics-*"                   # Matches all metrics indices

# Static index
"server_metrics"              # Single index
```

---

## 📊 Data Schema Mapping

Both adapters automatically transform your data to TFT-compatible format.

### Required Fields (LINBORG 14 Metrics)

| TFT Field | MongoDB Field | Elasticsearch Field | Description |
|-----------|---------------|---------------------|-------------|
| `timestamp` | `timestamp` | `@timestamp` | ISO 8601 timestamp |
| `server_name` | `server_name`, `hostname` | `server_name`, `host.name` | Server identifier |
| `profile` | `profile` | `profile`, `server_type` | Server profile (ml_compute, database, etc.) |
| `cpu_user_pct` | `cpu_user_pct` | `cpu.user.pct`, `system.cpu.user.pct` | CPU user % |
| `cpu_sys_pct` | `cpu_sys_pct` | `cpu.sys.pct`, `system.cpu.system.pct` | CPU system % |
| `cpu_iowait_pct` | `cpu_iowait_pct` | `cpu.iowait.pct`, `system.cpu.iowait.pct` | I/O wait % |
| `cpu_idle_pct` | `cpu_idle_pct` | `cpu.idle.pct`, `system.cpu.idle.pct` | CPU idle % |
| `java_cpu_pct` | `java_cpu_pct` | `java_cpu_pct` | Java process CPU |
| `mem_used_pct` | `mem_used_pct` | `memory.used.pct`, `system.memory.used.pct` | Memory used % |
| `swap_used_pct` | `swap_used_pct` | `swap.used.pct`, `system.swap.used.pct` | Swap used % |
| `disk_usage_pct` | `disk_usage_pct` | `disk.usage.pct`, `system.filesystem.used.pct` | Disk usage % |
| `net_in_mb_s` | `net_in_mb_s` | `network.in.mb_s` | Network inbound MB/s |
| `net_out_mb_s` | `net_out_mb_s` | `network.out.mb_s` | Network outbound MB/s |
| `back_close_wait` | `back_close_wait` | `back_close_wait` | Backend TCP CLOSE_WAIT |
| `front_close_wait` | `front_close_wait` | `front_close_wait` | Frontend TCP CLOSE_WAIT |
| `load_average` | `load_average` | `system.load.1` | 1-minute load average |
| `uptime_days` | `uptime_days` | `uptime_days` | Server uptime in days |

### Field Mapping Examples

**MongoDB Document:**
```json
{
  "_id": "...",
  "timestamp": "2025-10-17T12:00:00Z",
  "server_name": "ppml0001",
  "profile": "ml_compute",
  "cpu_user_pct": 65.4,
  "cpu_sys_pct": 12.3,
  "mem_used_pct": 85.2,
  ...
}
```

**Elasticsearch Document (Nested):**
```json
{
  "@timestamp": "2025-10-17T12:00:00Z",
  "host": {
    "name": "ppml0001"
  },
  "profile": "ml_compute",
  "system": {
    "cpu": {
      "user": {"pct": 0.654},
      "system": {"pct": 0.123}
    },
    "memory": {
      "used": {"pct": 0.852}
    }
  }
}
```

**Both transform to TFT format:**
```json
{
  "timestamp": "2025-10-17T12:00:00Z",
  "server_name": "ppml0001",
  "profile": "ml_compute",
  "cpu_user_pct": 65.4,
  "cpu_sys_pct": 12.3,
  "mem_used_pct": 85.2,
  ...
}
```

---

## 🔐 Security Best Practices

### 1. **API Key Authentication**

The adapters authenticate with the TFT Inference Daemon using an API key. This key is automatically managed by the system.

**How it works:**
1. Run `python generate_api_key.py` (done automatically by start scripts)
2. API key is written to `.env` file in project root
3. Adapters automatically load key from `.env` when they start
4. Key is sent as `X-API-Key` header with each HTTP request

**Priority order:**
1. `api_key` in adapter config file (if explicitly set)
2. `.env` file in project root (recommended)
3. `TFT_API_KEY` environment variable (fallback)

**Example `.env` file:**
```bash
TFT_API_KEY=abc123def456...
DAEMON_HOST=0.0.0.0
DAEMON_PORT=8000
```

**Manual override (optional):**
```json
{
  "tft_daemon": {
    "url": "http://localhost:8000",
    "api_key": "explicit-key-here"  // Override automatic loading
  }
}
```

### 2. **Use Read-Only Database Accounts**

```sql
-- MongoDB
db.createUser({
  user: "tft_readonly",
  pwd: "strong_password_here",
  roles: [{ role: "read", db: "linborg" }]
})

-- Elasticsearch (via Kibana or API)
POST /_security/role/tft_readonly
{
  "indices": [
    {
      "names": ["linborg-metrics-*"],
      "privileges": ["read"]
    }
  ]
}

POST /_security/user/tft_readonly
{
  "password": "strong_password_here",
  "roles": ["tft_readonly"]
}
```

### 2. **Secure Configuration Files**

```bash
# Restrict permissions
chmod 600 mongodb_adapter_config.json
chmod 600 elasticsearch_adapter_config.json

# Store in secure location
mv *_config.json /etc/tft/adapters/
```

### 3. **Use Environment Variables** (Alternative)

```bash
# Set environment variables instead of config file
export MONGODB_URI="mongodb://user:pass@host:27017/linborg"
export TFT_API_KEY="your-api-key"

# Adapter will fall back to environment variables
python mongodb_adapter.py --daemon
```

### 4. **Enable SSL/TLS**

```json
{
  "elasticsearch": {
    "use_ssl": true,
    "verify_certs": true,
    "ca_certs": "/path/to/ca-bundle.pem"
  }
}
```

---

## 🏗️ Production Deployment

### Option 1: Systemd Service (Linux)

Create `/etc/systemd/system/tft-mongodb-adapter.service`:

```ini
[Unit]
Description=TFT MongoDB Adapter
After=network.target mongodb.service

[Service]
Type=simple
User=tft
Group=tft
WorkingDirectory=/opt/tft-monitoring/adapters
ExecStart=/opt/tft-monitoring/venv/bin/python mongodb_adapter.py --daemon --config /etc/tft/mongodb_adapter_config.json
Restart=on-failure
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Enable and start:
```bash
sudo systemctl daemon-reload
sudo systemctl enable tft-mongodb-adapter
sudo systemctl start tft-mongodb-adapter
sudo systemctl status tft-mongodb-adapter
```

### Option 2: Docker Container

Create `Dockerfile`:

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY adapters/ ./adapters/

CMD ["python", "adapters/mongodb_adapter.py", "--daemon", "--config", "/config/mongodb_adapter_config.json"]
```

Run:
```bash
docker build -t tft-mongodb-adapter .
docker run -d \
  --name tft-adapter \
  -v /path/to/config:/config \
  --restart unless-stopped \
  tft-mongodb-adapter
```

### Option 3: Windows Service (via NSSM)

```batch
REM Download NSSM from https://nssm.cc/

REM Install as service
nssm install TFTMongoDBAdapter "C:\Python310\python.exe" ^
  "D:\tft-monitoring\adapters\mongodb_adapter.py" ^
  --daemon --config "D:\tft-monitoring\adapters\mongodb_adapter_config.json"

REM Start service
nssm start TFTMongoDBAdapter
```

---

## 🧪 Testing & Validation

### Test 1: Connection Test

```bash
# MongoDB
python mongodb_adapter.py --once --verbose

# Expected output:
# ✅ Connected to MongoDB
# ✅ Fetched X metrics
# ✅ Transformed X records
# ✅ Forwarded X records to TFT daemon
```

### Test 2: Schema Validation

```bash
# Check if metrics match expected format
python mongodb_adapter.py --once --verbose 2>&1 | grep "Transformed"

# Should show: ✅ Transformed X records to TFT format
# If 0 records, check field mappings
```

### Test 3: End-to-End Test

```bash
# Terminal 1: Start TFT daemon
python tft_inference_daemon.py --port 8000

# Terminal 2: Run adapter once
python mongodb_adapter.py --once --verbose

# Terminal 3: Check dashboard
# Open http://localhost:8501
# Verify servers appear in Overview tab
```

---

## 📈 Monitoring & Troubleshooting

### Check Adapter Status

```bash
# View logs (systemd)
journalctl -u tft-mongodb-adapter -f

# View logs (Docker)
docker logs -f tft-adapter

# Stats printed every 100 records:
# 📊 Stats: 500 records forwarded, 2 errors
```

### Common Issues

#### Issue 1: "No metrics found"

**Cause:** Query returning empty results

**Solutions:**
```bash
# Check time range
python mongodb_adapter.py --once --verbose

# Verify data exists in MongoDB
mongo linborg --eval "db.server_metrics.find().limit(1).pretty()"

# Verify data exists in Elasticsearch
curl "http://localhost:9200/linborg-metrics-*/_search?size=1&pretty"
```

#### Issue 2: "No records after transformation"

**Cause:** Field mapping mismatch

**Solutions:**
```python
# Add debug logging to see raw documents
# In adapter code, add:
logger.debug(f"Raw document: {json.dumps(doc, indent=2)}")

# Compare with expected field names
# Adjust transform_to_tft_format() function
```

#### Issue 3: "TFT daemon error: 403" or "Authentication failed"

**Cause:** Missing or invalid API key

**Solutions:**
```bash
# Step 1: Verify .env file exists and contains API key
cat .env | grep TFT_API_KEY
# Should show: TFT_API_KEY=abc123...

# Step 2: If missing, generate API key
python generate_api_key.py

# Step 3: Run adapter from project root directory
cd /path/to/MonitoringPrediction
python adapters/mongodb_adapter.py --once --verbose

# Step 4: Test daemon directly
curl -X POST http://localhost:8000/health \
  -H "X-API-Key: $(grep TFT_API_KEY .env | cut -d= -f2)"

# Step 5: Check adapter logs for "Loaded API key" message
# Should see: "✅ Loaded API key from .env"
```

**Note:** Adapters must be run from project root OR have .env file in adapters/ directory.

#### Issue 4: "Connection timeout"

**Cause:** Network/firewall issues

**Solutions:**
```bash
# Test MongoDB connectivity
telnet mongo.example.com 27017

# Test Elasticsearch connectivity
curl http://es.example.com:9200/_cluster/health

# Check firewall rules
# Ensure adapter host can reach database + TFT daemon
```

---

## 📊 Performance Tuning

### Fetch Interval

```bash
# Fast updates (5 seconds) - higher load
python mongodb_adapter.py --daemon --interval 5

# Balanced (10 seconds) - recommended
python mongodb_adapter.py --daemon --interval 10

# Slower updates (30 seconds) - lower load
python mongodb_adapter.py --daemon --interval 30
```

### Batch Size

Edit config:
```json
{
  "adapter": {
    "max_records_per_fetch": 1000  // Adjust based on load
  }
}
```

- **Small batches (100-500)**: Lower memory, more frequent updates
- **Large batches (1000-5000)**: Higher throughput, less overhead

### Index Optimization

**MongoDB:**
```javascript
// Create compound index for efficient queries
db.server_metrics.createIndex({timestamp: 1, server_name: 1})
```

**Elasticsearch:**
```json
PUT /linborg-metrics-2025.10.17
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "refresh_interval": "5s"
  }
}
```

---

## 🔄 Maintenance

### Rotating Logs

```bash
# Redirect stdout/stderr to files
python mongodb_adapter.py --daemon > /var/log/tft/adapter.log 2>&1

# Use logrotate
cat > /etc/logrotate.d/tft-adapter <<EOF
/var/log/tft/adapter.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
}
EOF
```

### Health Checks

```bash
# Check if adapter is running
ps aux | grep mongodb_adapter.py

# Check last log entry
tail -1 /var/log/tft/adapter.log

# Check records forwarded
grep "Stats:" /var/log/tft/adapter.log | tail -1
```

### Upgrading Adapters

```bash
# Stop adapter
sudo systemctl stop tft-mongodb-adapter

# Backup config
cp mongodb_adapter_config.json mongodb_adapter_config.json.backup

# Pull latest code
git pull origin main

# Restart adapter
sudo systemctl start tft-mongodb-adapter

# Verify
sudo systemctl status tft-mongodb-adapter
```

---

## 📚 Additional Resources

- **[TFT Monitoring Documentation](../Docs/)** - System overview
- **[LINBORG Metrics Guide](../Docs/LINBORG_METRICS.md)** - Metric definitions
- **[API Key Setup](../Docs/API_KEY_SETUP.md)** - Security configuration
- **[Troubleshooting Guide](../Docs/TROUBLESHOOTING.md)** - Common issues

---

## 🆘 Support

**Issues?**
1. Check adapter logs for error messages
2. Verify configuration (credentials, URLs, field mappings)
3. Test database connectivity independently
4. Ensure TFT daemon is running and accessible
5. Review field mapping in `transform_to_tft_format()`

**Need Help?**
- Open an issue with logs and configuration (redact passwords!)
- Include database schema sample
- Provide error messages and stack traces

---

**Version:** 1.0.0
**Last Updated:** 2025-10-17
**Compatibility:** TFT Monitoring System v1.0.0+
